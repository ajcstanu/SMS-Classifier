{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Model to classify SMS as either spam or non-spam\n**","metadata":{"id":"YazR9jKsstk1"}},{"cell_type":"markdown","source":"https://miro.medium.com/v2/resize:fit:620/0*ww5ON8MjhmUdMvoi.jpeg","metadata":{"id":"VGwjHauptNmY"}},{"cell_type":"markdown","source":"\n**Overview/Introduction:**\nIn today's digital age, mobile devices and Short Message Service (SMS) have become ubiquitous tools for communication. However, this convenience also brings the challenge of dealing with spam messages. These unwanted texts can not only be annoying but also pose security risks, such as phishing attempts. This project aims to leverage artificial intelligence to effectively detect and categorize spam messages, thereby providing a shield for users and enhancing their overall communication experience.\n\n**Problem Statement:**\nThe landscape of spam messages is constantly evolving to evade detection, making their identification a complex task. It is essential to accurately identify these messages while ensuring that legitimate messages are not incorrectly labeled as spam and no spam messages are missed. Given the high volume and rapid transmission of messages, manual inspection is not feasible. We require an automated, accurate, and adaptable solution.\n\n**Objectives:**\n1. Develop a machine learning model that accurately classifies SMS messages into spam or ham (legitimate) categories.\n2. Ensure the model's capability to adapt to the changing nature of spam messages, maintaining a high level of accuracy over time.\n3. Minimize the risk of mislabeling messages, preventing legitimate messages from being marked as spam and ensuring the detection of spam messages.\n4. Evaluate different algorithms to identify the most suitable one for the task.\n5. Contribute to ongoing research in spam detection by providing a robust and scalable solution that can potentially be extended to other forms of digital communication.\n\n**Dataset Description:**\n**Context:** The SMS Spam Collection is a curated dataset of SMS messages designed to support research in SMS spam detection. It comprises a total of 5,574 English SMS messages, each explicitly labeled as either ham (legitimate) or spam.\n\n**Content:** The dataset is straightforward and well-structured. Each row represents an individual message and is divided into two columns: 'v1' for labeling the message as spam or ham, and 'v2' containing the actual message text.\n\n**Source:** The data has been sourced from various origins, primarily those that are freely available or intended for research purposes:\n1. 425 spam SMS messages were manually selected from the Grumbletext website, a UK forum where mobile users discuss spam-related issues. This selection process involved sifting through numerous web pages to identify the spam content.\n2. 3,375 legitimate SMS messages were randomly sampled from the NUS SMS Corpus (NSC), a collection of approximately 10,000 genuine messages used for research at the National University of Singapore. These messages are primarily from students in Singapore.\n3. An additional 450 legitimate SMS messages were extracted from Caroline Tag's Ph.D. thesis.\n4. Finally, the SMS Spam Corpus v.0.1 Big, a publicly available dataset containing 1,002 legitimate messages and 322 spam messages, was included in the dataset.\n\nThis dataset serves as a valuable resource for advancing the field of SMS spam detection and contributes to the development of effective anti-spam solutions.\n\n","metadata":{"id":"NHrjpN-QbDTs"}},{"cell_type":"markdown","source":"**Technologies Used**\n\n- **Python**: The primary programming language used for building machine learning models and conducting data analysis.\n\n- **Scikit-Learn (Sklearn)**: A Python library for machine learning that offers efficient tools for data analysis, model building, and evaluation.\n\n- **TensorFlow**: An open-source machine learning platform developed by the Google Brain team, used for building and training deep learning models.\n\n- **TensorFlow Hub**: A library that simplifies the sharing and consumption of pre-trained machine learning models, facilitating model reuse and integration.\n\n- **Matplotlib**: A Python library for creating a wide range of static, animated, and interactive data visualizations to aid in data exploration and presentation.\n\n- **NLTK (Natural Language Toolkit)**: A Python library designed for working with human language data, enabling natural language processing tasks such as text analysis and classification.","metadata":{"id":"VdZihSivZfz0"}},{"cell_type":"markdown","source":"**Methodology:**\nThis project employed a supervised learning approach for text classification, with the primary objective of using artificial intelligence to identify spam SMS messages. A variety of machine learning and deep learning models were utilized, including LSTM, Bidirectional LSTM, GRU, a simple dense network, a model based on the Neural Network Language Model (NNLM), and a model utilizing the Universal Sentence Encoder (USE). Additionally, Conv1D and Bidirectional GRU models were included, along with a baseline model for benchmarking.\n\n**Implementation:**\nThe implementation began with crucial text data preprocessing, a fundamental step in effective Natural Language Processing (NLP). This preprocessing involved tasks such as removing unwanted elements like emojis, newline characters, URLs, mentions, and special characters. Additionally, text was converted to lowercase, common stop words were eliminated, relevant hashtags were retained, and lemmatization was applied.\n\nThe initial model was a baseline Multinomial Naive Bayes classifier with TF-IDF vectorization. Subsequently, various models, including simple dense networks, LSTM, Bidirectional LSTM, GRU, Bidirectional GRU, and Conv1D, were designed and trained using the dataset. Two additional models were created: one using the Neural Network Language Model (NNLM) and another incorporating the Universal Sentence Encoder (USE) for generating the embedding layer.\n\n**Results:**\nComprehensive model evaluation was conducted using critical performance metrics, including accuracy, precision, recall, F1-score, and loss. Notably, the simple dense network achieved perfect scores across all metrics, closely followed by the LSTM and an ensemble model, formed by combining multiple models. Models based on LSTM, Bidirectional GRU, and the USE also demonstrated strong performance.\n\n**Discussion/Interpretation of Results:**\nThe results were insightful, highlighting the outstanding performance of the simple dense network in text classification tasks, particularly for spam detection. The LSTM model also exhibited exceptional performance, underscoring the effectiveness of recurrent neural networks for such tasks. The ensemble model, leveraging the strengths of multiple models, secured a solid position in terms of performance, affirming the advantages of ensemble methods in enhancing model robustness.\n\n**Conclusion:**\nThis project underscored the potential of machine learning and deep learning models in text classification, specifically for the identification of spam SMS messages. A diverse array of model architectures was explored, ranging from straightforward dense networks to more intricate structures like LSTM and GRU. The results demonstrated that well-designed models can achieve impressive accuracy. Future work can focus on further enhancing these models through larger datasets, refined data preprocessing techniques, hyperparameter optimization, and the exploration of alternative architectures and ensemble strategies.","metadata":{"id":"NfU2GMRhnrvB"}},{"cell_type":"markdown","source":"**Acknowledgments:**\nThe original dataset used in this project can be accessed at the following URL: [SMS Spam Collection Dataset](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection).\n\n","metadata":{"id":"mkN8vd2boa1Z"}},{"cell_type":"code","source":"import numpy as np # Import the NumPy library for numerical operations\nimport pandas as pd # Import the Pandas library for data processing and manipulation\nimport tensorflow as tf # Import TensorFlow for deep learning operations\n\n# Input data files are available in the read-only \"/kaggle/input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Use the os library to traverse the directory structure starting from '/kaggle/input'\nimport os\n\n# Iterate through the directory structure and list all files in the '/kaggle/input' directory\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        # Print the full path to each file in the '/kaggle/input' directory\n        print(os.path.join(dirname, filename))\n        #####  ******other way to write the code *******************\nimport os\n\n# Specify the directory path you want to list files from\ndirectory_path = '/your/directory/path'  # Replace with your directory path\n\n# Use the os library to traverse the specified directory structure\nfor dirname, _, filenames in os.walk(directory_path):\n    for filename in filenames:\n        # Print the full path to each file in the specified directory\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"avF_0Z9lmWeK","outputId":"30471ba1-ccb0-4681-e52f-94e6d4651035","execution":{"iopub.status.busy":"2023-06-30T22:04:00.012377Z","iopub.execute_input":"2023-06-30T22:04:00.012799Z","iopub.status.idle":"2023-06-30T22:04:00.028714Z","shell.execute_reply.started":"2023-06-30T22:04:00.01277Z","shell.execute_reply":"2023-06-30T22:04:00.027695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\nimport importlib.util\n\n# Define the URL of the helper functions script\nhelper_functions_url = \"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\"\n\n# Define the local file name for the downloaded script\nlocal_script_filename = \"helper_functions.py\"\n\n# Download the script from the specified URL\nresponse = requests.get(helper_functions_url)\n\n# Check if the download was successful\nif response.status_code == 200:\n    # Save the downloaded script to a local file\n    with open(local_script_filename, \"w\") as script_file:\n        script_file.write(response.text)\n\n    # Import specific functions from the downloaded script\n    spec = importlib.util.spec_from_file_location(\"helper_functions\", local_script_filename)\n####### other way to write the code #########\n# Import a series of helper functions for the notebook\n\n# Download the helper functions script from a specified URL\n!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n\n# Import specific functions from the downloaded script\nfrom helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys\n","metadata":{"id":"1aLLu3eHm-R4","outputId":"8ed5f8f5-7637-4ed7-cde0-277e1f5ab0f3","execution":{"iopub.status.busy":"2023-06-30T22:04:00.031082Z","iopub.execute_input":"2023-06-30T22:04:00.031823Z","iopub.status.idle":"2023-06-30T22:04:01.427243Z","shell.execute_reply.started":"2023-06-30T22:04:00.031789Z","shell.execute_reply":"2023-06-30T22:04:01.425997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Import with Pandas**","metadata":{"id":"1yUrEbstvFCf"}},{"cell_type":"code","source":"DATA_DIR='/kaggle/input/ham-spam-messages-dataset/spam-ham v2.csv'","metadata":{"id":"89Rjtm39bv6p","execution":{"iopub.status.busy":"2023-06-30T22:04:01.429359Z","iopub.execute_input":"2023-06-30T22:04:01.429714Z","iopub.status.idle":"2023-06-30T22:04:01.43512Z","shell.execute_reply.started":"2023-06-30T22:04:01.429677Z","shell.execute_reply":"2023-06-30T22:04:01.434173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load CSV file into a DataFrame\ndf = pd.read_csv(DATA_DIR, encoding='latin1')\n\n# Display the DataFrame\ndf.head(20)","metadata":{"id":"5ZT6v1sKmWeQ","outputId":"ae9b1ce5-c261-455c-e238-9218ace8c44c","execution":{"iopub.status.busy":"2023-06-30T22:04:01.437992Z","iopub.execute_input":"2023-06-30T22:04:01.438746Z","iopub.status.idle":"2023-06-30T22:04:01.48795Z","shell.execute_reply.started":"2023-06-30T22:04:01.43871Z","shell.execute_reply":"2023-06-30T22:04:01.486977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code renames the columns of a DataFrame from 'v1' to 'label' and from 'v2' to 'text'. It then assigns the modified DataFrame to the variable 'df'. Here's how you can rewrite the code:\n","metadata":{"id":"WQXjI25Pg0OV"}},{"cell_type":"code","source":"# Assuming you have a DataFrame named 'original_df' that you want to modify\nimport pandas as pd\n\n# Rename the columns and assign the modified DataFrame to 'df'\ndf = original_df.rename(columns={'v1': 'label', 'v2': 'text'})\n","metadata":{"id":"NxhqeY6xFIr2","execution":{"iopub.status.busy":"2023-06-30T22:04:01.489508Z","iopub.execute_input":"2023-06-30T22:04:01.490249Z","iopub.status.idle":"2023-06-30T22:04:01.496556Z","shell.execute_reply.started":"2023-06-30T22:04:01.490215Z","shell.execute_reply":"2023-06-30T22:04:01.495492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"id":"yP2Ok9NbmWeR","outputId":"a9f8ec80-67a6-46e2-a3f5-11787daddcb7","execution":{"iopub.status.busy":"2023-06-30T22:04:01.498178Z","iopub.execute_input":"2023-06-30T22:04:01.498652Z","iopub.status.idle":"2023-06-30T22:04:01.51888Z","shell.execute_reply.started":"2023-06-30T22:04:01.498611Z","shell.execute_reply":"2023-06-30T22:04:01.517829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code imports the 'matplotlib.pyplot' library for data visualization, calculates the value counts of the 'label' column in the DataFrame, and stores the counts in the 'category_counts' variable. Here's how you can rewrite the code:\n\nimport matplotlib.pyplot as plt  # Import the matplotlib library for data visualization\n\n# Assuming you have a DataFrame named 'df' with a 'label' column\n# Calculate the value counts of the 'label' column\ncategory_counts = df['label'].value_counts()","metadata":{"id":"MJP-Ey8qg29_"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Calculate the value counts of the 'label' column\ncategory_counts = df['label'].value_counts()\n\n# Bar chart\nplt.figure(figsize=(6, 4))\ncategory_counts.plot(kind='bar')\nplt.xlabel('Label')\nplt.ylabel('Counts')\nplt.title('Bar Chart of Counts')\nplt.show()\nprint()\n\n# Pie chart\nplt.figure(figsize=(6, 4))\ncategory_counts.plot(kind='pie', autopct='%1.1f%%')\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\nplt.title('Pie Chart of Distribution')\n\n# Add legend\nplt.legend()\n\nplt.show()","metadata":{"id":"MKChBb5HmWeR","outputId":"666b5227-12e6-41a7-fede-759dfaf31916","execution":{"iopub.status.busy":"2023-06-30T22:04:01.521946Z","iopub.execute_input":"2023-06-30T22:04:01.522257Z","iopub.status.idle":"2023-06-30T22:04:01.963461Z","shell.execute_reply.started":"2023-06-30T22:04:01.522233Z","shell.execute_reply":"2023-06-30T22:04:01.962085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Duplicates and Missing Values**","metadata":{"id":"ETYyRy3SmWeU"}},{"cell_type":"markdown","source":"The code checks for missing values in the DataFrame using the 'isnull()' function, calculates the sum of missing values for each column, and prints the number of missing values for each column and the total number of missing values in the DataFrame. Here's how you can rewrite the code:","metadata":{"id":"V9aLqa8Khl-4"}},{"cell_type":"code","source":"# How many reviews do we have?\nprint('There are', df.shape[0], 'data in this dataset')\n\n# Do we have duplicates?\nprint('Number of Duplicates:', len(df[df.duplicated()]))\n\n# Do we have missing values?\nmissing_values = df.isnull().sum()\nprint('Number of Missing Values by column:\\n',missing_values)\n\nprint('Number of Missing Values:', df.isnull().sum().sum())","metadata":{"id":"aKbC7aThmWeX","outputId":"02c9fca3-1bed-427a-a73d-724088025911","execution":{"iopub.status.busy":"2023-06-30T22:04:01.965185Z","iopub.execute_input":"2023-06-30T22:04:01.96563Z","iopub.status.idle":"2023-06-30T22:04:01.99979Z","shell.execute_reply.started":"2023-06-30T22:04:01.965596Z","shell.execute_reply":"2023-06-30T22:04:01.998235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code then imports the 'numpy' library as 'np' and replaces empty strings with NaN values in the DataFrame using 'df.replace(\"\", np.nan, inplace=True)'. It calculates and prints the number of missing values and empty spaces for each column in the DataFrame.","metadata":{"id":"XjYLN2eghno4"}},{"cell_type":"code","source":"df.replace(\"\", np.nan, inplace=True)\nmissing_values = df.isnull().sum()\nprint('Number of Missing Values and Empty Spaces by column:\\n',missing_values)","metadata":{"id":"aX8mP7A9mWeY","outputId":"8e6a6d64-3586-4444-d001-f3e372713bdf","execution":{"iopub.status.busy":"2023-06-30T22:04:02.005136Z","iopub.execute_input":"2023-06-30T22:04:02.005594Z","iopub.status.idle":"2023-06-30T22:04:02.022796Z","shell.execute_reply.started":"2023-06-30T22:04:02.005552Z","shell.execute_reply":"2023-06-30T22:04:02.021813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Review Duplicates**\n\nThe code identifies duplicate rows in the DataFrame by finding rows that have duplicates across all columns. It then sorts the duplicate rows based on all columns and selects the top 5 pairs of duplicates (10 rows) using 'sorted_duplicates.head(20)'. Here's how you can rewrite the code:","metadata":{"id":"YAiVMoq6mWeZ"}},{"cell_type":"code","source":"# First, get all duplicate rows (keep=False ensures all duplicates are kept)\nduplicate_rows = df[df.duplicated(keep=False)]\n\n# Then sort the dataframe on all columns to ensure duplicates are adjacent\nsorted_duplicates = duplicate_rows.sort_values(by=list(duplicate_rows.columns))\n\n# Now, if we want to see 5 pairs of duplicates (10 rows), we can simply:\ntop_5_duplicate_pairs = sorted_duplicates.head(20)\ntop_5_duplicate_pairs","metadata":{"id":"go73GIi4mWea","outputId":"fdf1ed8f-aac6-45bc-969e-41cd8008f7ec","execution":{"iopub.status.busy":"2023-06-30T22:04:02.024176Z","iopub.execute_input":"2023-06-30T22:04:02.024865Z","iopub.status.idle":"2023-06-30T22:04:02.045377Z","shell.execute_reply.started":"2023-06-30T22:04:02.024833Z","shell.execute_reply":"2023-06-30T22:04:02.044469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Drop Duplicates**\n\nThis code removes duplicate rows from the DataFrame 'df'. Removing duplicate rows ensures that each row in the DataFrame is unique and eliminates redundant data, which can affect analysis and modeling.","metadata":{"id":"b3GQZ6zMmWeb"}},{"cell_type":"code","source":"df = df.drop_duplicates()\nprint('Number of Duplicates:', len(df[df.duplicated()]))","metadata":{"id":"hgKGzloxmWec","outputId":"e832ef18-1c67-4e11-87f2-a2ea672345a0","execution":{"iopub.status.busy":"2023-06-30T22:04:02.046692Z","iopub.execute_input":"2023-06-30T22:04:02.047629Z","iopub.status.idle":"2023-06-30T22:04:02.063902Z","shell.execute_reply.started":"2023-06-30T22:04:02.047597Z","shell.execute_reply":"2023-06-30T22:04:02.062862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Drop Missing Values**\n\nThis code drops rows containing missing values (NaN) from the DataFrame 'df'. Removing rows with missing values is important to ensure data quality and avoid errors or biased analysis caused by missing information.","metadata":{"id":"2vb0IWFWmWec"}},{"cell_type":"code","source":"df = df.dropna()\nprint('Number of Missing Values:', df.isnull().sum().sum())","metadata":{"id":"0SDqFbW8mWed","outputId":"7fca85b6-6c11-4e1b-b10b-1ac7064810de","execution":{"iopub.status.busy":"2023-06-30T22:04:02.065493Z","iopub.execute_input":"2023-06-30T22:04:02.065834Z","iopub.status.idle":"2023-06-30T22:04:02.08027Z","shell.execute_reply.started":"2023-06-30T22:04:02.065794Z","shell.execute_reply":"2023-06-30T22:04:02.078928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"id":"W__4qEh4mWed","outputId":"40c6ac8c-430b-4319-e231-09fca787c504","execution":{"iopub.status.busy":"2023-06-30T22:04:02.082085Z","iopub.execute_input":"2023-06-30T22:04:02.082493Z","iopub.status.idle":"2023-06-30T22:04:02.096574Z","shell.execute_reply.started":"2023-06-30T22:04:02.082461Z","shell.execute_reply":"2023-06-30T22:04:02.095552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**View random samples for each category**\n\nThis code defines a function 'random_sample_reviews' that takes a DataFrame 'df' and the number of samples to be extracted as input and returns a DataFrame with random samples from each group based on the 'label' column. This can be useful for data exploration, model training, or analysis.","metadata":{"id":"FZ7ZpPokmWee"}},{"cell_type":"code","source":"def random_sample_reviews(df, num_samples):\n    # Use groupby on 'label' and then apply the sample function to 'text' of each group\n    samples = df.groupby('label')['text'].apply(lambda x: x.sample(num_samples))\n\n    # Convert series to dataframe and reset index\n    # samples_df = samples.reset_index()\n    samples_df = samples.reset_index().drop(columns='level_1')\n\n    return samples_df\npd.set_option('display.max_colwidth', 200) # This will display up to 100 characters\nsamples = random_sample_reviews(df, num_samples=10)\nsamples.head(20)","metadata":{"id":"JQ4qRqqQmWef","outputId":"6ef0dd85-3b34-4ed0-cee2-ec727eb618e0","execution":{"iopub.status.busy":"2023-06-30T22:04:02.098456Z","iopub.execute_input":"2023-06-30T22:04:02.098833Z","iopub.status.idle":"2023-06-30T22:04:02.120984Z","shell.execute_reply.started":"2023-06-30T22:04:02.098759Z","shell.execute_reply":"2023-06-30T22:04:02.119917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Cleaning**","metadata":{"id":"3ebnHpjemWef"}},{"cell_type":"markdown","source":"These follwoing functions perform various text cleaning operations such as removing emojis, links, mentions, punctuation, and extra spaces from text data. Text cleaning is an essential preprocessing step in natural language processing tasks as it helps remove noise, irrelevant characters, and standardize the text data for better analysis and modeling.","metadata":{"id":"OtrYANauk0fq"}},{"cell_type":"code","source":"# Necessary libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nimport re\nimport string\n\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding\nfrom tensorflow.keras.layers import SimpleRNN, LSTM\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"id":"GeEDPkqQmWeg","execution":{"iopub.status.busy":"2023-06-30T22:04:02.122698Z","iopub.execute_input":"2023-06-30T22:04:02.123069Z","iopub.status.idle":"2023-06-30T22:04:02.130997Z","shell.execute_reply.started":"2023-06-30T22:04:02.12302Z","shell.execute_reply":"2023-06-30T22:04:02.129831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def strip_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n        u\"\\U00002500-\\U00002BEF\"  # chinese characters\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U000024C2-\\U0001F251\"\n        u\"\\U0001f926-\\U0001f937\"\n        u\"\\U00010000-\\U0010ffff\"\n        u\"\\u2640-\\u2642\"\n        u\"\\u2600-\\u2B55\"\n        u\"\\u200d\"\n        u\"\\u23cf\"\n        u\"\\u23e9\"\n        u\"\\u231a\"\n        u\"\\ufe0f\"  # dingbats\n        u\"\\u3030\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\n#Remove punctuations, links, mentions and \\r\\n new line characters\ndef strip_all_entities(text):\n    text = text.replace('\\r', '').replace('\\n', ' ').replace('\\n', ' ').lower() #remove \\n and \\r and lowercase\n    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #remove links and mentions\n    text = re.sub(r'[^\\x00-\\x7f]',r'', text) #remove non utf8/ascii characters such as '\\x9a\\x91\\x97\\x9a\\x97'\n    banned_list= string.punctuation + 'Ã'+'±'+'ã'+'¼'+'â'+'»'+'§'\n    table = str.maketrans('', '', banned_list)\n    text = text.translate(table)\n    return text\n\n#clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the # symbol\ndef clean_hashtags(text):\n    new_text = \" \".join(word.strip() for word in re.split('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', text)) #remove last hashtags\n    new_text2 = \" \".join(word.strip() for word in re.split('#|_', new_text)) #remove hashtags symbol from words in the middle of the sentence\n    return new_text2\n\n#Filter special characters such as & and $ present in some words\ndef filter_chars(a):\n    sent = []\n    for word in a.split(' '):\n        if ('$' in word) | ('&' in word):\n            sent.append('')\n        else:\n            sent.append(word)\n    return ' '.join(sent)\n\ndef remove_mult_spaces(text): # remove multiple spaces\n    return re.sub(\"\\s\\s+\" , \" \", text)","metadata":{"id":"jXq7YLEZmWeg","execution":{"iopub.status.busy":"2023-06-30T22:04:02.134296Z","iopub.execute_input":"2023-06-30T22:04:02.134558Z","iopub.status.idle":"2023-06-30T22:04:02.149429Z","shell.execute_reply.started":"2023-06-30T22:04:02.134535Z","shell.execute_reply":"2023-06-30T22:04:02.14848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code applies a series of text cleaning functions to the 'text' column of the DataFrame 'df' and assigns the cleaned text to a new column 'text1'.","metadata":{"id":"Y7fJgqiWlALE"}},{"cell_type":"code","source":"df['text1'] = (df['text']\n                     .apply(strip_emoji)\n                     .apply(strip_all_entities)\n                     .apply(clean_hashtags)\n                     .apply(filter_chars)\n                     .apply(remove_mult_spaces))","metadata":{"id":"BLSJbDpumWeh","execution":{"iopub.status.busy":"2023-06-30T22:04:02.151051Z","iopub.execute_input":"2023-06-30T22:04:02.151744Z","iopub.status.idle":"2023-06-30T22:04:02.355418Z","shell.execute_reply.started":"2023-06-30T22:04:02.15171Z","shell.execute_reply":"2023-06-30T22:04:02.354496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"sW_klspImWeh","outputId":"85eae900-dc4b-4c88-d72d-eb6272c31b89","execution":{"iopub.status.busy":"2023-06-30T22:04:02.356744Z","iopub.execute_input":"2023-06-30T22:04:02.357189Z","iopub.status.idle":"2023-06-30T22:04:02.370478Z","shell.execute_reply.started":"2023-06-30T22:04:02.357154Z","shell.execute_reply":"2023-06-30T22:04:02.369104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code creates a DataFrame 'df_comparison'.This DataFrame will be used to compare the original and cleaned text data and analyze the impact of text cleaning on the text length.","metadata":{"id":"MlioTaLLlDJo"}},{"cell_type":"code","source":"df_comparison = pd.DataFrame()\n\n# Original text and its length\ndf_comparison['pre-clean text'] = df['text']\ndf_comparison['pre-clean len'] = df['text'].apply(lambda x: len(str(x).split()))\n\n# Cleaned text and its length\ndf_comparison['post-clean text'] = df['text1']\ndf_comparison['post-clean len'] = df['text1'].apply(lambda x: len(str(x).split()))\n\ndf_comparison.head(20)","metadata":{"id":"-jP07q-bmWel","outputId":"e4d052e3-c835-4c79-a628-7687e79ccc0d","execution":{"iopub.status.busy":"2023-06-30T22:04:02.372318Z","iopub.execute_input":"2023-06-30T22:04:02.37295Z","iopub.status.idle":"2023-06-30T22:04:02.415878Z","shell.execute_reply.started":"2023-06-30T22:04:02.372917Z","shell.execute_reply":"2023-06-30T22:04:02.414933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remove Stopwords","metadata":{"id":"6GXWMdpZmWel"}},{"cell_type":"markdown","source":"This next code defines a function 'remove_stopwords' that takes a sentence as input and removes common stopwords from it. Removing stopwords can help eliminate words that carry little semantic meaning and improve the quality of text analysis or modeling tasks.","metadata":{"id":"DS6SCK7mlNH-"}},{"cell_type":"code","source":"def remove_stopwords(sentence):\n    \"\"\"\n    Removes a list of stopwords\n\n    Args:\n        sentence (string): sentence to remove the stopwords from\n\n    Returns:\n        sentence (string): lowercase sentence without the stopwords\n    \"\"\"\n    # List of stopwords\n    stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n\n    # Sentence converted to lowercase-only\n    sentence = sentence.lower()\n\n    words = sentence.split()\n    no_words = [w for w in words if w not in stopwords]\n    sentence = \" \".join(no_words)\n\n    return sentence\n","metadata":{"id":"m_84UgOKmWem","execution":{"iopub.status.busy":"2023-06-30T22:04:02.417485Z","iopub.execute_input":"2023-06-30T22:04:02.417835Z","iopub.status.idle":"2023-06-30T22:04:02.429871Z","shell.execute_reply.started":"2023-06-30T22:04:02.417795Z","shell.execute_reply":"2023-06-30T22:04:02.42853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code applies the 'remove_stopwords' function to the 'text1' column of the DataFrame 'df' and assigns the stopwords-removed text to a new column 'text2'.","metadata":{"id":"eT_2F6NVlTU9"}},{"cell_type":"code","source":"df['text2'] = (df['text1'].apply(remove_stopwords))","metadata":{"id":"Y-mDkT6OmWem","execution":{"iopub.status.busy":"2023-06-30T22:04:02.431801Z","iopub.execute_input":"2023-06-30T22:04:02.432177Z","iopub.status.idle":"2023-06-30T22:04:02.614464Z","shell.execute_reply.started":"2023-06-30T22:04:02.432143Z","shell.execute_reply":"2023-06-30T22:04:02.613279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following code creates a DataFrame 'df_comp' and will be used to compare the original and stopwords-removed text data and analyze the impact of removing stopwords on the text length.","metadata":{"id":"tNoYM_uBlWPw"}},{"cell_type":"code","source":"df_comp = pd.DataFrame()\n\n# Original text and its length\ndf_comp['pre-clean text'] = df['text1']\ndf_comp['pre-clean len'] = df['text1'].apply(lambda x: len(str(x).split()))\n\n# Cleaned text and its length\ndf_comp['post-clean text'] = df['text2']\ndf_comp['post-clean len'] = df['text2'].apply(lambda x: len(str(x).split()))\n\ndf_comp.head(20)","metadata":{"id":"qiJr0_jCmWen","outputId":"d85cb263-ab7b-4309-8b72-44bb90462e96","execution":{"iopub.status.busy":"2023-06-30T22:04:02.616Z","iopub.execute_input":"2023-06-30T22:04:02.616372Z","iopub.status.idle":"2023-06-30T22:04:02.657007Z","shell.execute_reply.started":"2023-06-30T22:04:02.616346Z","shell.execute_reply":"2023-06-30T22:04:02.656156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lemmatization","metadata":{"id":"mnwgOQnXmWen"}},{"cell_type":"markdown","source":"The following code defines a lemmatization function, which uses the WordNetLemmatizer from the NLTK library to lemmatize a given text. Lemmatization reduces words to their base or root form, allowing for better analysis and modeling.","metadata":{"id":"q0i7kQzZl4Ft"}},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\n\nimport nltk\nnltk.download('wordnet')\nnltk.download('punkt')\n\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\n\nlemmatizer = WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    # Tokenize the sentence\n    word_list = nltk.word_tokenize(text)\n\n    # Lemmatize list of words and join\n    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n\n    return lemmatized_output","metadata":{"id":"KbIrJFLbmWen","outputId":"f5fa5c26-6d61-4f48-f108-d04cf23754f2","execution":{"iopub.status.busy":"2023-06-30T22:04:02.659138Z","iopub.execute_input":"2023-06-30T22:04:02.659925Z","iopub.status.idle":"2023-06-30T22:17:44.290008Z","shell.execute_reply.started":"2023-06-30T22:04:02.659883Z","shell.execute_reply":"2023-06-30T22:17:44.288608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The lemmatization function is then applied to the 'text2' column of the DataFrame 'df' using the apply method, and the lemmatized output is assigned to the 'text3' column.","metadata":{"id":"mFTEuKb5l-ST"}},{"cell_type":"code","source":"df['text3'] = df['text2'].apply(lemmatize_text)","metadata":{"id":"36-RYTWnmWeo","execution":{"iopub.status.busy":"2023-06-30T22:17:44.300524Z","iopub.execute_input":"2023-06-30T22:17:44.300853Z","iopub.status.idle":"2023-06-30T22:17:45.719266Z","shell.execute_reply.started":"2023-06-30T22:17:44.300819Z","shell.execute_reply":"2023-06-30T22:17:45.718214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A new DataFrame, 'df_lemma', is created to store the original and lemmatized text data along with their respective lengths.","metadata":{"id":"K11A8jlkmCQ1"}},{"cell_type":"code","source":"df_lemma = pd.DataFrame()\n\n# Original text and its length\ndf_lemma['pre-clean text'] = df['text2']\ndf_lemma['pre-clean len'] = df['text2'].apply(lambda x: len(str(x).split()))\n\n# Cleaned text and its length\ndf_lemma['post-clean text'] = df['text3']\ndf_lemma['post-clean len'] = df['text3'].apply(lambda x: len(str(x).split()))\n\ndf_lemma.head(20)\n","metadata":{"id":"NhzRdaWlmWeo","outputId":"e5ce0353-dc81-4264-fe53-1d1e126a24a1","execution":{"iopub.status.busy":"2023-06-30T22:17:45.720814Z","iopub.execute_input":"2023-06-30T22:17:45.721285Z","iopub.status.idle":"2023-06-30T22:17:45.758067Z","shell.execute_reply.started":"2023-06-30T22:17:45.721251Z","shell.execute_reply":"2023-06-30T22:17:45.757087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Text Length**","metadata":{"id":"pl3srUMOmWeo"}},{"cell_type":"markdown","source":"The code calculates the length of each text in the 'text3' column and finds the 95th quartile of text lengths.","metadata":{"id":"XrkvxHydmFe8"}},{"cell_type":"code","source":"df['text_length'] = df['text3'].apply(lambda x: len(str(x).split()))","metadata":{"id":"7uoYyWwImWeo","execution":{"iopub.status.busy":"2023-06-30T22:17:45.759563Z","iopub.execute_input":"2023-06-30T22:17:45.760149Z","iopub.status.idle":"2023-06-30T22:17:45.774993Z","shell.execute_reply.started":"2023-06-30T22:17:45.760117Z","shell.execute_reply":"2023-06-30T22:17:45.774161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the length of each text\ntext_lengths = [len(text.split()) for text in df[\"text3\"]]\n\n# Find the 95th quartile\nquartile_95 = np.percentile(text_lengths, 95)\n\nprint(f\"95th Quartile of Text Lengths: {quartile_95}\")","metadata":{"id":"AoxXbHBTmWe1","outputId":"af741b24-aa5a-4293-f9a1-2edce8ea3abe","execution":{"iopub.status.busy":"2023-06-30T22:17:45.776961Z","iopub.execute_input":"2023-06-30T22:17:45.779907Z","iopub.status.idle":"2023-06-30T22:17:45.793139Z","shell.execute_reply.started":"2023-06-30T22:17:45.779839Z","shell.execute_reply":"2023-06-30T22:17:45.792097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A histogram of the text lengths is plotted using Matplotlib and Seaborn libraries, visualizing the distribution of text lengths. The 95th quartile is marked with a red dashed line.","metadata":{"id":"zCCigpyEmN3h"}},{"cell_type":"code","source":"# Plotting the histogram\nplt.figure(figsize=(10, 6))\nplt.hist(text_lengths, bins=20, edgecolor='black')\nplt.xlabel('Word Length')\nplt.ylabel('Frequency')\nplt.title('Distribution of Text Lengths')\n\n# Adding a vertical line for the 95th quartile\nquartile_95 = np.percentile(text_lengths, 95)\nplt.axvline(x=quartile_95, color='red', linestyle='--', label='95th Quartile')\nplt.legend()\n\nplt.grid(True)\nplt.show()","metadata":{"id":"LVuyM4N4mWe2","outputId":"bc0aa256-8878-4d6f-fa51-18964ffd98e9","execution":{"iopub.status.busy":"2023-06-30T22:17:45.795009Z","iopub.execute_input":"2023-06-30T22:17:45.795394Z","iopub.status.idle":"2023-06-30T22:17:46.176405Z","shell.execute_reply.started":"2023-06-30T22:17:45.795359Z","shell.execute_reply":"2023-06-30T22:17:46.175425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Descriptive statistics of the text lengths are displayed using the describe method of the DataFrame 'df.text_length'.","metadata":{"id":"NWxw8B2hmSlG"}},{"cell_type":"code","source":"df.text_length.describe()","metadata":{"id":"MR1QVdrOmWe2","outputId":"bc96c4cf-65ee-4e4d-f3da-cecb26dea6f3","execution":{"iopub.status.busy":"2023-06-30T22:17:46.177876Z","iopub.execute_input":"2023-06-30T22:17:46.178325Z","iopub.status.idle":"2023-06-30T22:17:46.191522Z","shell.execute_reply.started":"2023-06-30T22:17:46.178284Z","shell.execute_reply":"2023-06-30T22:17:46.189951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize text with less than 10 words","metadata":{"id":"AbeFS9M4mWe3"}},{"cell_type":"markdown","source":"A count plot is generated to visualize the distribution of texts with less than 10 words, filtering the data based on the 'text_length' column.","metadata":{"id":"sNvmoX1gmURp"}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(7,5))\nax = sns.countplot(x='text_length', data=df[df['text_length']<10], palette='mako')\nplt.title('Training text with less than 10 words')\nplt.yticks([])\nax.bar_label(ax.containers[0])\nplt.ylabel('Count')\nplt.xlabel('')\nplt.show()\n","metadata":{"id":"r1T4DlTDmWe3","outputId":"ed502163-21cd-4d2b-f075-a738212e32e3","execution":{"iopub.status.busy":"2023-06-30T22:17:46.193925Z","iopub.execute_input":"2023-06-30T22:17:46.194544Z","iopub.status.idle":"2023-06-30T22:17:46.439941Z","shell.execute_reply.started":"2023-06-30T22:17:46.194512Z","shell.execute_reply":"2023-06-30T22:17:46.438955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A subset of the DataFrame 'df' is created, including only the rows where the text length is less than 2.","metadata":{"id":"srgMFHd2mXZa"}},{"cell_type":"code","source":"data_head=df[df['text_length']<2]\ndata_head.head(30)","metadata":{"id":"643CMQDCmWe3","outputId":"0eb88204-ba06-42f1-964f-4bb3a5566dab","execution":{"iopub.status.busy":"2023-06-30T22:17:46.441358Z","iopub.execute_input":"2023-06-30T22:17:46.442273Z","iopub.status.idle":"2023-06-30T22:17:46.470775Z","shell.execute_reply.started":"2023-06-30T22:17:46.442238Z","shell.execute_reply":"2023-06-30T22:17:46.469894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Remove rows**\n\nAs can be seen, rows below word length of 2 either are empty rows or don't carry too much insight. Therefore, rows with word length below 2 are dropped from the DataFrame 'df'.","metadata":{"id":"kvnbFfSkmWe4"}},{"cell_type":"code","source":"df = df[df['text_length'] >= 2]","metadata":{"id":"l2cz79ZlmWe4","execution":{"iopub.status.busy":"2023-06-30T22:17:46.472286Z","iopub.execute_input":"2023-06-30T22:17:46.472608Z","iopub.status.idle":"2023-06-30T22:17:46.4807Z","shell.execute_reply.started":"2023-06-30T22:17:46.472578Z","shell.execute_reply":"2023-06-30T22:17:46.479996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Drop columns and shuffle","metadata":{"id":"T521UMd5mWe4"}},{"cell_type":"markdown","source":"Columns 'text', 'text1', and 'text2' are dropped from the DataFrame 'df'.","metadata":{"id":"wywcvN8snCti"}},{"cell_type":"code","source":"df = df.drop(['text', 'text1', 'text2'], axis=1)","metadata":{"id":"6Gwv95KBmWe5","execution":{"iopub.status.busy":"2023-06-30T22:17:46.481926Z","iopub.execute_input":"2023-06-30T22:17:46.482527Z","iopub.status.idle":"2023-06-30T22:17:46.489894Z","shell.execute_reply.started":"2023-06-30T22:17:46.482495Z","shell.execute_reply":"2023-06-30T22:17:46.488764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The training dataframe 'df' is shuffled randomly to ensure a more balanced distribution of labels.","metadata":{"id":"5jHmQkyMnESh"}},{"cell_type":"code","source":"# Shuffle training dataframe\ndf = df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\ndf.head()","metadata":{"id":"iUAADk0GmWe5","outputId":"9b1e86d6-d9b9-4a0f-f2bb-b506d1d7b3f8","execution":{"iopub.status.busy":"2023-06-30T22:17:46.491172Z","iopub.execute_input":"2023-06-30T22:17:46.491728Z","iopub.status.idle":"2023-06-30T22:17:46.507526Z","shell.execute_reply.started":"2023-06-30T22:17:46.491692Z","shell.execute_reply":"2023-06-30T22:17:46.505925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.label.value_counts()","metadata":{"id":"6ZaDdLPcmWe5","outputId":"6ae67be6-e566-412d-9185-077fecc459f4","execution":{"iopub.status.busy":"2023-06-30T22:17:46.508905Z","iopub.execute_input":"2023-06-30T22:17:46.509341Z","iopub.status.idle":"2023-06-30T22:17:46.519392Z","shell.execute_reply.started":"2023-06-30T22:17:46.50931Z","shell.execute_reply":"2023-06-30T22:17:46.518188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Recategorise Labels","metadata":{"id":"qOBvOjCKmWe6"}},{"cell_type":"markdown","source":"Label encoding is applied to the 'label' column of the DataFrame 'df', converting categorical labels into numerical representations. A DataFrame 'dr' is then created to display the original labels and their corresponding encoded values.","metadata":{"id":"DuQu-0uZnHOC"}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Define the encoder\nle = LabelEncoder()\n\n# Apply label encoding\ndf['label_le'] = le.fit_transform(df['label'])\n\n# Define data\ndata = {\n    'Label': le.classes_,\n    'Label Encoded': le.transform(le.classes_)\n}\n\n# Create DataFrame\ndr = pd.DataFrame(data)\ndr","metadata":{"id":"W0ftBHaKFIsL","outputId":"98939788-114e-494c-a9be-29aea51e1d14","execution":{"iopub.status.busy":"2023-06-30T22:17:46.520788Z","iopub.execute_input":"2023-06-30T22:17:46.521199Z","iopub.status.idle":"2023-06-30T22:17:46.536456Z","shell.execute_reply.started":"2023-06-30T22:17:46.521164Z","shell.execute_reply":"2023-06-30T22:17:46.535305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The 'Label' column of the DataFrame 'dr' is converted into a list, 'class_names', for further use in classification tasks.","metadata":{"id":"DG-n1CTsnOks"}},{"cell_type":"code","source":"class_names=dr.Label.tolist()\nclass_names","metadata":{"id":"SwjkQnJXFIsM","outputId":"5932eb1b-b778-42bf-a48d-d88a90b8b72e","execution":{"iopub.status.busy":"2023-06-30T22:17:46.538675Z","iopub.execute_input":"2023-06-30T22:17:46.539015Z","iopub.status.idle":"2023-06-30T22:17:46.550015Z","shell.execute_reply.started":"2023-06-30T22:17:46.538981Z","shell.execute_reply":"2023-06-30T22:17:46.548986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Balancing**","metadata":{"id":"kifdg-MUmWe8"}},{"cell_type":"markdown","source":"The following code shows the process of oversampling the data using RandomOverSampler from the imbalanced-learn library. It resamples the data to balance the classes by generating synthetic samples from the minority class.","metadata":{"id":"qkjDHj6lzbvW"}},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler()\ntrain_x, train_y = ros.fit_resample(np.array(df['text3']).reshape(-1, 1), np.array(df['label_le']).reshape(-1, 1));\ntrain_os = pd.DataFrame(list(zip([x[0] for x in train_x], train_y)), columns = ['text3', 'label_le']);","metadata":{"id":"8QnyLQcCmWe8","execution":{"iopub.status.busy":"2023-06-30T22:17:46.551329Z","iopub.execute_input":"2023-06-30T22:17:46.552073Z","iopub.status.idle":"2023-06-30T22:17:46.610463Z","shell.execute_reply.started":"2023-06-30T22:17:46.551913Z","shell.execute_reply":"2023-06-30T22:17:46.609613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_os.head()","metadata":{"id":"l8NaL7mImWe8","execution":{"iopub.status.busy":"2023-06-30T22:17:46.611938Z","iopub.execute_input":"2023-06-30T22:17:46.612289Z","iopub.status.idle":"2023-06-30T22:17:46.62118Z","shell.execute_reply.started":"2023-06-30T22:17:46.612258Z","shell.execute_reply":"2023-06-30T22:17:46.620224Z"},"outputId":"7fe563b1-5393-410c-9967-09749288cc41","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_os['label_le'].value_counts()","metadata":{"id":"tUCie69nmWe9","execution":{"iopub.status.busy":"2023-06-30T22:17:46.622465Z","iopub.execute_input":"2023-06-30T22:17:46.623434Z","iopub.status.idle":"2023-06-30T22:17:46.634457Z","shell.execute_reply.started":"2023-06-30T22:17:46.623401Z","shell.execute_reply":"2023-06-30T22:17:46.633289Z"},"outputId":"32c20c20-a980-46c6-d86c-f99f0a016e26","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffle training dataframe\ntrain_os = train_os.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\ntrain_os.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T22:17:46.636379Z","iopub.execute_input":"2023-06-30T22:17:46.636953Z","iopub.status.idle":"2023-06-30T22:17:46.65091Z","shell.execute_reply.started":"2023-06-30T22:17:46.636911Z","shell.execute_reply":"2023-06-30T22:17:46.649988Z"},"id":"m6RGGsMPmd-W","outputId":"3cbc1e6d-1795-4487-af73-71fcbdf688d2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_os['text3'].to_numpy()\ny = train_os['label_le'].to_numpy()","metadata":{"id":"KLI1qgmnmWe9","execution":{"iopub.status.busy":"2023-06-30T22:17:46.652597Z","iopub.execute_input":"2023-06-30T22:17:46.652931Z","iopub.status.idle":"2023-06-30T22:17:46.657701Z","shell.execute_reply.started":"2023-06-30T22:17:46.6529Z","shell.execute_reply":"2023-06-30T22:17:46.656607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y","metadata":{"execution":{"iopub.status.busy":"2023-06-30T22:17:46.659518Z","iopub.execute_input":"2023-06-30T22:17:46.660256Z","iopub.status.idle":"2023-06-30T22:17:46.6712Z","shell.execute_reply.started":"2023-06-30T22:17:46.660222Z","shell.execute_reply":"2023-06-30T22:17:46.670294Z"},"id":"zTt7qLyemd-W","outputId":"bc215be5-b610-4424-c384-104f04862ef5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The oversampled data is then split into training and validation sets using the train_val_split function, which takes the sentences and labels along with a training split ratio as input and returns the split sets.","metadata":{"id":"7FURS0RCzf8j"}},{"cell_type":"code","source":"def train_val_split(sentences, labels, training_split):\n    \"\"\"\n    Splits the dataset into training and validation sets\n\n    Args:\n        sentences (list of string): lower-cased sentences without stopwords\n        labels (list of string): list of labels\n        training split (float): proportion of the dataset to convert to include in the train set\n\n    Returns:\n        train_sentences, validation_sentences, train_labels, validation_labels - lists containing the data splits\n    \"\"\"\n\n    # Compute the number of sentences that will be used for training (should be an integer)\n    train_size = int(len(sentences) * training_split)\n\n    # Split the sentences and labels into train/validation splits\n    train_sentences = sentences[:train_size]\n    train_labels = labels[:train_size]\n\n    validation_sentences = sentences[train_size:]\n    validation_labels = labels[train_size:]\n\n    return train_sentences, validation_sentences, train_labels, validation_labels","metadata":{"id":"bHXNR6yejL2V","execution":{"iopub.status.busy":"2023-06-30T22:17:46.672827Z","iopub.execute_input":"2023-06-30T22:17:46.673233Z","iopub.status.idle":"2023-06-30T22:17:46.682955Z","shell.execute_reply.started":"2023-06-30T22:17:46.673198Z","shell.execute_reply":"2023-06-30T22:17:46.681962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test your function\nX_train, X_valid, y_train, y_valid = train_val_split(X, y, 0.8)\n\nprint(f\"There are {len(X_train)} sentences for training.\\n\")\nprint(f\"There are {len(y_train)} labels for training.\\n\")\nprint(f\"There are {len(X_valid)} sentences for validation.\\n\")\nprint(f\"There are {len(y_valid)} labels for validation.\")","metadata":{"id":"R8XWZoQmjL2W","outputId":"f367e8d8-cae8-42ba-c0ef-70d2d5f29e02","execution":{"iopub.status.busy":"2023-06-30T22:17:46.684761Z","iopub.execute_input":"2023-06-30T22:17:46.685443Z","iopub.status.idle":"2023-06-30T22:17:46.698023Z","shell.execute_reply.started":"2023-06-30T22:17:46.685417Z","shell.execute_reply":"2023-06-30T22:17:46.696787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the shape\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","metadata":{"id":"RDuXlKf3mWe9","outputId":"d6b4c1ef-af94-40c2-c73d-9f5ce7e5623d","execution":{"iopub.status.busy":"2023-06-30T22:17:46.699534Z","iopub.execute_input":"2023-06-30T22:17:46.700018Z","iopub.status.idle":"2023-06-30T22:17:46.711494Z","shell.execute_reply.started":"2023-06-30T22:17:46.699982Z","shell.execute_reply":"2023-06-30T22:17:46.710747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the lengths\nlen(X_train), len(X_valid), len(y_train), len(y_valid)","metadata":{"id":"a-_wUHyumWe-","outputId":"e3291101-de80-4aba-eade-72f0d6461c70","execution":{"iopub.status.busy":"2023-06-30T22:17:46.712911Z","iopub.execute_input":"2023-06-30T22:17:46.713657Z","iopub.status.idle":"2023-06-30T22:17:46.723942Z","shell.execute_reply.started":"2023-06-30T22:17:46.713624Z","shell.execute_reply":"2023-06-30T22:17:46.723306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[:5], X_valid[:5]","metadata":{"id":"qiaaosnJmWe-","outputId":"a2919590-6283-4286-f670-ab5f145d1ab7","execution":{"iopub.status.busy":"2023-06-30T22:17:46.726509Z","iopub.execute_input":"2023-06-30T22:17:46.727136Z","iopub.status.idle":"2023-06-30T22:17:46.736158Z","shell.execute_reply.started":"2023-06-30T22:17:46.727087Z","shell.execute_reply":"2023-06-30T22:17:46.735103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[:5], y_valid[:5]","metadata":{"id":"-VauP6mImWe_","outputId":"9784329f-160a-4c7e-ecee-7644d99ee62a","execution":{"iopub.status.busy":"2023-06-30T22:17:46.738019Z","iopub.execute_input":"2023-06-30T22:17:46.738409Z","iopub.status.idle":"2023-06-30T22:17:46.748822Z","shell.execute_reply.started":"2023-06-30T22:17:46.738379Z","shell.execute_reply":"2023-06-30T22:17:46.747699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The train and valid texts are copied to be used later.","metadata":{"id":"hs6_yLyI0rGT"}},{"cell_type":"code","source":"X_train_tx=X_train.copy()\nX_valid_tx=X_valid.copy()","metadata":{"id":"csMS6GbCFIsU","execution":{"iopub.status.busy":"2023-06-30T22:17:46.750574Z","iopub.execute_input":"2023-06-30T22:17:46.750909Z","iopub.status.idle":"2023-06-30T22:17:46.759813Z","shell.execute_reply.started":"2023-06-30T22:17:46.750878Z","shell.execute_reply":"2023-06-30T22:17:46.758948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_tx[:5], X_valid_tx[:5]","metadata":{"id":"cL3G9dq2FIsU","outputId":"9a86b45d-fc8a-4b6a-bd82-228eac87edec","execution":{"iopub.status.busy":"2023-06-30T22:17:46.76151Z","iopub.execute_input":"2023-06-30T22:17:46.761843Z","iopub.status.idle":"2023-06-30T22:17:46.774167Z","shell.execute_reply.started":"2023-06-30T22:17:46.761802Z","shell.execute_reply":"2023-06-30T22:17:46.773269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model 0: Baseline**","metadata":{"id":"AQ_Yz8CMjL2Y"}},{"cell_type":"markdown","source":"Next, a simple baseline model is defined using a TF-IDF vectorizer and a multinomial Naive Bayes classifier within a Scikit-Learn pipeline. The model is then trained on the training data.","metadata":{"id":"jlpLODw90mme"}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\n\n# Create tokenization and modelling pipeline\nmodel_0 = Pipeline([\n                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n                    (\"clf\", MultinomialNB()) # model the text\n])\n\n# Now fit the model\nmodel_0.fit(X_train_tx, y_train)","metadata":{"id":"Xo9CQrOwjL2Z","outputId":"04685e24-94fe-42ca-883c-076529ad8ca0","execution":{"iopub.status.busy":"2023-06-30T22:17:46.77609Z","iopub.execute_input":"2023-06-30T22:17:46.77647Z","iopub.status.idle":"2023-06-30T22:17:46.949382Z","shell.execute_reply.started":"2023-06-30T22:17:46.776435Z","shell.execute_reply":"2023-06-30T22:17:46.94843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The accuracy of the baseline model is then evaluated on the validation data and printed out.","metadata":{"id":"FveOpvCN05RD"}},{"cell_type":"code","source":"baseline_score = model_0.score(X_valid_tx, y_valid)\nprint(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")","metadata":{"id":"7HwPMhAJjL2Z","outputId":"c367cb14-d254-4da3-d764-00b9a15806c4","execution":{"iopub.status.busy":"2023-06-30T22:17:46.950804Z","iopub.execute_input":"2023-06-30T22:17:46.952301Z","iopub.status.idle":"2023-06-30T22:17:46.994008Z","shell.execute_reply.started":"2023-06-30T22:17:46.952267Z","shell.execute_reply":"2023-06-30T22:17:46.993103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, predictions are made using the baseline model on the validation sentences.","metadata":{"id":"uOEhcMDb0xrM"}},{"cell_type":"code","source":"# Make predictions\nbaseline_preds = model_0.predict(X_valid_tx)\nbaseline_preds[:20]","metadata":{"id":"Gi9Wv90PjL2Z","outputId":"3dc730de-a00f-4bd1-f035-7e99120b36b5","execution":{"iopub.status.busy":"2023-06-30T22:17:46.995439Z","iopub.execute_input":"2023-06-30T22:17:46.995761Z","iopub.status.idle":"2023-06-30T22:17:47.038208Z","shell.execute_reply.started":"2023-06-30T22:17:46.995737Z","shell.execute_reply":"2023-06-30T22:17:47.037119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then a function calculate_results is defined to calculate the accuracy, precision, recall, and F1 score of the model's predictions.","metadata":{"id":"AO1PiuX200p2"}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef calculate_results(y_true, y_pred, loss=None):\n    \"\"\"\n    Calculates model accuracy, precision, recall, f1-score, and loss of a binary classification model.\n\n    Args:\n    -----\n    y_true: true labels in the form of a 1D array\n    y_pred: predicted labels in the form of a 1D array\n    loss: (optional) loss value of the model, default is None\n\n    Returns a dictionary of accuracy, precision, recall, f1-score, and loss.\n    \"\"\"\n    # Calculate model accuracy\n    model_accuracy = accuracy_score(y_true, y_pred) * 100\n    # Calculate model precision, recall, and f1 score using \"weighted\" average\n    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n    model_results = {\n        \"accuracy\": model_accuracy,\n        \"precision\": model_precision,\n        \"recall\": model_recall,\n        \"f1\": model_f1,\n        \"loss\": loss\n    }\n    return model_results\n","metadata":{"id":"PS9s8D0yjL2Z","execution":{"iopub.status.busy":"2023-06-30T22:17:47.040649Z","iopub.execute_input":"2023-06-30T22:17:47.04124Z","iopub.status.idle":"2023-06-30T22:17:47.048345Z","shell.execute_reply.started":"2023-06-30T22:17:47.041213Z","shell.execute_reply":"2023-06-30T22:17:47.047188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The function is used to calculate the results of the baseline model and these are printed out.","metadata":{"id":"wF0Kv4YX0_cK"}},{"cell_type":"code","source":"# Get baseline results\nbaseline_results = calculate_results(y_true=y_valid,\n                                     y_pred=baseline_preds)\nbaseline_results","metadata":{"id":"biCoey7-jL2a","outputId":"6ee8dfb4-88cc-464f-f46f-6a91c58b8535","execution":{"iopub.status.busy":"2023-06-30T22:17:47.04994Z","iopub.execute_input":"2023-06-30T22:17:47.050292Z","iopub.status.idle":"2023-06-30T22:17:47.065179Z","shell.execute_reply.started":"2023-06-30T22:17:47.050261Z","shell.execute_reply":"2023-06-30T22:17:47.064161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A helper function compare_baseline_to_new_results is defined to compare the results of the baseline model to a new model. It does this by calculating the difference between the baseline and new results for each metric.","metadata":{"id":"ffTsfQ_X1BSu"}},{"cell_type":"code","source":"# Create a helper function to compare our baseline results to new model results\ndef compare_baseline_to_new_results(baseline_results, new_model_results):\n  for key, value in baseline_results.items():\n    if key != 'loss': # Do not compare if the key is 'loss'\n      print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")","metadata":{"id":"w_CVaFc3jL2a","execution":{"iopub.status.busy":"2023-06-30T22:27:26.02511Z","iopub.execute_input":"2023-06-30T22:27:26.025558Z","iopub.status.idle":"2023-06-30T22:27:26.03438Z","shell.execute_reply.started":"2023-06-30T22:27:26.025527Z","shell.execute_reply":"2023-06-30T22:27:26.033363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Text Length in Training Data**\n\nNext, the code analyzes the text length in the training data. It calculates the average number of tokens (words) in the training texts, finds the 98th percentile of text lengths, and plots a histogram to visualize the distribution of text lengths.","metadata":{"id":"_dQ3Gu1FmWe_"}},{"cell_type":"code","source":"# Find average number of tokens (words) in training texts\nround(sum([len(i.split()) for i in X_train])/len(X_train))","metadata":{"id":"xIaVStiZmWe_","outputId":"da1b7a18-6730-4bc5-9b72-e7d599d8c728","execution":{"iopub.status.busy":"2023-06-30T22:17:47.076569Z","iopub.execute_input":"2023-06-30T22:17:47.077601Z","iopub.status.idle":"2023-06-30T22:17:47.099077Z","shell.execute_reply.started":"2023-06-30T22:17:47.077575Z","shell.execute_reply":"2023-06-30T22:17:47.09808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the length of each text in X_train\ntext_lengths = [len(text.split()) for text in X_train]\n\n# Find the 98th percentile\npercentile_98 = np.percentile(text_lengths, 98)\n\nprint(f\"98th Percentile of Text Lengths: {percentile_98}\")","metadata":{"id":"2VmbCCEkmWe_","outputId":"bd93f6dd-b58e-4aed-dabb-c8874834c179","execution":{"iopub.status.busy":"2023-06-30T22:17:47.100445Z","iopub.execute_input":"2023-06-30T22:17:47.100771Z","iopub.status.idle":"2023-06-30T22:17:47.119483Z","shell.execute_reply.started":"2023-06-30T22:17:47.100741Z","shell.execute_reply":"2023-06-30T22:17:47.118558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the histogram\nplt.figure(figsize=(10, 6))\nplt.hist(text_lengths, bins=20, edgecolor='black')\nplt.xlabel('Word Length')\nplt.ylabel('Frequency')\nplt.title('Distribution of text Lengths')\n\n# Adding a vertical line for the 98th quartile\npercentile_98 = np.percentile(text_lengths, 98)\nplt.axvline(x=percentile_98, color='red', linestyle='--', label='98th Quartile')\nplt.legend()\n\nplt.grid(True)\nplt.show()","metadata":{"id":"EYU2LuXWmWfA","outputId":"e96daa29-49dc-40b7-dafb-ec8293acb710","execution":{"iopub.status.busy":"2023-06-30T22:17:47.122677Z","iopub.execute_input":"2023-06-30T22:17:47.122938Z","iopub.status.idle":"2023-06-30T22:17:47.500081Z","shell.execute_reply.started":"2023-06-30T22:17:47.122915Z","shell.execute_reply":"2023-06-30T22:17:47.499004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_text_length = max(text_lengths)\nprint(f\"Maximum Text Length: {max_text_length}\")","metadata":{"id":"jFuU3GBYmWfA","outputId":"5c7f2006-0e73-4fc0-b107-aab19fe32ade","execution":{"iopub.status.busy":"2023-06-30T22:17:47.50148Z","iopub.execute_input":"2023-06-30T22:17:47.501931Z","iopub.status.idle":"2023-06-30T22:17:47.507988Z","shell.execute_reply.started":"2023-06-30T22:17:47.501897Z","shell.execute_reply":"2023-06-30T22:17:47.506853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ****Text Tokenization and Sequence Padding","metadata":{"id":"8JT2YbzmeSBj"}},{"cell_type":"markdown","source":"# The code proceeds by tokenizing the training and validation sentences using the `fit_tokenizer` function, which generates a tokenizer and adapts it to the training sentences.","metadata":{"id":"KeBf5Gi_zzrr"}},{"cell_type":"code","source":"# FUNCTION: fit_tokenizer\ndef fit_tokenizer(train_sentences, num_words, oov_token):\n    \"\"\"\n    Instantiates the Tokenizer class on the training sentences\n\n    Args:\n        train_sentences (list of string): lower-cased sentences without stopwords to be used for training\n        num_words (int) - number of words to keep when tokenizing\n        oov_token (string) - symbol for the out-of-vocabulary token\n\n    Returns:\n        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n    \"\"\"\n\n    # Instantiate the Tokenizer class, passing in the correct values for num_words and oov_token\n    tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n\n    # Fit the tokenizer to the training sentences\n    tokenizer.fit_on_texts(train_sentences)\n\n    return tokenizer","metadata":{"id":"AqKPZpoSeb0j","execution":{"iopub.status.busy":"2023-06-30T22:17:47.509631Z","iopub.execute_input":"2023-06-30T22:17:47.510291Z","iopub.status.idle":"2023-06-30T22:17:47.519667Z","shell.execute_reply.started":"2023-06-30T22:17:47.510256Z","shell.execute_reply":"2023-06-30T22:17:47.518765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OOV_TOKEN = \"<OOV>\"","metadata":{"id":"B7ekVRwhjL2c","execution":{"iopub.status.busy":"2023-06-30T22:17:47.521632Z","iopub.execute_input":"2023-06-30T22:17:47.522429Z","iopub.status.idle":"2023-06-30T22:17:47.531346Z","shell.execute_reply.started":"2023-06-30T22:17:47.522397Z","shell.execute_reply":"2023-06-30T22:17:47.53041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_WORDS = 7000","metadata":{"id":"_aQ0N5YpFIsZ","execution":{"iopub.status.busy":"2023-06-30T22:17:47.534424Z","iopub.execute_input":"2023-06-30T22:17:47.53469Z","iopub.status.idle":"2023-06-30T22:17:47.545891Z","shell.execute_reply.started":"2023-06-30T22:17:47.534667Z","shell.execute_reply":"2023-06-30T22:17:47.544877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Subsequently, this function is employed to train a tokenizer on the training sentences, extracting the word index. The word index acts as a dictionary that associates words with their respective numerical identifiers.","metadata":{"id":"I6mo01d20a7P"}},{"cell_type":"code","source":"# Test your function\ntokenizer = fit_tokenizer(X_train, NUM_WORDS, OOV_TOKEN)\nword_index = tokenizer.word_index\n\nprint(f\"Vocabulary contains {len(word_index)} words\\n\")\nprint(\"<OOV> token included in vocabulary\" if \"<OOV>\" in word_index else \"<OOV> token NOT included in vocabulary\")","metadata":{"id":"fXEdye0BedEf","outputId":"b0746b30-efe9-4e5c-d7d8-9ece0445958d","execution":{"iopub.status.busy":"2023-06-30T22:17:47.548602Z","iopub.execute_input":"2023-06-30T22:17:47.548895Z","iopub.status.idle":"2023-06-30T22:17:47.712778Z","shell.execute_reply.started":"2023-06-30T22:17:47.54887Z","shell.execute_reply":"2023-06-30T22:17:47.711735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_vocab_length=NUM_WORDS\n# max_vocab_length=len(word_index)","metadata":{"id":"1QzKciB-jL2c","execution":{"iopub.status.busy":"2023-06-30T22:17:47.714373Z","iopub.execute_input":"2023-06-30T22:17:47.714751Z","iopub.status.idle":"2023-06-30T22:17:47.719547Z","shell.execute_reply.started":"2023-06-30T22:17:47.714717Z","shell.execute_reply":"2023-06-30T22:17:47.718411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# In the subsequent code block, a function named `seq_and_pad` is introduced. This function's purpose is to transform sentences into sequences of integers (tokens) and then pad these sequences to ensure they all share the same length.","metadata":{"id":"T5oElPUG0csz"}},{"cell_type":"code","source":"# FUNCTION: seq_and_pad\ndef seq_and_pad(sentences, tokenizer, padding, maxlen):\n    \"\"\"\n    Generates an array of token sequences and pads them to the same length\n\n    Args:\n        sentences (list of string): list of sentences to tokenize and pad\n        tokenizer (object): Tokenizer instance containing the word-index dictionary\n        padding (string): type of padding to use\n        maxlen (int): maximum length of the token sequence\n\n    Returns:\n        padded_sequences (array of int): tokenized sentences padded to the same length\n    \"\"\"\n\n    # Convert sentences to sequences\n    sequences = tokenizer.texts_to_sequences(sentences)\n\n    # Pad the sequences using the correct padding and maxlen\n    padded_sequences = pad_sequences(sequences, padding=padding, maxlen=maxlen)\n\n    return padded_sequences","metadata":{"id":"AFqxiah8eeWe","execution":{"iopub.status.busy":"2023-06-30T22:17:47.72134Z","iopub.execute_input":"2023-06-30T22:17:47.721676Z","iopub.status.idle":"2023-06-30T22:17:47.731144Z","shell.execute_reply.started":"2023-06-30T22:17:47.721645Z","shell.execute_reply":"2023-06-30T22:17:47.730283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PADDING = 'post'\nmax_length=int(percentile_98)","metadata":{"id":"nA_XkZiujL2d","execution":{"iopub.status.busy":"2023-06-30T22:17:47.732916Z","iopub.execute_input":"2023-06-30T22:17:47.73331Z","iopub.status.idle":"2023-06-30T22:17:47.742878Z","shell.execute_reply.started":"2023-06-30T22:17:47.733274Z","shell.execute_reply":"2023-06-30T22:17:47.741856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Next, this function is utilized to process the training and validation sentences, rendering them suitable for model input. The code prints out the shape of the resulting sequences as a confirmation of the data preparation.","metadata":{"id":"V9kcWZcF0gEp"}},{"cell_type":"code","source":"# Test your function\nX_train = seq_and_pad(X_train, tokenizer, PADDING, max_length)\nX_valid = seq_and_pad(X_valid, tokenizer, PADDING, max_length)\n\nprint(f\"Padded training sequences have shape: {X_train.shape}\\n\")\nprint(f\"Padded validation sequences have shape: {X_valid.shape}\")","metadata":{"id":"M2IWImVMefez","outputId":"ef0e74fc-a167-4e2c-a527-428a768d0ee6","execution":{"iopub.status.busy":"2023-06-30T22:17:47.764967Z","iopub.execute_input":"2023-06-30T22:17:47.765248Z","iopub.status.idle":"2023-06-30T22:17:47.96537Z","shell.execute_reply.started":"2023-06-30T22:17:47.765224Z","shell.execute_reply":"2023-06-30T22:17:47.964235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[:5], X_valid[:5]","metadata":{"id":"gthydjf4jL2f","outputId":"fb7f196f-3f22-4ec1-87c9-f77a77350940","execution":{"iopub.status.busy":"2023-06-30T22:17:47.967299Z","iopub.execute_input":"2023-06-30T22:17:47.967716Z","iopub.status.idle":"2023-06-30T22:17:47.977155Z","shell.execute_reply.started":"2023-06-30T22:17:47.967682Z","shell.execute_reply":"2023-06-30T22:17:47.974904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[:10], y_valid[:10]","metadata":{"id":"2_wY2Njmeqy4","outputId":"48e237f4-eeb6-4b07-e2db-17e79242976a","execution":{"iopub.status.busy":"2023-06-30T22:17:47.979084Z","iopub.execute_input":"2023-06-30T22:17:47.979912Z","iopub.status.idle":"2023-06-30T22:17:47.991411Z","shell.execute_reply.started":"2023-06-30T22:17:47.979875Z","shell.execute_reply":"2023-06-30T22:17:47.990394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Callbacks**","metadata":{"id":"9dkfQzqbq6QS"}},{"cell_type":"markdown","source":"# Callbacks are introduced, among which is the ModelCheckpoint callback. This callback is configured to save the best model during training, determined by the validation loss.","metadata":{"id":"GrsiNHPyz2IJ"}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n\ndef create_checkpoint_callback(checkpoint_path):\n    \"\"\"\n    This function returns a ModelCheckpoint callback that saves the model's weights only when the\n    validation accuracy improves.\n\n    Parameters:\n    checkpoint_path (str): The filepath where the model weights should be saved.\n\n    Returns:\n    ModelCheckpoint callback\n    \"\"\"\n    checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path,\n                                          monitor='val_loss',\n                                          mode='min',\n                                          save_best_only=True,\n                                          verbose=1)\n    return checkpoint_callback","metadata":{"id":"xAlMxK33q8KG","execution":{"iopub.status.busy":"2023-06-30T22:17:47.993096Z","iopub.execute_input":"2023-06-30T22:17:47.9936Z","iopub.status.idle":"2023-06-30T22:17:48.000967Z","shell.execute_reply.started":"2023-06-30T22:17:47.993566Z","shell.execute_reply":"2023-06-30T22:17:48.000054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Embedding layer","metadata":{"id":"OuVr94DJmWfC"}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import layers","metadata":{"id":"AZKAX9G3mWfC","execution":{"iopub.status.busy":"2023-06-30T22:17:48.002372Z","iopub.execute_input":"2023-06-30T22:17:48.002833Z","iopub.status.idle":"2023-06-30T22:17:48.015511Z","shell.execute_reply.started":"2023-06-30T22:17:48.002798Z","shell.execute_reply":"2023-06-30T22:17:48.014557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length","metadata":{"id":"fn5ciInsFIsc","outputId":"4f78814f-94b8-44b7-e92b-fe009d3bbe27","execution":{"iopub.status.busy":"2023-06-30T22:17:48.017292Z","iopub.execute_input":"2023-06-30T22:17:48.017717Z","iopub.status.idle":"2023-06-30T22:17:48.028326Z","shell.execute_reply.started":"2023-06-30T22:17:48.017685Z","shell.execute_reply":"2023-06-30T22:17:48.027173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_vocab_length","metadata":{"id":"VMic_GOnFIsd","outputId":"39b817ed-c494-463b-f78d-232b57f354bf","execution":{"iopub.status.busy":"2023-06-30T22:17:48.029836Z","iopub.execute_input":"2023-06-30T22:17:48.03031Z","iopub.status.idle":"2023-06-30T22:17:48.040787Z","shell.execute_reply.started":"2023-06-30T22:17:48.030279Z","shell.execute_reply":"2023-06-30T22:17:48.040101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this part of the code, an embedding layer is established to convert input words into fixed-size dense vectors. This transformation captures semantic relationships between words. Additionally, `tf.random.set_seed(42)` is employed to ensure reproducibility by controlling randomness in the process.","metadata":{"id":"T0ln2MJa1My3"}},{"cell_type":"code","source":"# from tensorflow.keras import layers\n\ntf.random.set_seed(42)\n\nembedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n                             output_dim=300, # set size of embedding vector\n                             embeddings_initializer=\"uniform\", # default, intialize randomly\n                             input_length=max_length, # how long is each input\n                             name=\"embedding_1\")\n\nembedding","metadata":{"id":"tAKE4J_2mWfC","outputId":"eee58549-0847-410c-a6a0-cf0f9e7cac5a","execution":{"iopub.status.busy":"2023-06-30T22:17:48.042264Z","iopub.execute_input":"2023-06-30T22:17:48.043014Z","iopub.status.idle":"2023-06-30T22:17:48.265204Z","shell.execute_reply.started":"2023-06-30T22:17:48.042984Z","shell.execute_reply":"2023-06-30T22:17:48.264122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model: Simple Dense**","metadata":{"id":"03zwdEeBzqAM"}},{"cell_type":"code","source":"X_train.shape[1]","metadata":{"id":"A0dCnoR2nr7X","outputId":"34672b18-c893-4291-a549-fc3e08995c4a","execution":{"iopub.status.busy":"2023-06-30T22:17:48.267299Z","iopub.execute_input":"2023-06-30T22:17:48.267797Z","iopub.status.idle":"2023-06-30T22:17:48.278028Z","shell.execute_reply.started":"2023-06-30T22:17:48.267763Z","shell.execute_reply":"2023-06-30T22:17:48.276968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code block constructs our initial neural network model for text classification. The incorporation of the GlobalAveragePooling1D layer is instrumental in reducing the dimensionality of the input, enhancing model performance by condensing information.","metadata":{"id":"SwAuXHRM1PNH"}},{"cell_type":"code","source":"from tensorflow.keras import layers\n\ninputs = layers.Input(shape=(X_train.shape[1],), dtype=\"int32\")\nx = embedding(inputs)\nx = layers.GlobalAveragePooling1D()(x)\noutputs = layers.Dense(1, activation=\"sigmoid\")(x)\nmodel_dense = tf.keras.Model(inputs, outputs, name=\"model_dense\")","metadata":{"id":"5bJTY43_zy29","execution":{"iopub.status.busy":"2023-06-30T22:17:48.281383Z","iopub.execute_input":"2023-06-30T22:17:48.281646Z","iopub.status.idle":"2023-06-30T22:17:48.336552Z","shell.execute_reply.started":"2023-06-30T22:17:48.281623Z","shell.execute_reply":"2023-06-30T22:17:48.335641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code compiles the `model_dense` by specifying `binary_crossentropy` as the loss function, `Adam` as the optimizer, and `accuracy` as the evaluation metric. This configuration prepares the model for binary classification tasks, utilizing the Adam optimizer for training and assessing its performance by measuring the accuracy of its predictions.","metadata":{"id":"-LJtHoRp1apq"}},{"cell_type":"code","source":"# Compile model\nmodel_dense.compile(loss=\"binary_crossentropy\",\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=[\"accuracy\"])","metadata":{"id":"-13pxFEK0Hy9","execution":{"iopub.status.busy":"2023-06-30T22:17:48.33817Z","iopub.execute_input":"2023-06-30T22:17:48.338579Z","iopub.status.idle":"2023-06-30T22:17:48.354437Z","shell.execute_reply.started":"2023-06-30T22:17:48.338547Z","shell.execute_reply":"2023-06-30T22:17:48.353599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a summary of the model\nmodel_dense.summary()","metadata":{"id":"tykmVRQf0Il4","outputId":"ccdfeb3e-efdf-4435-b0d2-785e7024a9d1","execution":{"iopub.status.busy":"2023-06-30T22:17:48.357617Z","iopub.execute_input":"2023-06-30T22:17:48.357887Z","iopub.status.idle":"2023-06-30T22:17:48.377404Z","shell.execute_reply.started":"2023-06-30T22:17:48.357864Z","shell.execute_reply":"2023-06-30T22:17:48.376612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this step, an instance of the ModelCheckpoint callback is instantiated. This callback will be responsible for saving the best model during the training process based on certain criteria, such as validation loss.","metadata":{"id":"fGfrRuxF1ruI"}},{"cell_type":"code","source":"# Define the checkpoint path\ncheckpoint_path = \"best_model_dense\"\n\ncc = create_checkpoint_callback(checkpoint_path)","metadata":{"id":"s-VVjjW70kJP","execution":{"iopub.status.busy":"2023-06-30T22:17:48.378407Z","iopub.execute_input":"2023-06-30T22:17:48.378726Z","iopub.status.idle":"2023-06-30T22:17:48.383082Z","shell.execute_reply.started":"2023-06-30T22:17:48.378696Z","shell.execute_reply":"2023-06-30T22:17:48.382368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `model_dense` is trained using the training data (`X_train` and `y_train`) for 20 epochs. The validation data (`X_valid` and `y_valid`) is used for evaluation during training. The training progress is recorded in `model_dense_history`, and the defined callbacks (including the ModelCheckpoint callback) are applied throughout the training process.","metadata":{"id":"BCsaNCLZ1zAY"}},{"cell_type":"code","source":"# Fit the model\nmodel_dense_history = model_dense.fit(X_train,\n                              y_train,\n                              epochs=20,\n                              validation_data=(X_valid, y_valid),\n                              callbacks=[cc])","metadata":{"id":"Dssb1y0V0U8N","outputId":"56278d0f-3d7b-4f6e-fa6a-e88dcf09b901","execution":{"iopub.status.busy":"2023-06-30T22:17:48.384017Z","iopub.execute_input":"2023-06-30T22:17:48.384436Z","iopub.status.idle":"2023-06-30T22:19:10.955572Z","shell.execute_reply.started":"2023-06-30T22:17:48.384405Z","shell.execute_reply":"2023-06-30T22:19:10.954399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Upon completing the training process, the code generates plots that visualize the model's accuracy and loss over the course of multiple epochs. These plots provide insights into how the model's performance evolved during training.","metadata":{"id":"gqu-2iCg100f"}},{"cell_type":"code","source":"# Plot Utility\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n\n# Plot the accuracy and loss history\nplot_graphs(model_dense_history, 'accuracy')\nplot_graphs(model_dense_history, 'loss')","metadata":{"id":"Qx1kXeHIO4h8","outputId":"8c060e79-8ebe-40a0-e33b-bad331001962","execution":{"iopub.status.busy":"2023-06-30T22:19:10.958276Z","iopub.execute_input":"2023-06-30T22:19:10.958645Z","iopub.status.idle":"2023-06-30T22:19:11.512889Z","shell.execute_reply.started":"2023-06-30T22:19:10.958611Z","shell.execute_reply":"2023-06-30T22:19:11.511945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code loads the best model, which was determined based on the validation loss during the training process. This ensures that the model with the highest validation performance is used for further tasks or evaluations.","metadata":{"id":"WJyE-F8H13K_"}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the entire model\nmodel_dense = load_model(checkpoint_path)","metadata":{"id":"XzZ2Mdt6O7FQ","execution":{"iopub.status.busy":"2023-06-30T22:19:11.514292Z","iopub.execute_input":"2023-06-30T22:19:11.514706Z","iopub.status.idle":"2023-06-30T22:19:11.770059Z","shell.execute_reply.started":"2023-06-30T22:19:11.514668Z","shell.execute_reply":"2023-06-30T22:19:11.769073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code proceeds to evaluate the model's performance on the validation set. This assessment provides insights into how well the model generalizes to data it hasn't seen during training.","metadata":{"id":"8MC41GrS15RB"}},{"cell_type":"code","source":"# Check the results\nmodel_dense_ev = model_dense.evaluate(X_valid, y_valid)\nmodel_dense_loss = model_dense_ev[0]\nmodel_dense_loss","metadata":{"id":"55VSKVVWOrs1","outputId":"0b10226f-1bfd-4f3b-8928-fb31c5cfb164","execution":{"iopub.status.busy":"2023-06-30T22:19:11.772901Z","iopub.execute_input":"2023-06-30T22:19:11.773277Z","iopub.status.idle":"2023-06-30T22:19:12.075677Z","shell.execute_reply.started":"2023-06-30T22:19:11.773243Z","shell.execute_reply":"2023-06-30T22:19:12.074524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code predicts probabilities on the validation set and subsequently transforms these probabilities into class predictions. This step determines which class (e.g., binary classification labels) each data point belongs to based on the predicted probabilities.","metadata":{"id":"IS0S1BBs18_q"}},{"cell_type":"code","source":"# Make predictions (these come back in the form of probabilities)\nmodel_dense_pred_probs = model_dense.predict(X_valid)\nmodel_dense_pred_probs[:10] # only print out the first 10 prediction probabilities","metadata":{"id":"6WXZaobVOz5j","outputId":"5006a991-7c82-415f-bbce-ce7498c6b962","execution":{"iopub.status.busy":"2023-06-30T22:19:12.07893Z","iopub.execute_input":"2023-06-30T22:19:12.079982Z","iopub.status.idle":"2023-06-30T22:19:12.316129Z","shell.execute_reply.started":"2023-06-30T22:19:12.079942Z","shell.execute_reply":"2023-06-30T22:19:12.315075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert prediction probabilities to labels\nmodel_dense_preds = tf.squeeze(tf.round(model_dense_pred_probs))\nmodel_dense_preds[:10]","metadata":{"id":"byq45DVpaT38","outputId":"76c01176-f2c8-4789-a9d9-30d440ff2ecd","execution":{"iopub.status.busy":"2023-06-30T22:19:12.317558Z","iopub.execute_input":"2023-06-30T22:19:12.317896Z","iopub.status.idle":"2023-06-30T22:19:12.332737Z","shell.execute_reply.started":"2023-06-30T22:19:12.317869Z","shell.execute_reply":"2023-06-30T22:19:12.331354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Multiple metrics, including accuracy, precision, recall, and F1-score, are computed to evaluate the performance of the model. These metrics provide a comprehensive assessment of the model's ability to classify data accurately and are particularly valuable for classification tasks.","metadata":{"id":"G44JGB7m1_8I"}},{"cell_type":"code","source":"# Calculate model_dense metrics\nmodel_dense_results = calculate_results(y_true=y_valid,\n                                    y_pred=model_dense_preds,\n                                       loss=model_dense_loss)\nmodel_dense_results","metadata":{"id":"bCeF2y4FO14q","outputId":"993ce436-62b1-4f58-a974-8edbe6e8204e","execution":{"iopub.status.busy":"2023-06-30T22:19:12.334176Z","iopub.execute_input":"2023-06-30T22:19:12.334924Z","iopub.status.idle":"2023-06-30T22:19:12.348786Z","shell.execute_reply.started":"2023-06-30T22:19:12.334881Z","shell.execute_reply":"2023-06-30T22:19:12.347567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = y_valid.tolist()  # Convert labels to a list\npreds = model_dense.predict(X_valid)\ny_probs = preds.squeeze().tolist()  # Store the prediction probabilities as a list\ny_preds = tf.round(y_probs).numpy().tolist()  # Convert probabilities to class predictions and convert to a list","metadata":{"id":"ZXEn0sEAsGkZ","outputId":"8899a86a-d7f1-47b2-bcbe-29bafea458d3","execution":{"iopub.status.busy":"2023-06-30T22:19:12.35043Z","iopub.execute_input":"2023-06-30T22:19:12.3512Z","iopub.status.idle":"2023-06-30T22:19:12.552147Z","shell.execute_reply.started":"2023-06-30T22:19:12.351168Z","shell.execute_reply":"2023-06-30T22:19:12.551024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A confusion matrix is created to provide a visual representation of the classification model's performance. After generating the confusion matrix, a custom function is employed to enhance its readability. This function likely formats and labels the matrix for better interpretation.","metadata":{"id":"RkaHJBuf2BlJ"}},{"cell_type":"code","source":"# Check out the non-prettified confusion matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_true=y_true,\n                 y_pred=y_preds)","metadata":{"id":"kY6eapwmsGka","outputId":"b6f1f362-3555-447b-f801-724022508649","execution":{"iopub.status.busy":"2023-06-30T22:19:12.553767Z","iopub.execute_input":"2023-06-30T22:19:12.554151Z","iopub.status.idle":"2023-06-30T22:19:12.566727Z","shell.execute_reply.started":"2023-06-30T22:19:12.554118Z","shell.execute_reply":"2023-06-30T22:19:12.565649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\ndef make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15):\n    \"\"\"\n    Create a labeled confusion matrix comparing predictions and ground truth labels.\n    \n    Args:\n        y_true: Array of true labels (must be the same shape as y_pred).\n        y_pred: Array of predicted labels (must be the same shape as y_true).\n        classes: Array of class labels (e.g., string form). If None, integer labels are used.\n        figsize: Size of the output figure (default=(10, 10)).\n        text_size: Size of the text in the output figure (default=15).\n    \n    Returns:\n        A labeled confusion matrix plot comparing y_true and y_pred.\n    \"\"\"\n    # Create the confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]  # Normalize it\n    n_classes = cm.shape[0]  # Find the number of classes we're dealing with\n    \n    # Plot the figure and make it visually appealing\n    fig, ax = plt.subplots(figsize=figsize)\n    cax = ax.matshow(cm, cmap=plt.cm.Blues)  # Use colors to represent how 'correct' a class is (darker == better)\n    fig.colorbar(cax)\n    \n    # Check if there's a list of class labels\n    if classes:\n        labels = classes\n    else:\n        labels = np.arange(cm.shape[0])\n    \n    # Label the axes\n    ax.set(title=\"Confusion Matrix\",\n           xlabel=\"Predicted label\",\n           ylabel=\"True label\",\n           xticks=np.arange(n_classes),  # Create enough axis slots for each class\n           yticks=np.arange(n_classes),\n           xticklabels=labels,  # Axes are labeled with class names (if available) or integers\n           yticklabels=labels)\n    \n    # Place x-axis labels at the bottom\n    ax.xaxis.set_label_position(\"bottom\")\n    ax.xaxis.tick_bottom()\n    \n    # Set the threshold for different colors\n    threshold = (cm.max() + cm.min()) / 2.\n    \n    # Plot text on each cell\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1]):\n        plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j] * 100:.1f}%)\",\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > threshold else \"black\",\n                 size=text_size)\n\n# Example usage:\n# make_confusion_matrix(y_true, y_pred, classes=class_names, figsize=(15, 15), text_size=10)\n","metadata":{"id":"QtcgNF8QsGkb","execution":{"iopub.status.busy":"2023-06-30T22:19:12.568486Z","iopub.execute_input":"2023-06-30T22:19:12.569112Z","iopub.status.idle":"2023-06-30T22:19:12.582253Z","shell.execute_reply.started":"2023-06-30T22:19:12.569078Z","shell.execute_reply":"2023-06-30T22:19:12.581063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prettier confusion matrix\nmake_confusion_matrix(y_true=y_true,\n                      y_pred=y_preds,\n                      classes=class_names,\n                      figsize=(15, 15),\n                      text_size=10)","metadata":{"id":"NNukSFtysGke","outputId":"819dd292-2f6f-477d-a4dd-d217782c004d","execution":{"iopub.status.busy":"2023-06-30T22:19:12.583957Z","iopub.execute_input":"2023-06-30T22:19:12.584367Z","iopub.status.idle":"2023-06-30T22:19:13.182625Z","shell.execute_reply.started":"2023-06-30T22:19:12.584331Z","shell.execute_reply":"2023-06-30T22:19:13.181707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following show_random_predictions function picks random samples from the validation set, makes predictions on them, and prints the actual and predicted labels. It provides an intuitive way to see how the model performs on unseen data.","metadata":{"id":"rr8WVJI02LuE"}},{"cell_type":"code","source":"index_word = {v: k for k, v in tokenizer.word_index.items()}\n\nfrom colorama import Fore, Style\ndef show_random_predictions(model, X_valid, y_valid, tokenizer, num_samples=5, class_names=None):\n    # Check if it's binary or multi-class classification\n    is_binary_classification = len(np.unique(y_valid)) == 2\n\n    # Getting indices of the random samples\n    random_indices = np.random.choice(np.arange(len(X_valid)), size=num_samples, replace=False)\n\n    # Selecting the random samples\n    random_X_samples = X_valid[random_indices]\n    random_y_samples = y_valid[random_indices]\n\n    # Making predictions on the random samples\n    y_pred_probs = model.predict(random_X_samples)\n\n    if is_binary_classification:\n        y_pred = np.squeeze(np.round(y_pred_probs).astype(int))\n    else:\n        y_pred = np.argmax(y_pred_probs, axis=1)\n\n    # Print the actual and predicted labels\n    for i in range(num_samples):\n        text_tokens = random_X_samples[i]\n        text = ' '.join([index_word.get(token) for token in text_tokens if token != 0])  # 0 is typically the padding token\n        true_label = random_y_samples[i] if is_binary_classification else np.argmax(random_y_samples[i])\n        predicted_label = y_pred[i]\n\n        # If class names are provided, use them for printing\n        if class_names is not None:\n            true_label_name = class_names[true_label]\n            predicted_label_name = class_names[predicted_label]\n        else:\n            true_label_name = true_label\n            predicted_label_name = predicted_label\n\n        # Determine the color of the text (green for correct, red for incorrect)\n        text_color = Fore.GREEN if true_label == predicted_label else Fore.RED\n\n        print(f\"\\nSample {i + 1}:\")\n        print(f\"Text: {text}\")\n        print(text_color + f\"True: {true_label_name} \\n Predicted: {predicted_label_name}\" + Style.RESET_ALL)","metadata":{"id":"EclD0I9op2ee","execution":{"iopub.status.busy":"2023-06-30T22:19:13.186973Z","iopub.execute_input":"2023-06-30T22:19:13.189128Z","iopub.status.idle":"2023-06-30T22:19:13.21043Z","shell.execute_reply.started":"2023-06-30T22:19:13.189094Z","shell.execute_reply":"2023-06-30T22:19:13.209476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The show_random_predictions function is called to generate and display predictions on random samples.","metadata":{"id":"V2zgT6ee2GZD"}},{"cell_type":"code","source":"show_random_predictions(model_dense,\n                   X_valid,\n                   y_valid,\n                   tokenizer,\n                   num_samples=10,\n                   class_names=class_names)","metadata":{"id":"GXD-7ijVp4mk","outputId":"3e72f32b-47aa-4572-b1c4-8bc823971245","execution":{"iopub.status.busy":"2023-06-30T22:19:13.215481Z","iopub.execute_input":"2023-06-30T22:19:13.217986Z","iopub.status.idle":"2023-06-30T22:19:13.326176Z","shell.execute_reply.started":"2023-06-30T22:19:13.217952Z","shell.execute_reply":"2023-06-30T22:19:13.325097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model: LSTM**","metadata":{"id":"vNRNNj7jSXl9"}},{"cell_type":"markdown","source":"The code establishes an LSTM (Long Short-Term Memory) model for sequence classification. Here's a summary of the code's key components:\n\n1. **Random Seed for Reproducibility**:\n   - The `tf.random.set_seed(42)` function is used to set a random seed, ensuring reproducibility by fixing the randomness of the model initialization.\n\n2. **Embedding Layer**:\n   - An `Embedding` layer is added to convert input words into dense fixed-size vectors. This layer is commonly used for text data to capture semantic relationships between words.\n\n3. **LSTM Layers**:\n   - Two consecutive LSTM layers are added. The first LSTM layer returns sequences and allows for layer stacking. LSTM layers are recurrent layers that can capture sequential dependencies in the data.\n\n4. **Dense Layer with 'relu' Activation**:\n   - A dense layer with a 'relu' (Rectified Linear Unit) activation function is included. This layer helps the model learn relevant features from the LSTM-encoded representations.\n\n5. **Output Dense Layer with 'sigmoid' Activation**:\n   - The model concludes with an output dense layer featuring a 'sigmoid' activation function. This configuration is suitable for binary classification tasks, as it produces probabilities ranging from 0 to 1.\n\n6. **Model Name**:\n   - The model is named \"model_1LSTM\" and is constructed to accept inputs and generate outputs according to the defined layers.\n\nOverall, this code sets up an LSTM-based neural network model for sequence classification, which is capable of learning from sequential data and making binary classification predictions.","metadata":{"id":"wjlxXYlU2n0n"}},{"cell_type":"code","source":"# Set random seed and create embedding layer (new embedding layer for each model)\ntf.random.set_seed(42)\nfrom tensorflow.keras import layers\nmodel_1LSTM_embedding = layers.Embedding(input_dim=max_vocab_length,\n                                     output_dim=300,\n                                     embeddings_initializer=\"uniform\",\n                                     input_length=max_length,\n                                     name=\"embedding_2\")\n\n\n# Create LSTM model\ninputs = layers.Input(shape=(X_train.shape[1],), dtype=\"int32\")\nx = model_1LSTM_embedding(inputs)\nx = layers.LSTM(64, return_sequences=True)(x)\nx = layers.LSTM(64)(x)\nx = layers.Dense(64, activation=\"relu\")(x)\noutputs = layers.Dense(1, activation=\"sigmoid\")(x)\nmodel_1LSTM = tf.keras.Model(inputs, outputs, name=\"model_1LSTM\")","metadata":{"id":"vjqsKlnuSW-L","execution":{"iopub.status.busy":"2023-06-30T22:19:13.327406Z","iopub.execute_input":"2023-06-30T22:19:13.327766Z","iopub.status.idle":"2023-06-30T22:19:14.149359Z","shell.execute_reply.started":"2023-06-30T22:19:13.327733Z","shell.execute_reply":"2023-06-30T22:19:14.148418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code compiles the LSTM model using binary_crossentropy as the loss function, Adam as the optimizer, and accuracy as the evaluation metric. This configuration sets up the model for binary classification tasks, optimizing it with the Adam optimizer and assessing its performance based on the accuracy of its predictions.","metadata":{"id":"Em3I3MVB2swD"}},{"cell_type":"code","source":"# Compile model\nmodel_1LSTM.compile(loss=\"binary_crossentropy\",\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=[\"accuracy\"])","metadata":{"id":"G66DgG6rSbhq","execution":{"iopub.status.busy":"2023-06-30T22:19:14.153958Z","iopub.execute_input":"2023-06-30T22:19:14.156348Z","iopub.status.idle":"2023-06-30T22:19:14.174504Z","shell.execute_reply.started":"2023-06-30T22:19:14.156305Z","shell.execute_reply":"2023-06-30T22:19:14.173609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1LSTM.summary()","metadata":{"id":"m5Pa-j-6ScaZ","outputId":"da762f08-1f92-4b91-9620-7d5385e6b1b9","execution":{"iopub.status.busy":"2023-06-30T22:19:14.178695Z","iopub.execute_input":"2023-06-30T22:19:14.180842Z","iopub.status.idle":"2023-06-30T22:19:14.225937Z","shell.execute_reply.started":"2023-06-30T22:19:14.180809Z","shell.execute_reply":"2023-06-30T22:19:14.225191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now create a checkpoint callback for model LSTM.","metadata":{"id":"Fu5jvMSF2zlB"}},{"cell_type":"code","source":"# Define the checkpoint path\ncheckpoint_path = \"best_model_LSTM\"\n\ncc = create_checkpoint_callback(checkpoint_path)","metadata":{"id":"9q7HOPz-Tcru","execution":{"iopub.status.busy":"2023-06-30T22:19:14.227179Z","iopub.execute_input":"2023-06-30T22:19:14.227493Z","iopub.status.idle":"2023-06-30T22:19:14.233321Z","shell.execute_reply.started":"2023-06-30T22:19:14.227465Z","shell.execute_reply":"2023-06-30T22:19:14.232554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nThe LSTM model is fit to the training data (X_train and y_train) for 20 epochs, with validation data (X_valid and y_valid) used for evaluation. The training progress is recorded in model_1LSTM_history, and the defined callbacks (cc) are utilized during training.","metadata":{"id":"Sut5rT5p29mL"}},{"cell_type":"code","source":"# Fit model\nmodel_1LSTM_history = model_1LSTM.fit(X_train, y_train,\n                              epochs=20,\n                              validation_data=(X_valid, y_valid),\n                              callbacks=[cc])","metadata":{"id":"eTKBS3w5Sdpk","outputId":"d6539839-61b4-46b8-ef12-d05c5a2c08fe","execution":{"iopub.status.busy":"2023-06-30T22:19:14.234417Z","iopub.execute_input":"2023-06-30T22:19:14.235183Z","iopub.status.idle":"2023-06-30T22:20:47.152078Z","shell.execute_reply.started":"2023-06-30T22:19:14.235146Z","shell.execute_reply":"2023-06-30T22:20:47.150983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Following training, the history of LSTM model's accuracy and loss over the epochs is plotted.","metadata":{"id":"dXBE7Q1G3CMd"}},{"cell_type":"code","source":"# Plot Utility\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n\n# Plot the accuracy and loss history\nplot_graphs(model_1LSTM_history, 'accuracy')\nplot_graphs(model_1LSTM_history, 'loss')","metadata":{"id":"xaG8O66RTrJi","outputId":"9187f7fb-362f-4e2f-b245-ef33ad3356b8","execution":{"iopub.status.busy":"2023-06-30T22:20:47.154564Z","iopub.execute_input":"2023-06-30T22:20:47.154941Z","iopub.status.idle":"2023-06-30T22:20:47.736498Z","shell.execute_reply.started":"2023-06-30T22:20:47.154908Z","shell.execute_reply":"2023-06-30T22:20:47.734739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best LSTM model (as determined by validation loss) is loaded for further analysis.","metadata":{"id":"j566QiJ13Eez"}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the entire model\nmodel_1LSTM = load_model(checkpoint_path)","metadata":{"id":"YAPlN9_kTvc6","execution":{"iopub.status.busy":"2023-06-30T22:20:47.741673Z","iopub.execute_input":"2023-06-30T22:20:47.744082Z","iopub.status.idle":"2023-06-30T22:20:51.506962Z","shell.execute_reply.started":"2023-06-30T22:20:47.744019Z","shell.execute_reply":"2023-06-30T22:20:51.505987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The LSTM model is evaluated on the validation set to understand its performance on unseen data.","metadata":{"id":"lY99cSqeCumB"}},{"cell_type":"code","source":"# Check the results\nmodel_1LSTM_ev  = model_1LSTM.evaluate(X_valid, y_valid)\nmodel_1LSTM_loss = model_1LSTM_ev [0]\nmodel_1LSTM_loss","metadata":{"id":"Zn1OrWEpT1qk","outputId":"eb0ffa98-f057-43eb-b23c-3b7f5bd3ccea","execution":{"iopub.status.busy":"2023-06-30T22:20:51.523405Z","iopub.execute_input":"2023-06-30T22:20:51.523752Z","iopub.status.idle":"2023-06-30T22:20:52.571659Z","shell.execute_reply.started":"2023-06-30T22:20:51.52372Z","shell.execute_reply":"2023-06-30T22:20:52.570741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The LSTM model predicts probabilities on the validation set, which are then converted into class predictions.","metadata":{"id":"fvYrfg9MCyvJ"}},{"cell_type":"code","source":"# Make predictions on the validation dataset\nmodel_1LSTM_pred_probs = model_1LSTM.predict(X_valid)\nmodel_1LSTM_pred_probs.shape, model_1LSTM_pred_probs[:10] # view the first 10","metadata":{"id":"3lRhKO-rSfSx","outputId":"ecc42797-6dda-4fda-b3b8-c4df64154244","execution":{"iopub.status.busy":"2023-06-30T22:20:52.572985Z","iopub.execute_input":"2023-06-30T22:20:52.573363Z","iopub.status.idle":"2023-06-30T22:20:53.546253Z","shell.execute_reply.started":"2023-06-30T22:20:52.573329Z","shell.execute_reply":"2023-06-30T22:20:53.545339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert prediction probabilities to labels\nmodel_1LSTM_preds = tf.squeeze(tf.round(model_1LSTM_pred_probs))\nmodel_1LSTM_preds[:10]","metadata":{"id":"ojdzf0-1dDSG","outputId":"c9e55d7c-c105-4641-a4ba-b2aa183a4bca","execution":{"iopub.status.busy":"2023-06-30T22:20:53.547765Z","iopub.execute_input":"2023-06-30T22:20:53.548151Z","iopub.status.idle":"2023-06-30T22:20:53.56201Z","shell.execute_reply.started":"2023-06-30T22:20:53.548117Z","shell.execute_reply":"2023-06-30T22:20:53.560765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Metrics such as accuracy, precision, recall, and F1-score are calculated to evaluate the performance of the LSTM model.","metadata":{"id":"osXrWKFAC0yB"}},{"cell_type":"code","source":"# Calculate LSTM model results\nmodel_1LSTM_results = calculate_results(y_true=y_valid,\n                                    y_pred=model_1LSTM_preds,\n                                       loss=model_1LSTM_loss)\nmodel_1LSTM_results","metadata":{"id":"6174IjhCShFj","outputId":"df4361d6-01f2-4bd2-af37-21bc27b758cb","execution":{"iopub.status.busy":"2023-06-30T22:20:53.564186Z","iopub.execute_input":"2023-06-30T22:20:53.564644Z","iopub.status.idle":"2023-06-30T22:20:53.578715Z","shell.execute_reply.started":"2023-06-30T22:20:53.564599Z","shell.execute_reply":"2023-06-30T22:20:53.57753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The function compares the performance metrics of the baseline model with the LSTM model. The comparison include various metrics such as accuracy, precision, recall, and F1-score.","metadata":{"id":"hEH_nXq_C2nt"}},{"cell_type":"code","source":"# Compare model 2 to baseline\ncompare_baseline_to_new_results(baseline_results, model_1LSTM_results)","metadata":{"id":"EmEoc5hTSiLb","outputId":"200b6e66-dcf6-462f-9670-2eeffc174f7d","execution":{"iopub.status.busy":"2023-06-30T22:27:41.389162Z","iopub.execute_input":"2023-06-30T22:27:41.38956Z","iopub.status.idle":"2023-06-30T22:27:41.39575Z","shell.execute_reply.started":"2023-06-30T22:27:41.389529Z","shell.execute_reply":"2023-06-30T22:27:41.394608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = y_valid.tolist()  # Convert labels to a list\npreds = model_1LSTM.predict(X_valid)\ny_probs = preds.squeeze().tolist()  # Store the prediction probabilities as a list\ny_preds = tf.round(y_probs).numpy().tolist()  # Convert probabilities to class predictions and convert to a list","metadata":{"id":"yQmRO19-sGkz","outputId":"e92e10cb-abf2-40c1-f2f0-91b8392e2e85","execution":{"iopub.status.busy":"2023-06-30T22:27:41.403845Z","iopub.execute_input":"2023-06-30T22:27:41.4046Z","iopub.status.idle":"2023-06-30T22:27:41.77296Z","shell.execute_reply.started":"2023-06-30T22:27:41.404572Z","shell.execute_reply":"2023-06-30T22:27:41.771853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A confusion matrix is generated to visualize the classification performance of the LSTM model. A custom function is used to make the matrix more readable.","metadata":{"id":"9jRzXRGJC5ID"}},{"cell_type":"code","source":"# Check out the non-prettified confusion matrix\nconfusion_matrix(y_true=y_true,\n                 y_pred=y_preds)","metadata":{"id":"PB67WPSesGk0","outputId":"7f4b0108-c921-49ec-c71c-c2f73ba450d3","execution":{"iopub.status.busy":"2023-06-30T22:27:41.777381Z","iopub.execute_input":"2023-06-30T22:27:41.777673Z","iopub.status.idle":"2023-06-30T22:27:41.789806Z","shell.execute_reply.started":"2023-06-30T22:27:41.777647Z","shell.execute_reply":"2023-06-30T22:27:41.7886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prettier confusion matrix\nmake_confusion_matrix(y_true=y_true,\n                      y_pred=y_preds,\n                      classes=class_names,\n                      figsize=(15, 15),\n                      text_size=10)","metadata":{"id":"WzgoXQuLsGk2","outputId":"a3fc40e1-ef6b-4a13-a1a9-69f343284f51","execution":{"iopub.status.busy":"2023-06-30T22:27:41.791992Z","iopub.execute_input":"2023-06-30T22:27:41.792478Z","iopub.status.idle":"2023-06-30T22:27:42.303543Z","shell.execute_reply.started":"2023-06-30T22:27:41.792435Z","shell.execute_reply":"2023-06-30T22:27:42.301806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The show_random_predictions function is called to generate and display predictions of the LSTM model on random samples.","metadata":{"id":"fsB5oISyC8Dv"}},{"cell_type":"code","source":"show_random_predictions(model_1LSTM,\n                   X_valid,\n                   y_valid,\n                   tokenizer,\n                   num_samples=10,\n                   class_names=class_names)","metadata":{"id":"KMm4fw7ksGk3","outputId":"1978702e-ae04-4333-ddc1-de610d249346","execution":{"iopub.status.busy":"2023-06-30T22:27:42.307027Z","iopub.execute_input":"2023-06-30T22:27:42.307505Z","iopub.status.idle":"2023-06-30T22:27:42.381741Z","shell.execute_reply.started":"2023-06-30T22:27:42.307469Z","shell.execute_reply":"2023-06-30T22:27:42.380827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model: Bidirectional LSTM**","metadata":{"id":"qqWoqtNJok7_"}},{"cell_type":"markdown","source":"The code introduces a Bidirectional LSTM (Long Short-Term Memory) model, which is a more advanced version of a recurrent neural network (RNN) model and is particularly suitable for text classification tasks. Here's an overview of the key components of this model:\n\n1. **Reproducibility**:\n   - Reproducibility is ensured by setting a random seed using `tf.random.set_seed(42)`.\n\n2. **Input and Embedding Layer**:\n   - The model, named `model_lstm`, accepts word indices as input and transforms them into dense vectors through an embedding layer.\n   - The embedding layer has a uniform embedding initializer and an output dimension of 128.\n\n3. **Bidirectional LSTM Layers**:\n   - Two bidirectional LSTM layers are employed, each consisting of 64 units. Bidirectional LSTMs capture context from both past and future data, enhancing their ability to capture sequential patterns.\n\n4. **Dense Layer**:\n   - A dense layer with 512 units and a 'relu' activation function is added. This layer is intended to learn high-level features from the LSTM-encoded representations.\n\n5. **Output Dense Layer with 'sigmoid' Activation**:\n   - The model is finalized with an output dense layer featuring a 'sigmoid' activation function, suitable for binary classification tasks.\n\nThis model is designed to capture complex sequential patterns in text data and make binary classification predictions. The bidirectional LSTM layers enhance the model's ability to understand both past and future context, making it well-suited for text classification tasks.","metadata":{"id":"qN02L5IwDcG1"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\n# Parameters\nembedding_dim=128\n\ntf.random.set_seed(42)\n\n# Input layer\ninputs = layers.Input(shape=(X_train.shape[1],), dtype=\"int32\")\n# Create an embedding of the numerized numbers\nx = layers.Embedding(input_dim=max_vocab_length,\n                     output_dim=128,\n                     embeddings_initializer=\"uniform\",\n                     input_length=max_length,\n                     name=\"embedding_2\")(inputs)\n\n# Bidirectional LSTM\nx = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n# Another LSTM Layer\nx = layers.Bidirectional(layers.LSTM(64))(x)\n# Dense layer\nx = layers.Dense(512, activation='relu')(x)\n# Output layer\noutputs = layers.Dense(1, activation='sigmoid')(x)\n# Create the model\nmodel_lstm = tf.keras.Model(inputs, outputs)","metadata":{"id":"LfZ6PKC8orqd","execution":{"iopub.status.busy":"2023-06-30T22:27:42.384971Z","iopub.execute_input":"2023-06-30T22:27:42.385307Z","iopub.status.idle":"2023-06-30T22:27:43.473617Z","shell.execute_reply.started":"2023-06-30T22:27:42.385281Z","shell.execute_reply":"2023-06-30T22:27:43.472513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nAfter these layers are assembled, the model, referred to as 'model_lstm', is compiled using the Adam optimizer and a binary cross-entropy loss function - appropriate for binary classification tasks.","metadata":{"id":"RzlTfRxiDj_h"}},{"cell_type":"code","source":"# Set the training parameters\nmodel_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n# Print the model summary\nmodel_lstm.summary()","metadata":{"id":"4ybHsCW-Dk6C","execution":{"iopub.status.busy":"2023-06-30T22:27:43.475128Z","iopub.execute_input":"2023-06-30T22:27:43.475758Z","iopub.status.idle":"2023-06-30T22:27:43.519886Z","shell.execute_reply.started":"2023-06-30T22:27:43.475724Z","shell.execute_reply":"2023-06-30T22:27:43.519107Z"},"outputId":"ce8d6f8d-eba2-4831-b5e9-abb6c38e6338","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the checkpoint path\ncheckpoint_path = \"best_model_Bi-LSTM\"\n\ncc = create_checkpoint_callback(checkpoint_path)","metadata":{"id":"HJMoDkPOpE5v","execution":{"iopub.status.busy":"2023-06-30T22:27:43.52091Z","iopub.execute_input":"2023-06-30T22:27:43.521397Z","iopub.status.idle":"2023-06-30T22:27:43.526589Z","shell.execute_reply.started":"2023-06-30T22:27:43.521363Z","shell.execute_reply":"2023-06-30T22:27:43.525754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model_lstm is fit to the training data (X_train and y_train) for 20 epochs, with validation data (X_valid and y_valid) used for evaluation. The training progress is recorded in history_lstm, and the defined callbacks (cc) are utilized during training.","metadata":{"id":"dZG0RDGUDwe8"}},{"cell_type":"code","source":"NUM_EPOCHS = 20\n\n# Train the model\nhistory_lstm = model_lstm.fit(X_train, y_train, epochs=NUM_EPOCHS, validation_data=(X_valid, y_valid),callbacks=[cc])","metadata":{"id":"M_L-8WTco3Wb","outputId":"3f86bc14-de1a-4326-be55-fd15444b7b05","execution":{"iopub.status.busy":"2023-06-30T22:27:43.527696Z","iopub.execute_input":"2023-06-30T22:27:43.528084Z","iopub.status.idle":"2023-06-30T22:30:11.496505Z","shell.execute_reply.started":"2023-06-30T22:27:43.52805Z","shell.execute_reply":"2023-06-30T22:30:11.49535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Post-training, the model's accuracy and loss evolution across epochs is visualized.","metadata":{"id":"Yb23CDtFD3c8"}},{"cell_type":"code","source":"# Plot Utility\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n\n# Plot the accuracy and loss history\nplot_graphs(history_lstm, 'accuracy')\nplot_graphs(history_lstm, 'loss')","metadata":{"id":"tS4ABQEBo9cQ","outputId":"09568fc0-a445-4486-d80d-92cf3504104f","execution":{"iopub.status.busy":"2023-06-30T22:30:11.499529Z","iopub.execute_input":"2023-06-30T22:30:11.499995Z","iopub.status.idle":"2023-06-30T22:30:12.038065Z","shell.execute_reply.started":"2023-06-30T22:30:11.49996Z","shell.execute_reply":"2023-06-30T22:30:12.037009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model with the best validation loss is loaded for further usage.","metadata":{"id":"lrRFXwlpD570"}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the entire model\nmodel_lstm = load_model(checkpoint_path)","metadata":{"id":"9lHMJnZGpep7","execution":{"iopub.status.busy":"2023-06-30T22:30:12.042863Z","iopub.execute_input":"2023-06-30T22:30:12.043786Z","iopub.status.idle":"2023-06-30T22:30:21.079892Z","shell.execute_reply.started":"2023-06-30T22:30:12.043751Z","shell.execute_reply":"2023-06-30T22:30:21.078791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performance of this model is assessed on the validation dataset.","metadata":{"id":"Q3c8O02qD9Mc"}},{"cell_type":"code","source":"# Check the results\nmodel_lstm_ev = model_lstm.evaluate(X_valid, y_valid)\nmodel_lstm_loss = model_lstm_ev[0]\nmodel_lstm_loss","metadata":{"id":"NZNFOdPnpq8b","outputId":"cfa50f12-6f52-45a7-9c7b-862245c8273e","execution":{"iopub.status.busy":"2023-06-30T22:30:21.138548Z","iopub.execute_input":"2023-06-30T22:30:21.138978Z","iopub.status.idle":"2023-06-30T22:30:23.121276Z","shell.execute_reply.started":"2023-06-30T22:30:21.138944Z","shell.execute_reply":"2023-06-30T22:30:23.120288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Class predictions are generated by transforming predicted probabilities on the validation dataset.","metadata":{"id":"2fX1usVpD_F4"}},{"cell_type":"code","source":"# Make predictions with model\nmodel_lstm_pred_probs = model_lstm.predict(X_valid)\nmodel_lstm_pred_probs[:10]","metadata":{"id":"kPDHumSHpveO","outputId":"b9b9efa0-54c2-496e-b988-cb6ccd52c4de","execution":{"iopub.status.busy":"2023-06-30T22:30:23.122708Z","iopub.execute_input":"2023-06-30T22:30:23.123174Z","iopub.status.idle":"2023-06-30T22:30:25.010117Z","shell.execute_reply.started":"2023-06-30T22:30:23.12314Z","shell.execute_reply":"2023-06-30T22:30:25.009075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert prediction probabilities to labels\nmodel_lstm_preds = tf.squeeze(tf.round(model_lstm_pred_probs))\nmodel_lstm_preds[:10]","metadata":{"id":"iRwrY0mZdMsM","outputId":"eaa683cb-8398-41c7-c38a-729e00aeff85","execution":{"iopub.status.busy":"2023-06-30T22:30:25.01178Z","iopub.execute_input":"2023-06-30T22:30:25.012143Z","iopub.status.idle":"2023-06-30T22:30:25.02676Z","shell.execute_reply.started":"2023-06-30T22:30:25.01211Z","shell.execute_reply":"2023-06-30T22:30:25.025547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To evaluate the model's performance, metrics such as accuracy, precision, recall, and F1-score are computed.","metadata":{"id":"hAUSbkchEBeH"}},{"cell_type":"code","source":"# Calculate model performance metrics\nmodel_lstm_results = calculate_results(y_valid, model_lstm_preds, loss=model_lstm_loss)\nmodel_lstm_results","metadata":{"id":"_34YndYDp0iW","outputId":"d0c63208-5504-4080-b96c-1c04ce59a6be","execution":{"iopub.status.busy":"2023-06-30T22:30:25.028766Z","iopub.execute_input":"2023-06-30T22:30:25.029125Z","iopub.status.idle":"2023-06-30T22:30:25.042469Z","shell.execute_reply.started":"2023-06-30T22:30:25.029092Z","shell.execute_reply":"2023-06-30T22:30:25.0412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performance metrics of the baseline model and the bidirectional LSTM model are compared.","metadata":{"id":"e2eqIsm2EDGI"}},{"cell_type":"code","source":"# Compare model 2 to baseline\ncompare_baseline_to_new_results(baseline_results, model_1LSTM_results)\n","metadata":{"id":"bLQZEb0YsGlB","outputId":"0ad30224-ef6c-4369-dab6-219f83761d4d","execution":{"iopub.status.busy":"2023-06-30T22:30:25.044236Z","iopub.execute_input":"2023-06-30T22:30:25.044581Z","iopub.status.idle":"2023-06-30T22:30:25.049658Z","shell.execute_reply.started":"2023-06-30T22:30:25.044549Z","shell.execute_reply":"2023-06-30T22:30:25.048737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = y_valid.tolist()  # Convert labels to a list\npreds = model_lstm.predict(X_valid)\ny_probs = preds.squeeze().tolist()  # Store the prediction probabilities as a list\ny_preds = tf.round(y_probs).numpy().tolist()  # Convert probabilities to class predictions and convert to a list\n","metadata":{"id":"tzLft_o1sGlC","outputId":"f8b05c02-bb01-4dcd-a6f1-d7babeff0b7e","execution":{"iopub.status.busy":"2023-06-30T22:30:25.050983Z","iopub.execute_input":"2023-06-30T22:30:25.051697Z","iopub.status.idle":"2023-06-30T22:30:25.737935Z","shell.execute_reply.started":"2023-06-30T22:30:25.051663Z","shell.execute_reply":"2023-06-30T22:30:25.736833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A confusion matrix is constructed to offer a visual perspective of the classification model's performance. The matrix is simplified using a custom function.","metadata":{"id":"EovBhUHbEEtE"}},{"cell_type":"code","source":"# Check out the non-prettified confusion matrix\nconfusion_matrix(y_true=y_true,\n                 y_pred=y_preds)\n","metadata":{"id":"cP_Y4sVAsGlC","outputId":"4aa59106-38a2-44f7-d522-85c5be7e02b8","execution":{"iopub.status.busy":"2023-06-30T22:30:25.739525Z","iopub.execute_input":"2023-06-30T22:30:25.739893Z","iopub.status.idle":"2023-06-30T22:30:25.751537Z","shell.execute_reply.started":"2023-06-30T22:30:25.73986Z","shell.execute_reply":"2023-06-30T22:30:25.750601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prettier confusion matrix\nmake_confusion_matrix(y_true=y_true,\n                      y_pred=y_preds,\n                      classes=class_names,\n                      figsize=(15, 15),\n                      text_size=10)","metadata":{"id":"C4ClURPlsGlD","outputId":"22c7bb5d-8544-4b4e-a0a1-5999c5cfc05b","execution":{"iopub.status.busy":"2023-06-30T22:30:25.754536Z","iopub.execute_input":"2023-06-30T22:30:25.754794Z","iopub.status.idle":"2023-06-30T22:30:26.227718Z","shell.execute_reply.started":"2023-06-30T22:30:25.754771Z","shell.execute_reply":"2023-06-30T22:30:26.226715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The function 'show_random_predictions' is invoked to generate and display predictions on random samples.","metadata":{"id":"58hj3TcIEGoR"}},{"cell_type":"code","source":"show_random_predictions(model_lstm,\n                   X_valid,\n                   y_valid,\n                   tokenizer,\n                   num_samples=10,\n                   class_names=class_names)","metadata":{"id":"HH04ETuXs6yv","outputId":"3456108b-d33b-4776-9557-86998e7ac50c","execution":{"iopub.status.busy":"2023-06-30T22:30:26.230957Z","iopub.execute_input":"2023-06-30T22:30:26.23127Z","iopub.status.idle":"2023-06-30T22:30:26.307723Z","shell.execute_reply.started":"2023-06-30T22:30:26.231244Z","shell.execute_reply":"2023-06-30T22:30:26.30663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model: GRU**","metadata":{"id":"fGdZey03T5VO"}},{"cell_type":"markdown","source":"The provided code initializes a recurrent neural network (RNN) with Gated Recurrent Units (GRUs), which are known for their efficiency in sequence processing. Here's an overview of the key components of this model:\n\n1. **Reproducibility**:\n   - Reproducibility is ensured by setting a random seed using `tf.random.set_seed(42)`.\n\n2. **Input and Embedding Layer**:\n   - The model, named `model_GRU`, accepts input sequences and transforms them into dense vectors using an embedding layer.\n\n3. **Two GRU Layers**:\n   - Two GRU layers are incorporated into the model. GRUs are a type of recurrent layer designed for efficient sequence modeling.\n   \n4. **Dense Layer**:\n   - A dense layer is included in the model with unspecified units and an unspecified activation function. This layer is responsible for learning relevant features from the GRU-encoded representations.\n\n5. **Output Dense Layer with 'sigmoid' Activation**:\n   - The model concludes with an output dense layer featuring a 'sigmoid' activation function. This setup is suitable for binary text classification tasks, as it produces probabilities in the range of 0 to 1.\n\nOverall, the code configures an RNN model with GRUs for efficient sequence processing, making it well-suited for text classification tasks. The model is designed to learn from sequential data and make binary classification predictions.","metadata":{"id":"Oo8rpBVcExVh"}},{"cell_type":"code","source":"# Set random seed and create embedding layer (new embedding layer for each model)\ntf.random.set_seed(42)\n\nfrom tensorflow.keras import layers\nmodel_GRU_embedding = layers.Embedding(input_dim=max_vocab_length,\n                                     output_dim=300,\n                                     embeddings_initializer=\"uniform\",\n                                     input_length=max_length,\n                                     name=\"embedding_GRU\")\n\n# Build an RNN using the GRU cell\ninputs = layers.Input(shape=(X_train.shape[1],), dtype=\"int32\")\nx = model_GRU_embedding(inputs)\nx = layers.GRU(64, return_sequences=True)(x)\nx = layers.GRU(64)(x)\nx = layers.Dense(64, activation=\"relu\")(x)\noutputs = layers.Dense(1, activation=\"sigmoid\")(x)\nmodel_GRU = tf.keras.Model(inputs, outputs, name=\"model_GRU\")","metadata":{"id":"UPV5d48QT8hP","execution":{"iopub.status.busy":"2023-06-30T22:30:26.310839Z","iopub.execute_input":"2023-06-30T22:30:26.311172Z","iopub.status.idle":"2023-06-30T22:30:26.857878Z","shell.execute_reply.started":"2023-06-30T22:30:26.311144Z","shell.execute_reply":"2023-06-30T22:30:26.856879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The 'model_GRU' is compiled using the Adam optimizer and binary cross-entropy as the loss function, suitable for binary classification tasks.","metadata":{"id":"nHyk0zsfElFZ"}},{"cell_type":"code","source":"# Compile GRU model\nmodel_GRU.compile(loss=\"binary_crossentropy\",\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=[\"accuracy\"])","metadata":{"id":"WYMRyhU9T9_w","execution":{"iopub.status.busy":"2023-06-30T22:30:26.859413Z","iopub.execute_input":"2023-06-30T22:30:26.859847Z","iopub.status.idle":"2023-06-30T22:30:26.874653Z","shell.execute_reply.started":"2023-06-30T22:30:26.859804Z","shell.execute_reply":"2023-06-30T22:30:26.873531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a summary of the GRU model\nmodel_GRU.summary()","metadata":{"id":"sjx27-VpT_Dt","outputId":"92f6e7f7-79c6-4632-f052-879fbc9dcbc4","execution":{"iopub.status.busy":"2023-06-30T22:30:26.876073Z","iopub.execute_input":"2023-06-30T22:30:26.876417Z","iopub.status.idle":"2023-06-30T22:30:26.898406Z","shell.execute_reply.started":"2023-06-30T22:30:26.876386Z","shell.execute_reply":"2023-06-30T22:30:26.897571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A checkpoint callback is created for the GRU model.","metadata":{"id":"_oRAcKXiE0rE"}},{"cell_type":"code","source":"# Define the checkpoint path\ncheckpoint_path = \"best_model_GRU\"\n\ncc = create_checkpoint_callback(checkpoint_path)","metadata":{"id":"RC1mbGYvWqvC","execution":{"iopub.status.busy":"2023-06-30T22:30:26.899545Z","iopub.execute_input":"2023-06-30T22:30:26.899842Z","iopub.status.idle":"2023-06-30T22:30:26.903836Z","shell.execute_reply.started":"2023-06-30T22:30:26.899813Z","shell.execute_reply":"2023-06-30T22:30:26.903136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The improved  is fit to the training data (X_train and y_train) for 20 epochs, with validation data (X_valid and y_valid) used for evaluation. The training progress is recorded in model_GRU_history, and the defined callbacks (cc) are utilized during training.","metadata":{"id":"5UIaBvQdE4CY"}},{"cell_type":"code","source":"# Fit model\nmodel_GRU_history = model_GRU.fit(X_train, y_train,\n                              epochs=20,\n                              validation_data=(X_valid, y_valid),\n                              callbacks=[cc])","metadata":{"id":"4XzPs7RAUADH","outputId":"1d1b3fc4-7a0b-40f8-9e96-e3032c009622","execution":{"iopub.status.busy":"2023-06-30T22:30:26.905145Z","iopub.execute_input":"2023-06-30T22:30:26.905459Z","iopub.status.idle":"2023-06-30T22:31:51.779864Z","shell.execute_reply.started":"2023-06-30T22:30:26.905429Z","shell.execute_reply":"2023-06-30T22:31:51.778783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model's accuracy and loss history is visualized post-training.","metadata":{"id":"nKkdvnN6E9kI"}},{"cell_type":"code","source":"# Plot Utility\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n\n# Plot the accuracy and loss history\nplot_graphs(model_GRU_history, 'accuracy')\nplot_graphs(model_GRU_history, 'loss')","metadata":{"id":"_c4h9fhGWPb1","outputId":"c048bf8f-53bd-42a1-942f-1c3b1032a2dc","execution":{"iopub.status.busy":"2023-06-30T22:31:51.781888Z","iopub.execute_input":"2023-06-30T22:31:51.782195Z","iopub.status.idle":"2023-06-30T22:31:52.337172Z","shell.execute_reply.started":"2023-06-30T22:31:51.782169Z","shell.execute_reply":"2023-06-30T22:31:52.335982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best model, determined by validation loss, is then loaded.","metadata":{"id":"Puk4GsxBE_hR"}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the entire model\nmodel_GRU = load_model(checkpoint_path)","metadata":{"id":"h_p7KXHHWRBT","execution":{"iopub.status.busy":"2023-06-30T22:31:52.338695Z","iopub.execute_input":"2023-06-30T22:31:52.339076Z","iopub.status.idle":"2023-06-30T22:31:55.341293Z","shell.execute_reply.started":"2023-06-30T22:31:52.339026Z","shell.execute_reply":"2023-06-30T22:31:55.340295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model evaluation occurs on the validation set.","metadata":{"id":"wE7JLCqgFBv8"}},{"cell_type":"code","source":"# Check the results\nmodel_GRU_ev = model_GRU.evaluate(X_valid, y_valid)\nmodel_GRU_loss = model_GRU_ev[0]\nmodel_GRU_loss","metadata":{"id":"ozeUm3ZLWSxD","outputId":"a2efde1a-a600-442f-a38f-21b952766457","execution":{"iopub.status.busy":"2023-06-30T22:31:55.35853Z","iopub.execute_input":"2023-06-30T22:31:55.358871Z","iopub.status.idle":"2023-06-30T22:31:56.348989Z","shell.execute_reply.started":"2023-06-30T22:31:55.358843Z","shell.execute_reply":"2023-06-30T22:31:56.348009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model predicts probabilities on the validation set, converting these into class predictions.","metadata":{"id":"0fv6-RljFD0y"}},{"cell_type":"code","source":"# Make predictions on the validation data\nmodel_GRU_pred_probs = model_GRU.predict(X_valid)\nmodel_GRU_pred_probs.shape, model_GRU_pred_probs[:10]","metadata":{"id":"gOGx89ydUBar","outputId":"5b612f24-8b84-48d4-f3e2-bde0abbaeba8","execution":{"iopub.status.busy":"2023-06-30T22:31:56.358863Z","iopub.execute_input":"2023-06-30T22:31:56.359164Z","iopub.status.idle":"2023-06-30T22:31:57.267135Z","shell.execute_reply.started":"2023-06-30T22:31:56.359138Z","shell.execute_reply":"2023-06-30T22:31:57.265957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert prediction probabilities to labels\nmodel_GRU_preds = tf.squeeze(tf.round(model_GRU_pred_probs))\nmodel_GRU_preds[:10]","metadata":{"id":"ICU0ysxFdTtN","outputId":"afdaac72-4094-42b0-967d-093a288df3f0","execution":{"iopub.status.busy":"2023-06-30T22:31:57.268548Z","iopub.execute_input":"2023-06-30T22:31:57.269008Z","iopub.status.idle":"2023-06-30T22:31:57.282641Z","shell.execute_reply.started":"2023-06-30T22:31:57.268972Z","shell.execute_reply":"2023-06-30T22:31:57.281437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performance metrics, including accuracy, precision, recall, and F1-score, are computed for model evaluation.","metadata":{"id":"IG0ZGbl4FGm-"}},{"cell_type":"code","source":"# Calcuate model_GRU results\nmodel_GRU_results = calculate_results(y_true=y_valid,\n                                    y_pred=model_GRU_preds,\n                                     loss=model_GRU_loss)\nmodel_GRU_results","metadata":{"id":"JrmtwK4tUDJ9","outputId":"f2a42bd2-a826-4db5-cece-59a42c4a7f65","execution":{"iopub.status.busy":"2023-06-30T22:31:57.285198Z","iopub.execute_input":"2023-06-30T22:31:57.285869Z","iopub.status.idle":"2023-06-30T22:31:57.29758Z","shell.execute_reply.started":"2023-06-30T22:31:57.285835Z","shell.execute_reply":"2023-06-30T22:31:57.296048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The baseline model's performance is compared with the GRU model.","metadata":{"id":"l9wuQgNiFITd"}},{"cell_type":"code","source":"# Compare to baseline\ncompare_baseline_to_new_results(baseline_results, model_GRU_results)","metadata":{"id":"7ZOKqAflUEv6","outputId":"210a45fb-1bb6-4ee0-aef6-e35097f34bde","execution":{"iopub.status.busy":"2023-06-30T22:31:57.299322Z","iopub.execute_input":"2023-06-30T22:31:57.299693Z","iopub.status.idle":"2023-06-30T22:31:57.30576Z","shell.execute_reply.started":"2023-06-30T22:31:57.299655Z","shell.execute_reply":"2023-06-30T22:31:57.304694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = y_valid.tolist()  # Convert labels to a list\npreds = model_GRU.predict(X_valid)\ny_probs = preds.squeeze().tolist()  # Store the prediction probabilities as a list\ny_preds = tf.round(y_probs).numpy().tolist()  # Convert probabilities to class predictions and convert to a list\n","metadata":{"id":"lSkKCTyQsGlU","outputId":"e924e818-0315-406d-aee7-c25e6bb85bc0","execution":{"iopub.status.busy":"2023-06-30T22:31:57.307519Z","iopub.execute_input":"2023-06-30T22:31:57.308359Z","iopub.status.idle":"2023-06-30T22:31:57.67416Z","shell.execute_reply.started":"2023-06-30T22:31:57.308324Z","shell.execute_reply":"2023-06-30T22:31:57.673101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A confusion matrix is created for visualization of the model's classification performance. The matrix readability is enhanced via a custom function.","metadata":{"id":"saL9KSmAFLwA"}},{"cell_type":"code","source":"# Check out the non-prettified confusion matrix\nconfusion_matrix(y_true=y_true,\n                 y_pred=y_preds)","metadata":{"id":"_DPF76YfsGlV","outputId":"074b0ab4-9489-4434-aad9-395c2e579fc1","execution":{"iopub.status.busy":"2023-06-30T22:31:57.675496Z","iopub.execute_input":"2023-06-30T22:31:57.675838Z","iopub.status.idle":"2023-06-30T22:31:57.689277Z","shell.execute_reply.started":"2023-06-30T22:31:57.675803Z","shell.execute_reply":"2023-06-30T22:31:57.688097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prettier confusion matrix\nmake_confusion_matrix(y_true=y_true,\n                      y_pred=y_preds,\n                      classes=class_names,\n                      figsize=(15, 15),\n                      text_size=10)","metadata":{"id":"2hNHQ9eOsGlW","outputId":"0db18f42-342d-4efd-9e8d-b5751879e5dc","execution":{"iopub.status.busy":"2023-06-30T22:31:57.691947Z","iopub.execute_input":"2023-06-30T22:31:57.692711Z","iopub.status.idle":"2023-06-30T22:31:58.180756Z","shell.execute_reply.started":"2023-06-30T22:31:57.692685Z","shell.execute_reply":"2023-06-30T22:31:58.179831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lastly, the 'show_random_predictions' function generates and displays predictions on random samples.","metadata":{"id":"t7mGaGelFOMl"}},{"cell_type":"code","source":"show_random_predictions(model_GRU,\n                   X_valid,\n                   y_valid,\n                   tokenizer,\n                   num_samples=10,\n                   class_names=class_names)","metadata":{"id":"j-9lkkCzrtT6","outputId":"5ac134cd-23bb-46a8-f1ab-4fdfa1199996","execution":{"iopub.status.busy":"2023-06-30T22:31:58.182372Z","iopub.execute_input":"2023-06-30T22:31:58.182742Z","iopub.status.idle":"2023-06-30T22:31:58.253642Z","shell.execute_reply.started":"2023-06-30T22:31:58.182708Z","shell.execute_reply":"2023-06-30T22:31:58.252708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model: Bi-directional GRU**","metadata":{"id":"hpvo3eHjCiz5"}},{"cell_type":"markdown","source":"The following code forms a bidirectional recurrent neural network (RNN) using Gated Recurrent Units (GRUs). After setting a random seed for consistency, an Embedding layer transforms inputs into dense vectors. Two bidirectional GRU layers allow past and future context capture. The model, 'model_bi_GRU', includes a Dense layer and concludes with a sigmoid-function output layer, apt for binary classification tasks.","metadata":{"id":"ck8yrUSDFa9Z"}},{"cell_type":"code","source":"# Set random seed and create embedding layer\ntf.random.set_seed(42)\n\nfrom tensorflow.keras import layers\nmodel_GRU_embedding = layers.Embedding(input_dim=max_vocab_length,\n                                       output_dim=300,\n                                       embeddings_initializer=\"uniform\",\n                                       input_length=max_length,\n                                       name=\"embedding_GRU\")\n\n# Build a bidirectional RNN using the GRU cell\ninputs = layers.Input(shape=(X_train.shape[1],), dtype=\"int32\")\nx = model_GRU_embedding(inputs)\nx = layers.Bidirectional(layers.GRU(64, return_sequences=True))(x)\nx = layers.Bidirectional(layers.GRU(64))(x)\nx = layers.Dense(64, activation=\"relu\")(x)\noutputs = layers.Dense(1, activation=\"sigmoid\")(x)\nmodel_bi_GRU = tf.keras.Model(inputs, outputs, name=\"model_bi_GRU\")","metadata":{"id":"ZlCpKZB_Ciz7","execution":{"iopub.status.busy":"2023-06-30T22:31:58.255199Z","iopub.execute_input":"2023-06-30T22:31:58.255889Z","iopub.status.idle":"2023-06-30T22:31:59.220717Z","shell.execute_reply.started":"2023-06-30T22:31:58.255828Z","shell.execute_reply":"2023-06-30T22:31:59.219739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The 'model_bi_GRU' is compiled using the Adam optimizer and the binary cross-entropy as the loss function, which is suitable for binary classification tasks.","metadata":{"id":"3sDhSYPTFea8"}},{"cell_type":"code","source":"# Compile bi-GRU model\nmodel_bi_GRU.compile(loss=\"binary_crossentropy\",\n                     optimizer=tf.keras.optimizers.Adam(),\n                     metrics=[\"accuracy\"])","metadata":{"id":"9oJBnRjeCiz8","execution":{"iopub.status.busy":"2023-06-30T22:31:59.222402Z","iopub.execute_input":"2023-06-30T22:31:59.222758Z","iopub.status.idle":"2023-06-30T22:31:59.237684Z","shell.execute_reply.started":"2023-06-30T22:31:59.222726Z","shell.execute_reply":"2023-06-30T22:31:59.236425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a summary of the model\nmodel_bi_GRU.summary()","metadata":{"outputId":"72fd43cd-b77e-48ea-dc13-4a846bbf4ca9","id":"XARgJeKdCiz9","execution":{"iopub.status.busy":"2023-06-30T22:31:59.239063Z","iopub.execute_input":"2023-06-30T22:31:59.239413Z","iopub.status.idle":"2023-06-30T22:31:59.263307Z","shell.execute_reply.started":"2023-06-30T22:31:59.239378Z","shell.execute_reply":"2023-06-30T22:31:59.262548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the checkpoint path\ncheckpoint_path = \"best_model_bi_GRU\"\n\ncc = create_checkpoint_callback(checkpoint_path)","metadata":{"id":"d4i5Kql0Ciz-","execution":{"iopub.status.busy":"2023-06-30T22:31:59.264306Z","iopub.execute_input":"2023-06-30T22:31:59.264721Z","iopub.status.idle":"2023-06-30T22:31:59.269413Z","shell.execute_reply.started":"2023-06-30T22:31:59.264687Z","shell.execute_reply":"2023-06-30T22:31:59.268643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model_bi_GRU is fit to the training data (X_train and y_train) for 20 epochs, with validation data (X_valid and y_valid) used for evaluation. The training progress is recorded in model_bi_GRU_history, and the defined callbacks (cc) are utilized during training.","metadata":{"id":"38ysu50OFkVl"}},{"cell_type":"code","source":"# Fit model\nmodel_bi_GRU_history = model_bi_GRU.fit(X_train, y_train,\n                                        epochs=20,\n                                        validation_data=(X_valid, y_valid),\n                                        callbacks=[cc])","metadata":{"outputId":"9b279b15-a9da-471a-ac91-775f9b82ed77","id":"VAxxe2vvCiz-","execution":{"iopub.status.busy":"2023-06-30T22:31:59.270444Z","iopub.execute_input":"2023-06-30T22:31:59.270845Z","iopub.status.idle":"2023-06-30T22:35:03.64499Z","shell.execute_reply.started":"2023-06-30T22:31:59.270804Z","shell.execute_reply":"2023-06-30T22:35:03.644124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After the training phase, the model's history of accuracy and loss is plotted over epochs.","metadata":{"id":"G-vy__hEFowu"}},{"cell_type":"code","source":"# Plot Utility\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n\n# Plot the accuracy and loss history\nplot_graphs(model_GRU_history, 'accuracy')\nplot_graphs(model_GRU_history, 'loss')","metadata":{"outputId":"597842fc-9ee9-421f-d1ea-53dc2c515e35","id":"gtmcYdGuCiz_","execution":{"iopub.status.busy":"2023-06-30T22:35:03.646751Z","iopub.execute_input":"2023-06-30T22:35:03.647752Z","iopub.status.idle":"2023-06-30T22:35:04.219703Z","shell.execute_reply.started":"2023-06-30T22:35:03.647714Z","shell.execute_reply":"2023-06-30T22:35:04.218649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The optimal model, based on validation loss, is loaded for further use.","metadata":{"id":"ZJPxHJOoFq5L"}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the entire model\nmodel_bi_GRU = load_model(checkpoint_path)","metadata":{"id":"-TOEd6s0Ci0B","execution":{"iopub.status.busy":"2023-06-30T22:35:04.221325Z","iopub.execute_input":"2023-06-30T22:35:04.221661Z","iopub.status.idle":"2023-06-30T22:35:15.27081Z","shell.execute_reply.started":"2023-06-30T22:35:04.221628Z","shell.execute_reply":"2023-06-30T22:35:15.269775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model's performance is evaluated on the validation dataset.","metadata":{"id":"4rei9He2Ft3I"}},{"cell_type":"code","source":"# Check the results\nmodel_bi_GRU_ev = model_bi_GRU.evaluate(X_valid, y_valid)\nmodel_bi_GRU_loss = model_bi_GRU_ev[0]\nmodel_bi_GRU_loss","metadata":{"outputId":"ae3ddeaf-463a-4151-e4db-61a593bf80bd","id":"0gDeZmi0Ci0C","execution":{"iopub.status.busy":"2023-06-30T22:35:15.277532Z","iopub.execute_input":"2023-06-30T22:35:15.277858Z","iopub.status.idle":"2023-06-30T22:35:17.205746Z","shell.execute_reply.started":"2023-06-30T22:35:15.277828Z","shell.execute_reply":"2023-06-30T22:35:17.204672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model predicts class probabilities on the validation dataset, which are then transformed into class predictions.","metadata":{"id":"gJBc_4uIFw8U"}},{"cell_type":"code","source":"# Make predictions on the validation data\nmodel_bi_GRU_pred_probs = model_bi_GRU.predict(X_valid)\nmodel_bi_GRU_pred_probs.shape, model_bi_GRU_pred_probs[:10]","metadata":{"outputId":"8e2e2e90-049a-49e6-c72c-bbb9391a39bb","id":"8WPww7BwCi0E","execution":{"iopub.status.busy":"2023-06-30T22:35:17.20714Z","iopub.execute_input":"2023-06-30T22:35:17.20747Z","iopub.status.idle":"2023-06-30T22:35:18.790941Z","shell.execute_reply.started":"2023-06-30T22:35:17.207444Z","shell.execute_reply":"2023-06-30T22:35:18.789976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert prediction probabilities to labels\nmodel_bi_GRU_preds = tf.squeeze(tf.round(model_bi_GRU_pred_probs))\nmodel_bi_GRU_preds[:10]","metadata":{"id":"AKnaD_0lCi0H","outputId":"58f2ea88-9152-4baf-e688-344340198b73","execution":{"iopub.status.busy":"2023-06-30T22:35:18.793168Z","iopub.execute_input":"2023-06-30T22:35:18.794209Z","iopub.status.idle":"2023-06-30T22:35:18.807867Z","shell.execute_reply.started":"2023-06-30T22:35:18.794174Z","shell.execute_reply":"2023-06-30T22:35:18.806743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Various performance metrics, such as accuracy, precision, recall, and the F1-score, are computed for model evaluation.","metadata":{"id":"WorSvwmjFyps"}},{"cell_type":"code","source":"# Calcuate model_bi_GRU results\nmodel_bi_GRU_results = calculate_results(y_true=y_valid,\n                                    y_pred=model_bi_GRU_preds,\n                                        loss=model_bi_GRU_loss)\nmodel_bi_GRU_results","metadata":{"outputId":"0c220ce5-2aef-416a-b3de-eabc9a1dd270","id":"ntlBoBcACi0I","execution":{"iopub.status.busy":"2023-06-30T22:35:18.809676Z","iopub.execute_input":"2023-06-30T22:35:18.810555Z","iopub.status.idle":"2023-06-30T22:35:18.823225Z","shell.execute_reply.started":"2023-06-30T22:35:18.810528Z","shell.execute_reply":"2023-06-30T22:35:18.822159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model's performance is compared with that of the baseline and the bidirectional GRU models.","metadata":{"id":"G4JFZcDVF1k5"}},{"cell_type":"code","source":"# Compare to baseline\ncompare_baseline_to_new_results(baseline_results, model_bi_GRU_results)","metadata":{"outputId":"fd6be3ea-f0fb-4a38-b0d2-14baec76d35c","id":"VI8N_pqaCi0J","execution":{"iopub.status.busy":"2023-06-30T22:35:18.824831Z","iopub.execute_input":"2023-06-30T22:35:18.825842Z","iopub.status.idle":"2023-06-30T22:35:18.830812Z","shell.execute_reply.started":"2023-06-30T22:35:18.8258Z","shell.execute_reply":"2023-06-30T22:35:18.829701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = y_valid.tolist()  # Convert labels to a list\npreds = model_bi_GRU.predict(X_valid)\ny_probs = preds.squeeze().tolist()  # Store the prediction probabilities as a list\ny_preds = tf.round(y_probs).numpy().tolist()  # Convert probabilities to class predictions and convert to a list\n","metadata":{"id":"wWVIAid6sGln","outputId":"a43c8c0b-ec06-4ce0-c800-07da2af2d478","execution":{"iopub.status.busy":"2023-06-30T22:35:18.832392Z","iopub.execute_input":"2023-06-30T22:35:18.833095Z","iopub.status.idle":"2023-06-30T22:35:19.200499Z","shell.execute_reply.started":"2023-06-30T22:35:18.833011Z","shell.execute_reply":"2023-06-30T22:35:19.199227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To visualize the model's classification performance, a confusion matrix is generated. Its readability is enhanced through a custom function.","metadata":{"id":"geW_pnciF-S_"}},{"cell_type":"code","source":"# Check out the non-prettified confusion matrix\nconfusion_matrix(y_true=y_true,\n                 y_pred=y_preds)","metadata":{"id":"OV44NQSMsGlo","outputId":"68c19926-e76e-4e7a-cecd-d8babbcf25dc","execution":{"iopub.status.busy":"2023-06-30T22:35:19.202284Z","iopub.execute_input":"2023-06-30T22:35:19.202893Z","iopub.status.idle":"2023-06-30T22:35:19.213128Z","shell.execute_reply.started":"2023-06-30T22:35:19.202858Z","shell.execute_reply":"2023-06-30T22:35:19.212414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prettier confusion matrix\nmake_confusion_matrix(y_true=y_true,\n                      y_pred=y_preds,\n                      classes=class_names,\n                      figsize=(15, 15),\n                      text_size=10)","metadata":{"id":"QYLBCcqksGlp","outputId":"b560ff47-0aa6-4658-afaf-1ab7aa8ef4a7","execution":{"iopub.status.busy":"2023-06-30T22:35:19.214609Z","iopub.execute_input":"2023-06-30T22:35:19.215322Z","iopub.status.idle":"2023-06-30T22:35:19.700446Z","shell.execute_reply.started":"2023-06-30T22:35:19.215262Z","shell.execute_reply":"2023-06-30T22:35:19.69938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, the function 'show_random_predictions' is invoked to generate and display predictions on random samples.","metadata":{"id":"tGed7SLYGBuE"}},{"cell_type":"code","source":"show_random_predictions(model_bi_GRU,\n                   X_valid,\n                   y_valid,\n                   tokenizer,\n                   num_samples=10,\n                   class_names=class_names)","metadata":{"id":"FsIjNZNZryIy","outputId":"e1f10b05-dc81-41dd-950d-8c24687e9828","execution":{"iopub.status.busy":"2023-06-30T22:35:19.702069Z","iopub.execute_input":"2023-06-30T22:35:19.702629Z","iopub.status.idle":"2023-06-30T22:35:19.784055Z","shell.execute_reply.started":"2023-06-30T22:35:19.702594Z","shell.execute_reply":"2023-06-30T22:35:19.783078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model: Conv1D**","metadata":{"id":"B27_CW0XqVqK"}},{"cell_type":"markdown","source":"The provided code block establishes a 1D Convolutional Neural Network (CNN) model for binary text classification. Here's an overview of the key components of this model:\n\n1. **Reproducibility**:\n   - Reproducibility is ensured by setting a random seed using `tf.random.set_seed(42)`.\n\n2. **Input and Embedding Layer**:\n   - The model begins with an input layer that accepts sequences of word indices.\n   - An embedding layer is introduced to convert these indices into dense vectors, which capture semantic relationships between words.\n\n3. **Convolutional Layer (Conv1D)**:\n   - A Conv1D layer is included with a specific number of filters and kernel size. This layer performs convolution operations on the input sequences to learn spatial patterns and features.\n\n4. **GlobalMaxPooling1D Layer**:\n   - Following the Conv1D layer, a GlobalMaxPooling1D layer is applied to reduce the spatial dimensions of the output. This step helps capture the most relevant information from the convolutional layer's output.\n\n5. **Dense Layer with 'relu' Activation**:\n   - A dense layer is added to the model, with a 'relu' (Rectified Linear Unit) activation function. This layer is responsible for learning high-level features from the extracted representations.\n\n6. **Output Dense Layer with 'sigmoid' Activation**:\n   - The model is finalized with an output dense layer featuring a 'sigmoid' activation function. This configuration is well-suited for binary text classification tasks, as it produces probabilities in the range of 0 to 1.\n\nThis model is designed to leverage convolutional operations to capture patterns in the input sequences and make binary classification predictions. It can be particularly effective for text classification tasks where local patterns in the text data are important.","metadata":{"id":"0Vl-LggUGWCx"}},{"cell_type":"code","source":"from tensorflow.keras import layers\n\n# Parameters\nembedding_dim = 300\nfilters = 64\nkernel_size = 5\n\ntf.random.set_seed(42)\n\n# Input layer\ninputs = layers.Input(shape=(X_train.shape[1],), dtype=\"int32\")\n\n# Create an embedding of the numerized numbers\nx = layers.Embedding(input_dim=max_vocab_length,\n                     output_dim=embedding_dim,\n                     embeddings_initializer=\"uniform\",\n                     input_length=max_length,\n                     name=\"embedding_2\")(inputs)\n# Conv1D layer\nx = layers.Conv1D(filters, kernel_size, activation='relu')(x)\n# GlobalMaxPooling1D layer\nx = layers.GlobalMaxPooling1D()(x)\n# Dense layer\nx = layers.Dense(512, activation='relu')(x)\n# Output layer\noutputs = layers.Dense(1, activation='sigmoid')(x)\n# Create the model\nmodel_conv = tf.keras.Model(inputs, outputs)\n\n","metadata":{"id":"Z3FnaFT8qcva","execution":{"iopub.status.busy":"2023-06-30T22:35:19.785846Z","iopub.execute_input":"2023-06-30T22:35:19.786307Z","iopub.status.idle":"2023-06-30T22:35:19.9098Z","shell.execute_reply.started":"2023-06-30T22:35:19.786256Z","shell.execute_reply":"2023-06-30T22:35:19.908809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model is then compiled with the 'adam' optimizer and 'binary_crossentropy' loss function, and the model summary is printed.","metadata":{"id":"3V5aiGlPGO5S"}},{"cell_type":"code","source":"# Set the training parameters\nmodel_conv.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Print the model summary\nmodel_conv.summary()","metadata":{"id":"TuZp7RgEGPY1","execution":{"iopub.status.busy":"2023-06-30T22:35:19.911181Z","iopub.execute_input":"2023-06-30T22:35:19.912005Z","iopub.status.idle":"2023-06-30T22:35:19.946568Z","shell.execute_reply.started":"2023-06-30T22:35:19.911967Z","shell.execute_reply":"2023-06-30T22:35:19.94569Z"},"outputId":"f0faef56-0f0a-4a5c-ad25-ef061b51498f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the checkpoint path\ncheckpoint_path = \"best_model_conv\"\n\ncc = create_checkpoint_callback(checkpoint_path)","metadata":{"id":"d44NPTBPrlhX","execution":{"iopub.status.busy":"2023-06-30T22:35:19.947734Z","iopub.execute_input":"2023-06-30T22:35:19.948147Z","iopub.status.idle":"2023-06-30T22:35:19.952761Z","shell.execute_reply.started":"2023-06-30T22:35:19.948112Z","shell.execute_reply":"2023-06-30T22:35:19.952018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model_conv is fit to the training data (X_train and y_train) for 20 epochs, with validation data (X_valid and y_valid) used for evaluation. The training progress is recorded in history_conv1d, and the defined callbacks (cc) are utilized during training.","metadata":{"id":"U70JU1x6GfdN"}},{"cell_type":"code","source":"NUM_EPOCHS = 20\n\n# Train the model\nhistory_conv1d = model_conv.fit(X_train, y_train, epochs=NUM_EPOCHS, validation_data=(X_valid, y_valid),callbacks=[cc])","metadata":{"id":"Zbu1TK4yqefb","outputId":"85e09463-eac1-4e21-a284-84c750da8440","execution":{"iopub.status.busy":"2023-06-30T22:35:19.953835Z","iopub.execute_input":"2023-06-30T22:35:19.95421Z","iopub.status.idle":"2023-06-30T22:36:15.462159Z","shell.execute_reply.started":"2023-06-30T22:35:19.954157Z","shell.execute_reply":"2023-06-30T22:36:15.461028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After training, the model's accuracy and loss history are plotted over the epochs.","metadata":{"id":"w9EbU4xtG7MO"}},{"cell_type":"code","source":"# Plot Utility\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n\n# Plot the accuracy and loss history\nplot_graphs(history_conv1d, 'accuracy')\nplot_graphs(history_conv1d, 'loss')","metadata":{"id":"0G4rCcQTqfv8","outputId":"90839df7-8f5a-4f46-ae32-c51e9141e9d1","execution":{"iopub.status.busy":"2023-06-30T22:36:15.464583Z","iopub.execute_input":"2023-06-30T22:36:15.465Z","iopub.status.idle":"2023-06-30T22:36:16.019155Z","shell.execute_reply.started":"2023-06-30T22:36:15.464962Z","shell.execute_reply":"2023-06-30T22:36:16.017684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best-performing model, determined by validation loss, is loaded for future use.","metadata":{"id":"y391Ise9G9SE"}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the entire model\nmodel_conv = load_model(checkpoint_path)","metadata":{"id":"ZRCWO6wWsQm5","execution":{"iopub.status.busy":"2023-06-30T22:36:16.022157Z","iopub.execute_input":"2023-06-30T22:36:16.022803Z","iopub.status.idle":"2023-06-30T22:36:16.410752Z","shell.execute_reply.started":"2023-06-30T22:36:16.022766Z","shell.execute_reply":"2023-06-30T22:36:16.40967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model is evaluated on the validation set, after which probabilities are predicted and transformed into class predictions.","metadata":{"id":"sW4Cbaa9HADw"}},{"cell_type":"code","source":"# Check the results\nmodel_conv_ev = model_conv.evaluate(X_valid, y_valid)\nmodel_conv_loss = model_conv_ev[0]\nmodel_conv_loss","metadata":{"id":"ESspc1_9sSS2","outputId":"f56a4a22-12f2-4b3b-cff9-4963089eb699","execution":{"iopub.status.busy":"2023-06-30T22:36:16.414491Z","iopub.execute_input":"2023-06-30T22:36:16.414801Z","iopub.status.idle":"2023-06-30T22:36:16.750695Z","shell.execute_reply.started":"2023-06-30T22:36:16.414775Z","shell.execute_reply":"2023-06-30T22:36:16.749733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions with the model\nmodel_conv_pred_probs = model_conv.predict(X_valid)\nmodel_conv_pred_probs[:10]","metadata":{"id":"tnO5gkD2sT6P","outputId":"1bd5e3e4-0ab1-4409-9c95-72b2096da728","execution":{"iopub.status.busy":"2023-06-30T22:36:16.753047Z","iopub.execute_input":"2023-06-30T22:36:16.753657Z","iopub.status.idle":"2023-06-30T22:36:17.022886Z","shell.execute_reply.started":"2023-06-30T22:36:16.753622Z","shell.execute_reply":"2023-06-30T22:36:17.017953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert prediction probabilities to labels\nmodel_conv_preds = tf.squeeze(tf.round(model_conv_pred_probs))\nmodel_conv_preds[:10]","metadata":{"id":"XA7QWiOWdYg1","outputId":"bf63725b-1949-4c42-d23f-e8ad9ab88829","execution":{"iopub.status.busy":"2023-06-30T22:36:17.024129Z","iopub.execute_input":"2023-06-30T22:36:17.024888Z","iopub.status.idle":"2023-06-30T22:36:17.041208Z","shell.execute_reply.started":"2023-06-30T22:36:17.024854Z","shell.execute_reply":"2023-06-30T22:36:17.03969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performance metrics such as accuracy, precision, recall, and the F1-score are calculated for model evaluation.","metadata":{"id":"iOtI9kZ1HC7E"}},{"cell_type":"code","source":"# Calculate model performance metrics\nmodel_conv_results = calculate_results(y_valid, model_conv_preds, loss=model_conv_loss)\nmodel_conv_results","metadata":{"id":"ihrEwhmrsWvn","outputId":"975956c7-7eb1-479f-ec4c-9cc60c2bb64e","execution":{"iopub.status.busy":"2023-06-30T22:48:46.364938Z","iopub.execute_input":"2023-06-30T22:48:46.365382Z","iopub.status.idle":"2023-06-30T22:48:46.378225Z","shell.execute_reply.started":"2023-06-30T22:48:46.365351Z","shell.execute_reply":"2023-06-30T22:48:46.377186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performance comparisons are made between the baseline and the convolutional model.","metadata":{"id":"Kl-D0XFmHEti"}},{"cell_type":"code","source":"# Compare model to baseline\ncompare_baseline_to_new_results(baseline_results, model_conv_results)","metadata":{"id":"wNvacdN_sGl3","outputId":"f1df74ee-3ec8-4fc0-abf5-62ec1815db91","execution":{"iopub.status.busy":"2023-06-30T22:36:17.060603Z","iopub.execute_input":"2023-06-30T22:36:17.061083Z","iopub.status.idle":"2023-06-30T22:36:17.066682Z","shell.execute_reply.started":"2023-06-30T22:36:17.061022Z","shell.execute_reply":"2023-06-30T22:36:17.065456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = y_valid.tolist()  # Convert labels to a list\npreds = model_conv.predict(X_valid)\ny_probs = preds.squeeze().tolist()  # Store the prediction probabilities as a list\ny_preds = tf.round(y_probs).numpy().tolist()  # Convert probabilities to class predictions and convert to a list","metadata":{"id":"8CYM6B_lsGl4","outputId":"0b424012-dde8-4c4a-e9c9-afa2339bfee7","execution":{"iopub.status.busy":"2023-06-30T22:36:17.067985Z","iopub.execute_input":"2023-06-30T22:36:17.068312Z","iopub.status.idle":"2023-06-30T22:36:17.259117Z","shell.execute_reply.started":"2023-06-30T22:36:17.068281Z","shell.execute_reply":"2023-06-30T22:36:17.258055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A confusion matrix is created to visualize the classification model's performance, and a custom function enhances the matrix's readability.","metadata":{"id":"iySVZlmmHHQf"}},{"cell_type":"code","source":"# Check out the non-prettified confusion matrix\nconfusion_matrix(y_true=y_true,\n                 y_pred=y_preds)","metadata":{"id":"8B1AHOQHsGl5","outputId":"bc1615e3-844a-4815-8872-8c5a54b6f7a5","execution":{"iopub.status.busy":"2023-06-30T22:36:17.261021Z","iopub.execute_input":"2023-06-30T22:36:17.261493Z","iopub.status.idle":"2023-06-30T22:36:17.274297Z","shell.execute_reply.started":"2023-06-30T22:36:17.261451Z","shell.execute_reply":"2023-06-30T22:36:17.273318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prettier confusion matrix\nmake_confusion_matrix(y_true=y_true,\n                      y_pred=y_preds,\n                      classes=class_names,\n                      figsize=(15, 15),\n                      text_size=10)","metadata":{"id":"doGRpsnQsGl6","outputId":"e032c076-16f0-4ea2-ba2a-31481186a7a8","execution":{"iopub.status.busy":"2023-06-30T22:36:17.275779Z","iopub.execute_input":"2023-06-30T22:36:17.27637Z","iopub.status.idle":"2023-06-30T22:36:17.767389Z","shell.execute_reply.started":"2023-06-30T22:36:17.276335Z","shell.execute_reply":"2023-06-30T22:36:17.766022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, the 'show_random_predictions' function generates and displays predictions on random samples.","metadata":{"id":"uyIuLLiGHJTb"}},{"cell_type":"code","source":"show_random_predictions(model_conv,\n                   X_valid,\n                   y_valid,\n                   tokenizer,\n                   num_samples=10,\n                   class_names=class_names)","metadata":{"id":"5xu6tAsgr1NJ","outputId":"2a3fd440-83c1-4c40-fafa-0e8c18c3c27f","execution":{"iopub.status.busy":"2023-06-30T22:36:17.769331Z","iopub.execute_input":"2023-06-30T22:36:17.769748Z","iopub.status.idle":"2023-06-30T22:36:17.845596Z","shell.execute_reply.started":"2023-06-30T22:36:17.76971Z","shell.execute_reply":"2023-06-30T22:36:17.844653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model: USE**","metadata":{"id":"YOlkGSt6qN5q"}},{"cell_type":"markdown","source":"The code you've described outlines the construction and training of a binary text classification model using Google's Universal Sentence Encoder (USE) from TensorFlow Hub. Below is a summarized version of the code's key steps and components:\n\n1. **Universal Sentence Encoder (USE)**: \n   - Google's Universal Sentence Encoder is used as a pre-trained model from TensorFlow Hub. It takes text sentences as input and encodes them into high-dimensional vectors. The USE layer is non-trainable, meaning it retains the pre-trained weights and functions as a feature extractor.\n\n2. **Dense Layer with 'relu' Activation**:\n   - The encoded vectors from the USE layer are passed through a dense layer with a Rectified Linear Unit (ReLU) activation function. This dense layer is responsible for learning relevant features from the encoded text representations.\n\n3. **Output Layer with 'sigmoid' Activation**:\n   - The final layer of the model is an output layer with a 'sigmoid' activation function. This is suitable for binary classification tasks, as it outputs probabilities ranging from 0 to 1.\n\n4. **Model Compilation**:\n   - The model is compiled using the Adam optimizer, which is a popular optimization algorithm for training neural networks. The binary cross-entropy loss function is chosen, which is commonly used for binary classification problems.\n\n5. **Model Summary**:\n   - A summary of the model is printed, displaying the architecture, layer details, and the number of trainable and non-trainable parameters.\n\nThe code you've described seems to be focused on the construction and compilation of the model. To complete the model, you would typically perform the following additional steps:\n\n6. **Model Training**:\n   - Fit the model to your training data using the `fit` method, specifying the training data, labels, and other parameters like batch size and the number of epochs.\n\n7. **Evaluation and Prediction**:\n   - Evaluate the model's performance on validation and test datasets. You can also use the trained model to make predictions on new text data.\n\nOverall, this code serves as the foundation for building a binary text classification model using the Universal Sentence Encoder and TensorFlow Hub and you would continue by training and evaluating the model on your specific dataset.","metadata":{"id":"DfRVpU4OHtHC"}},{"cell_type":"code","source":"# import tensorflow_hub as hub\n\n# We can use this encoding layer in place of our text_vectorizer and embedding layer\nsentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n                                        input_shape=[], # shape of inputs coming to our model\n                                        dtype=tf.string, # data type of inputs coming to the USE layer\n                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n                                        name=\"USE\")","metadata":{"id":"fN5P1NQ1mWfC","execution":{"iopub.status.busy":"2023-06-30T22:36:17.848167Z","iopub.execute_input":"2023-06-30T22:36:17.848644Z","iopub.status.idle":"2023-06-30T22:36:28.176855Z","shell.execute_reply.started":"2023-06-30T22:36:17.848617Z","shell.execute_reply":"2023-06-30T22:36:28.175861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(42)\n\n# Create model using the Sequential API\nmodel_USE = tf.keras.Sequential([\nsentence_encoder_layer, # take in sentences and then encode them into an embedding\nlayers.Dense(512, activation=\"relu\"),\nlayers.Dense(1, activation=\"sigmoid\")\n], name=\"model_USE\")\n\n# Compile model\nmodel_USE.compile(loss=\"binary_crossentropy\",\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=[\"accuracy\"])\n\nmodel_USE.summary()","metadata":{"id":"1HlSuCvfmWfD","outputId":"5503a811-6da3-45fb-bbb0-166cbd4dc6ae","execution":{"iopub.status.busy":"2023-06-30T22:36:28.178493Z","iopub.execute_input":"2023-06-30T22:36:28.179243Z","iopub.status.idle":"2023-06-30T22:36:28.497788Z","shell.execute_reply.started":"2023-06-30T22:36:28.179208Z","shell.execute_reply":"2023-06-30T22:36:28.496762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A ModelCheckpoint callback is set to save only the best model, as determined by validation loss.","metadata":{"id":"w0zHqc9SHWJQ"}},{"cell_type":"code","source":"# Define the checkpoint path\ncheckpoint_path = \"best_model_USE\"\n\n# Create a ModelCheckpoint callback that saves the model's weights only when the validation accuracy improves\ncc = ModelCheckpoint(filepath=checkpoint_path,\n                                      monitor='val_loss',\n                                      mode='min',\n                                      save_best_only=True,\n                                      verbose=1)","metadata":{"id":"Us9yRlwvmWfE","execution":{"iopub.status.busy":"2023-06-30T22:36:28.499601Z","iopub.execute_input":"2023-06-30T22:36:28.500339Z","iopub.status.idle":"2023-06-30T22:36:28.506476Z","shell.execute_reply.started":"2023-06-30T22:36:28.500304Z","shell.execute_reply":"2023-06-30T22:36:28.505348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_tx, y_train","metadata":{"id":"-UsKD2j9v7b4","outputId":"aa3ef35c-6575-4fd5-cbeb-64680430e6e8","execution":{"iopub.status.busy":"2023-06-30T22:36:28.508074Z","iopub.execute_input":"2023-06-30T22:36:28.508631Z","iopub.status.idle":"2023-06-30T22:36:28.52005Z","shell.execute_reply.started":"2023-06-30T22:36:28.508598Z","shell.execute_reply":"2023-06-30T22:36:28.5192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nThe model_USE is fit to the training data (X_train_tx and y_train) for 20 epochs, with validation data (X_valid_tx and y_valid) used for evaluation. The training progress is recorded in model_USE_history, and the defined callbacks (cc) are utilized during training.","metadata":{"id":"C4DocQyXICbi"}},{"cell_type":"code","source":"# Train a classifier on top of pretrained embeddings\nmodel_USE_history = model_USE.fit(X_train_tx,\n                              y_train,\n                              epochs=20,\n                              validation_data=(X_valid_tx, y_valid),\n                              callbacks=[cc])","metadata":{"id":"--3HYtIbmWfG","outputId":"eca0e3e0-2ce9-4cec-8a25-b3e778394775","execution":{"iopub.status.busy":"2023-06-30T22:36:28.521242Z","iopub.execute_input":"2023-06-30T22:36:28.522498Z","iopub.status.idle":"2023-06-30T22:38:43.133283Z","shell.execute_reply.started":"2023-06-30T22:36:28.522453Z","shell.execute_reply":"2023-06-30T22:38:43.13223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model demonstrating the best validation loss is loaded for use in subsequent steps.","metadata":{"id":"RuUsP8b2Hpv8"}},{"cell_type":"code","source":"# Load the entire model\nmodel_USE = load_model(checkpoint_path)","metadata":{"id":"rZ98ZBex5gf-","execution":{"iopub.status.busy":"2023-06-30T22:38:43.13551Z","iopub.execute_input":"2023-06-30T22:38:43.135814Z","iopub.status.idle":"2023-06-30T22:38:54.860598Z","shell.execute_reply.started":"2023-06-30T22:38:43.135787Z","shell.execute_reply":"2023-06-30T22:38:54.859466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, the model is evaluated on the validation set, where probabilities are predicted and converted into class predictions.","metadata":{"id":"RIgJLefOIRXo"}},{"cell_type":"code","source":"# Check the results\nmodel_USE_ev = model_USE.evaluate(X_valid_tx, y_valid)\nmodel_USE_loss = model_USE_ev[0]\nmodel_USE_loss","metadata":{"id":"c8_0KZQU5iIt","outputId":"afed444d-7bc0-4d7c-ea06-06e93629c1b4","execution":{"iopub.status.busy":"2023-06-30T22:38:54.863729Z","iopub.execute_input":"2023-06-30T22:38:54.864262Z","iopub.status.idle":"2023-06-30T22:38:55.993019Z","shell.execute_reply.started":"2023-06-30T22:38:54.86423Z","shell.execute_reply":"2023-06-30T22:38:55.992014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Post-training, the model's performance is assessed by plotting the history of accuracy and loss over the epochs.","metadata":{"id":"R3sapCQfIN8t"}},{"cell_type":"code","source":"# Plot Utility\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n\n# Plot the accuracy and loss history\nplot_graphs(model_USE_history, 'accuracy')\nplot_graphs(model_USE_history, 'loss')","metadata":{"id":"A4wpz0MNucAW","outputId":"b1a09348-7042-43be-a016-219cb044af24","execution":{"iopub.status.busy":"2023-06-30T22:38:55.994599Z","iopub.execute_input":"2023-06-30T22:38:55.994941Z","iopub.status.idle":"2023-06-30T22:38:56.545913Z","shell.execute_reply.started":"2023-06-30T22:38:55.994908Z","shell.execute_reply":"2023-06-30T22:38:56.544881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions with USE TF Hub model\nmodel_USE_pred_probs = model_USE.predict(X_valid_tx)\nmodel_USE_pred_probs[:10]","metadata":{"id":"qfS54pYJ5k5l","outputId":"80c5c4b6-1be3-4dcd-cc5e-496460bdd829","execution":{"iopub.status.busy":"2023-06-30T22:38:56.547316Z","iopub.execute_input":"2023-06-30T22:38:56.54802Z","iopub.status.idle":"2023-06-30T22:38:57.588701Z","shell.execute_reply.started":"2023-06-30T22:38:56.547986Z","shell.execute_reply":"2023-06-30T22:38:57.587751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert prediction probabilities to labels\nmodel_USE_preds = tf.squeeze(tf.round(model_USE_pred_probs))\nmodel_USE_preds[:10]","metadata":{"id":"T1snAT9kdetg","outputId":"3460b45e-a666-4483-ea2d-d8440dfb270c","execution":{"iopub.status.busy":"2023-06-30T22:38:57.590386Z","iopub.execute_input":"2023-06-30T22:38:57.590758Z","iopub.status.idle":"2023-06-30T22:38:57.606107Z","shell.execute_reply.started":"2023-06-30T22:38:57.590724Z","shell.execute_reply":"2023-06-30T22:38:57.605007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Various performance metrics such as accuracy, precision, recall, and the F1-score are calculated for the model.","metadata":{"id":"OiZB-3AtIU6I"}},{"cell_type":"code","source":"# Calculate model performance metrics\nmodel_USE_results = calculate_results(y_valid, model_USE_preds, loss=model_USE_loss)\nmodel_USE_results","metadata":{"id":"QjBsLuRI5qZH","outputId":"dcb77dc2-b6be-4ba2-b506-b57114fe1ee5","execution":{"iopub.status.busy":"2023-06-30T22:38:57.607449Z","iopub.execute_input":"2023-06-30T22:38:57.607732Z","iopub.status.idle":"2023-06-30T22:38:57.621915Z","shell.execute_reply.started":"2023-06-30T22:38:57.607707Z","shell.execute_reply":"2023-06-30T22:38:57.620763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A comparison of the baseline and USE models is then performed based on these metrics.","metadata":{"id":"ITaIoZnpIWl_"}},{"cell_type":"code","source":"# Compare model to baseline\ncompare_baseline_to_new_results(baseline_results, model_USE_results)","metadata":{"id":"VLzt5p2lsGmD","outputId":"e9c0e26b-6567-4236-a3d6-95607e1b42ec","execution":{"iopub.status.busy":"2023-06-30T22:38:57.623458Z","iopub.execute_input":"2023-06-30T22:38:57.623889Z","iopub.status.idle":"2023-06-30T22:38:57.632538Z","shell.execute_reply.started":"2023-06-30T22:38:57.623855Z","shell.execute_reply":"2023-06-30T22:38:57.630481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = y_valid.tolist()  # Convert labels to a list\npreds = model_USE.predict(X_valid_tx)\ny_probs = preds.squeeze().tolist()  # Store the prediction probabilities as a list\ny_preds = tf.round(y_probs).numpy().tolist()  # Convert probabilities to class predictions and convert to a list","metadata":{"id":"YNCjICetsGmE","outputId":"fc385fdf-6478-4670-839d-7c27b98b6858","execution":{"iopub.status.busy":"2023-06-30T22:38:57.634256Z","iopub.execute_input":"2023-06-30T22:38:57.634608Z","iopub.status.idle":"2023-06-30T22:38:58.319192Z","shell.execute_reply.started":"2023-06-30T22:38:57.634575Z","shell.execute_reply":"2023-06-30T22:38:58.318073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A confusion matrix is created to offer a visual perspective of the classification model's performance, which is further refined for readability using a custom function.","metadata":{"id":"0xxRExXjIYW_"}},{"cell_type":"code","source":"# Check out the non-prettified confusion matrix\nconfusion_matrix(y_true=y_true,\n                 y_pred=y_preds)","metadata":{"id":"edo4KHs1sGmF","outputId":"7b368e11-2596-4ec5-fe0b-03a96bb86d0a","execution":{"iopub.status.busy":"2023-06-30T22:38:58.320805Z","iopub.execute_input":"2023-06-30T22:38:58.321186Z","iopub.status.idle":"2023-06-30T22:38:58.334229Z","shell.execute_reply.started":"2023-06-30T22:38:58.32115Z","shell.execute_reply":"2023-06-30T22:38:58.333059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prettier confusion matrix\nmake_confusion_matrix(y_true=y_true,\n                      y_pred=y_preds,\n                      classes=class_names,\n                      figsize=(15, 15),\n                      text_size=10)","metadata":{"id":"PcXA1e7OsGmF","outputId":"ea293d63-ff73-4984-87f1-b6cd214f940b","execution":{"iopub.status.busy":"2023-06-30T22:38:58.33681Z","iopub.execute_input":"2023-06-30T22:38:58.337114Z","iopub.status.idle":"2023-06-30T22:38:58.82589Z","shell.execute_reply.started":"2023-06-30T22:38:58.337082Z","shell.execute_reply":"2023-06-30T22:38:58.824745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The function '`random_predictions`' generates and displays predictions on random samples specifically model USE.","metadata":{"id":"oyoj17XtIdbf"}},{"cell_type":"code","source":"def random_predictions(model, val_padded_seq, val_labels, num_samples=5, class_names=None):\n    # Check if it's binary or multi-class classification\n    num_classes = val_labels.shape[1] if len(val_labels.shape) > 1 else 2\n    is_binary_classification = num_classes == 2\n\n    # Getting indices of the random samples\n    random_indices = np.random.choice(np.arange(len(val_padded_seq)), size=num_samples, replace=False)\n\n    # Selecting the random samples\n    random_X_samples = val_padded_seq[random_indices]\n    random_y_samples = val_labels[random_indices]\n\n    # Making predictions on the random samples\n    y_pred_probs = model.predict(random_X_samples)\n\n    if is_binary_classification:\n        y_pred = np.squeeze(np.round(y_pred_probs).astype(int))\n    else:\n        y_pred = np.argmax(y_pred_probs, axis=1)\n\n    # Print the actual and predicted labels\n    for i in range(num_samples):\n        text = random_X_samples[i]\n        true_label = np.argmax(random_y_samples[i]) if not is_binary_classification else np.squeeze(random_y_samples[i])\n        predicted_label = y_pred[i]\n\n        # If class names are provided, use them for printing\n        if class_names is not None:\n            true_label_name = class_names[true_label]\n            predicted_label_name = class_names[predicted_label]\n        else:\n            true_label_name = true_label\n            predicted_label_name = predicted_label\n\n        # Determine the color of the text (green for correct, red for incorrect)\n        text_color = Fore.GREEN if true_label == predicted_label else Fore.RED\n\n        print(f\"\\nSample {i + 1}:\")\n        print(f\"Text: {text}\")\n        print(text_color + f\"True: {true_label_name} \\n Predicted: {predicted_label_name}\" + Style.RESET_ALL)","metadata":{"id":"Lh8facYQaoL2","execution":{"iopub.status.busy":"2023-06-30T22:38:58.84037Z","iopub.execute_input":"2023-06-30T22:38:58.840671Z","iopub.status.idle":"2023-06-30T22:38:58.852239Z","shell.execute_reply.started":"2023-06-30T22:38:58.840645Z","shell.execute_reply":"2023-06-30T22:38:58.851386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_predictions(model_USE,\n                   X_valid_tx,\n                   y_valid,\n                   num_samples=20,\n                   class_names=class_names)","metadata":{"id":"ESYeoR1usGmG","outputId":"84e8b219-a4d0-4817-9e7f-8b7c5009319c","execution":{"iopub.status.busy":"2023-06-30T22:38:58.853605Z","iopub.execute_input":"2023-06-30T22:38:58.854159Z","iopub.status.idle":"2023-06-30T22:38:58.944691Z","shell.execute_reply.started":"2023-06-30T22:38:58.85412Z","shell.execute_reply":"2023-06-30T22:38:58.943705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model: nnlm-en-dim128-with-normalization**","metadata":{"id":"QBWVLH0YFItd"}},{"cell_type":"markdown","source":"\nThe provided code block constructs a sequential Neural Network model in TensorFlow Keras, utilizing a pre-trained embedding layer from TensorFlow Hub. Here's a summary of the key components of this model:\n\n1. **Pre-trained Embedding Layer**:\n   - The model uses Google's NNLM (Neural Network Language Model) with 128 dimensions for the embedding layer. This pre-trained embedding layer converts input text into fixed-size vectors.\n   - Normalization is applied to the embedding layer, ensuring that the vectors are scaled to have unit norm.\n\n2. **Embedding Training**:\n   - The model allows for embedding training, meaning the pre-trained embeddings can be fine-tuned during the training process to adapt to the specific dataset.\n\n3. **Dropout Layer**:\n   - To prevent overfitting, a Dropout layer is introduced. During training, it randomly nullifies 40% of the input units. This helps improve model generalization.\n\n4. **Dense Layer with 'sigmoid' Activation**:\n   - The model concludes with a Dense layer featuring a 'sigmoid' activation function. This configuration is suitable for binary classification tasks, as it produces probabilities in the range of 0 to 1.\n\nThis model leverages pre-trained embeddings to represent input text, allows for fine-tuning of these embeddings, incorporates dropout for regularization, and makes binary classification predictions. It can be highly effective for text classification tasks, benefiting from the pre-trained embeddings' ability to capture semantic information in text data.","metadata":{"id":"T3JZI4UkIurO"}},{"cell_type":"code","source":"from tensorflow.keras.layers import Dropout\n\n# embedding_url = \"https://tfhub.dev/google/nnlm-en-dim50-with-normalization/2\"\nembedding_url = \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\"\n\nmodel_NN = Sequential()\nmodel_NN.add(hub.KerasLayer(embedding_url, input_shape=(), dtype=tf.string, trainable=True))\nmodel_NN.add(Dropout(0.4))\nmodel_NN.add(Dense(1, activation=\"sigmoid\"))\nmodel_NN.summary()","metadata":{"id":"JQudp9a2FIte","outputId":"af0833d3-edfe-4655-9ead-de3ab7b24ede","execution":{"iopub.status.busy":"2023-06-30T22:38:58.946457Z","iopub.execute_input":"2023-06-30T22:38:58.94694Z","iopub.status.idle":"2023-06-30T22:39:02.347884Z","shell.execute_reply.started":"2023-06-30T22:38:58.946906Z","shell.execute_reply":"2023-06-30T22:39:02.34712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This next line compiles the neural network model (model_NN) using the RMSprop optimizer and binary cross-entropy loss function. It also specifies that the model's performance should be evaluated using accuracy as a metric.","metadata":{"id":"TMD6UZAnJtOr"}},{"cell_type":"code","source":"model_NN.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","metadata":{"id":"-jWCWNGmFIte","execution":{"iopub.status.busy":"2023-06-30T22:39:02.349001Z","iopub.execute_input":"2023-06-30T22:39:02.34938Z","iopub.status.idle":"2023-06-30T22:39:02.365651Z","shell.execute_reply.started":"2023-06-30T22:39:02.349347Z","shell.execute_reply":"2023-06-30T22:39:02.364578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" This line creates a ModelCheckpoint callback (cc). The callback monitors the validation accuracy (val_loss) during training and saves the model's weights to the specified checkpoint_path only when the validation loss decreases.","metadata":{"id":"_FNLYW_cJsFh"}},{"cell_type":"code","source":"# Define the checkpoint path\ncheckpoint_path = \"best_model_nn\"\n\n# Create a ModelCheckpoint callback that saves the model's weights only when the validation accuracy improves\ncc = ModelCheckpoint(filepath=checkpoint_path,\n                                      monitor='val_loss',\n                                      mode='min',\n                                      save_best_only=True,\n                                      verbose=1)\n","metadata":{"id":"4H1vChDuFItf","execution":{"iopub.status.busy":"2023-06-30T22:39:02.367364Z","iopub.execute_input":"2023-06-30T22:39:02.368285Z","iopub.status.idle":"2023-06-30T22:39:02.373637Z","shell.execute_reply.started":"2023-06-30T22:39:02.368248Z","shell.execute_reply":"2023-06-30T22:39:02.372724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The fit method is called to train the neural network model. It takes the training data (X_train_tx and y_train) and runs for 20 epochs. The validation_data parameter is set to evaluate the model's performance on the validation data (X_valid_tx and y_valid). The callbacks argument is provided with the cc callback, which triggers the model checkpointing process during training.","metadata":{"id":"EbNC1fBVJ2Yb"}},{"cell_type":"code","source":"model_NN_history = model_NN.fit(X_train_tx,\n                              y_train,\n                              epochs=20,\n                              validation_data=(X_valid_tx, y_valid),\n                              callbacks=[cc])\n","metadata":{"id":"X-vMYHNgFItf","outputId":"a7b9c00b-55c7-45c8-93f1-67ed98d5ff90","execution":{"iopub.status.busy":"2023-06-30T22:39:02.375018Z","iopub.execute_input":"2023-06-30T22:39:02.375613Z","iopub.status.idle":"2023-06-30T22:42:24.886031Z","shell.execute_reply.started":"2023-06-30T22:39:02.375576Z","shell.execute_reply":"2023-06-30T22:42:24.884798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After training is complete, we load the entire model from the saved checkpoint path (checkpoint_path).","metadata":{"id":"HaXNLu08KGDI"}},{"cell_type":"code","source":"# Load the entire model\nmodel_NN = load_model(checkpoint_path)","metadata":{"id":"UaGUSRC1FItf","execution":{"iopub.status.busy":"2023-06-30T22:42:24.888651Z","iopub.execute_input":"2023-06-30T22:42:24.888955Z","iopub.status.idle":"2023-06-30T22:42:30.682432Z","shell.execute_reply.started":"2023-06-30T22:42:24.888928Z","shell.execute_reply":"2023-06-30T22:42:30.679993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the results\nmodel_NN_ev = model_NN.evaluate(X_valid_tx, y_valid)\nmodel_NN_loss = model_NN_ev[0]\nmodel_NN_loss","metadata":{"id":"pabiMfyNFItg","outputId":"0eeadc19-4294-404e-9376-4ec865bfc4a8","execution":{"iopub.status.busy":"2023-06-30T22:42:30.685919Z","iopub.execute_input":"2023-06-30T22:42:30.686266Z","iopub.status.idle":"2023-06-30T22:42:31.085799Z","shell.execute_reply.started":"2023-06-30T22:42:30.686237Z","shell.execute_reply":"2023-06-30T22:42:31.084391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Post-training, the model's performance is assessed by plotting the history of accuracy and loss over the epochs.","metadata":{"id":"QP6VjOTiJnny"}},{"cell_type":"code","source":"# Plot Utility\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n\n# Plot the accuracy and loss history\nplot_graphs(model_NN_history, 'accuracy')\nplot_graphs(model_NN_history, 'loss')","metadata":{"id":"Xq6HsHzHFItg","outputId":"2163d0e2-0f5d-4ec5-8cc5-5f242a031271","execution":{"iopub.status.busy":"2023-06-30T22:42:31.087292Z","iopub.execute_input":"2023-06-30T22:42:31.087672Z","iopub.status.idle":"2023-06-30T22:42:31.636978Z","shell.execute_reply.started":"2023-06-30T22:42:31.087643Z","shell.execute_reply":"2023-06-30T22:42:31.635921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, the model is evaluated on the validation set, where probabilities are predicted and converted into class predictions.","metadata":{"id":"CjQ8NgMZJljy"}},{"cell_type":"code","source":"# Make predictions with the model\nmodel_NN_pred_probs = model_NN.predict(X_valid_tx)\nmodel_NN_pred_probs[:10]","metadata":{"id":"gEJMLcnmFIth","outputId":"b12433ed-d1b8-46da-bf8f-61bb6830ecbd","execution":{"iopub.status.busy":"2023-06-30T22:42:31.638442Z","iopub.execute_input":"2023-06-30T22:42:31.639477Z","iopub.status.idle":"2023-06-30T22:42:31.89718Z","shell.execute_reply.started":"2023-06-30T22:42:31.639442Z","shell.execute_reply":"2023-06-30T22:42:31.895993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert prediction probabilities to labels\nmodel_NN_preds = tf.squeeze(tf.round(model_NN_pred_probs))\nmodel_NN_preds[:10]","metadata":{"id":"p7NPaHBlFIth","outputId":"eb96ecbe-a073-4391-e727-13120980cc1d","execution":{"iopub.status.busy":"2023-06-30T22:42:31.898497Z","iopub.execute_input":"2023-06-30T22:42:31.898963Z","iopub.status.idle":"2023-06-30T22:42:31.909419Z","shell.execute_reply.started":"2023-06-30T22:42:31.89893Z","shell.execute_reply":"2023-06-30T22:42:31.908302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Various performance metrics such as accuracy, precision, recall, and the F1-score are calculated for the model.","metadata":{"id":"KZTHwGEtJim1"}},{"cell_type":"code","source":"# Calculate model performance metrics\nmodel_NN_results = calculate_results(y_valid, model_NN_preds,loss=model_NN_loss)\nmodel_NN_results","metadata":{"id":"rhTY7EtGFIti","outputId":"03c4953e-3c3b-478e-e330-3a9601e7dd25","execution":{"iopub.status.busy":"2023-06-30T22:42:31.911042Z","iopub.execute_input":"2023-06-30T22:42:31.911622Z","iopub.status.idle":"2023-06-30T22:42:31.925398Z","shell.execute_reply.started":"2023-06-30T22:42:31.911583Z","shell.execute_reply":"2023-06-30T22:42:31.924186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A comparison of the baseline and NNLM model is then performed based on these metrics.","metadata":{"id":"sOeQSXjJJeGw"}},{"cell_type":"code","source":"# Compare model to baseline\ncompare_baseline_to_new_results(baseline_results, model_NN_results)","metadata":{"id":"yW-mbdQMFIti","outputId":"8a9bdb56-8a98-4365-c005-6c7f5adf51d0","execution":{"iopub.status.busy":"2023-06-30T22:42:31.927197Z","iopub.execute_input":"2023-06-30T22:42:31.927542Z","iopub.status.idle":"2023-06-30T22:42:31.933421Z","shell.execute_reply.started":"2023-06-30T22:42:31.92751Z","shell.execute_reply":"2023-06-30T22:42:31.932356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = y_valid.tolist()  # Convert labels to a list\npreds = model_NN.predict(X_valid_tx)\ny_probs = preds.squeeze().tolist()  # Store the prediction probabilities as a list\ny_preds = tf.round(y_probs).numpy().tolist()  # Convert probabilities to class predictions and convert to a list","metadata":{"id":"qqGSuKpOFIti","outputId":"7dbed3f1-d684-407e-e088-7e68dd199aa6","execution":{"iopub.status.busy":"2023-06-30T22:42:31.935116Z","iopub.execute_input":"2023-06-30T22:42:31.935481Z","iopub.status.idle":"2023-06-30T22:42:32.298386Z","shell.execute_reply.started":"2023-06-30T22:42:31.93545Z","shell.execute_reply":"2023-06-30T22:42:32.297368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A confusion matrix is created to offer a visual perspective of the classification model's performance, which is further refined for readability using a custom function.","metadata":{"id":"pUPYYYfpJbmx"}},{"cell_type":"code","source":"# Check out the non-prettified confusion matrix\nconfusion_matrix(y_true=y_true,\n                 y_pred=y_preds)","metadata":{"id":"hAxazj4ZFItn","outputId":"8211188d-8df6-4ccb-b4d9-32f9e032dec0","execution":{"iopub.status.busy":"2023-06-30T22:42:32.299996Z","iopub.execute_input":"2023-06-30T22:42:32.30035Z","iopub.status.idle":"2023-06-30T22:42:32.313989Z","shell.execute_reply.started":"2023-06-30T22:42:32.300317Z","shell.execute_reply":"2023-06-30T22:42:32.313049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prettier confusion matrix\nmake_confusion_matrix(y_true=y_true,\n                      y_pred=y_preds,\n                      classes=class_names,\n                      figsize=(15, 15),\n                      text_size=10)","metadata":{"id":"ZgXtZEsoFIto","outputId":"93696b5b-ce6e-4334-e7cf-4c42a377262f","execution":{"iopub.status.busy":"2023-06-30T22:42:32.315866Z","iopub.execute_input":"2023-06-30T22:42:32.316309Z","iopub.status.idle":"2023-06-30T22:42:32.80704Z","shell.execute_reply.started":"2023-06-30T22:42:32.316269Z","shell.execute_reply":"2023-06-30T22:42:32.805972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The function '`random_predictions`' generates and displays predictions on random samples specifically model NNLM.","metadata":{"id":"cSAhkHHxJUzf"}},{"cell_type":"code","source":"random_predictions(model_NN,\n                   X_valid_tx,\n                   y_valid,\n                   num_samples=20,\n                   class_names=class_names)","metadata":{"id":"L7NRcBssFIto","outputId":"b1fcd181-cf2c-4168-abdc-b5ba92fbe4d2","execution":{"iopub.status.busy":"2023-06-30T22:42:32.809677Z","iopub.execute_input":"2023-06-30T22:42:32.810356Z","iopub.status.idle":"2023-06-30T22:42:32.879506Z","shell.execute_reply.started":"2023-06-30T22:42:32.810321Z","shell.execute_reply":"2023-06-30T22:42:32.878574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Comparing all models**","metadata":{"id":"-WtFFnIj52IR"}},{"cell_type":"markdown","source":"The following section compares and visualizes the performance of various models. Initially, the evaluation results from each model are compiled into a DataFrame for comparison. Metrics such as F1-score are used to sort the models in terms of performance.","metadata":{"id":"ZTGi4RiPKf2Z"}},{"cell_type":"code","source":"# Combine model results into a DataFrame\nall_model_results = pd.DataFrame({\"baseline\": baseline_results,\n                                  \"Simple Dense\": model_dense_results,\n                                  \"LSTM\": model_1LSTM_results,\n                                  \"Bidirectional LSTM\": model_lstm_results,\n                                  \"GRU\": model_GRU_results,\n                                  \"Bidirectional GRU\": model_bi_GRU_results,\n                                  \"Conv1D\": model_conv_results,\n                                  \"USE\": model_USE_results,\n                                  \"NNLM\": model_NN_results,\n                                  })\n\n\nall_model_results = all_model_results.transpose()\n# Reduce the accuracy to same scale as other metrics\nall_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\nall_model_results=all_model_results.sort_values(by=\"loss\", ascending=True)\nall_model_results\n","metadata":{"id":"IFvZMe116bdE","outputId":"0ecc58ee-0fc3-42c4-8caf-2db3b09596ea","execution":{"iopub.status.busy":"2023-06-30T22:48:56.953613Z","iopub.execute_input":"2023-06-30T22:48:56.953994Z","iopub.status.idle":"2023-06-30T22:48:56.973347Z","shell.execute_reply.started":"2023-06-30T22:48:56.953962Z","shell.execute_reply":"2023-06-30T22:48:56.972086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The summary of the model performance results revealed distinct variations in accuracy, precision, recall, F1 score, and loss among the different models. The Simple Dense model stood out as the best-performing model, achieving perfect accuracy, precision, recall, and F1 score all at 1.0, accompanied by the smallest loss of 0.003321. The LSTM model followed closely with an accuracy, precision, recall, and F1 score of approximately 0.998 and a slightly higher loss of 0.004826. Bidirectional GRU and Bidirectional LSTM also showed impressive performance, albeit slightly lower than the LSTM model, with similar scores in the range of 0.993 to 0.995 and a marginally higher loss. The NNLM and GRU models also produced high-level performance metrics, ranging around 0.992 to 0.994, with incrementally higher losses. The USE and Conv1D models were on par with GRU, but with an increased loss. Lastly, the baseline model demonstrated the lowest performance metrics in the range of approximately 0.980 and an undefined loss.","metadata":{"id":"70aAbsXUmd_f"}},{"cell_type":"code","source":"# Plot and compare all of the model results\nall_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));","metadata":{"id":"bjyGEyPP6ee5","outputId":"12283b1d-ca61-40a3-9512-2dbafd5f1f70","execution":{"iopub.status.busy":"2023-06-30T22:48:56.975371Z","iopub.execute_input":"2023-06-30T22:48:56.975966Z","iopub.status.idle":"2023-06-30T22:48:57.445969Z","shell.execute_reply.started":"2023-06-30T22:48:56.975934Z","shell.execute_reply":"2023-06-30T22:48:57.444854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sort model results by f1-score\nall_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));","metadata":{"id":"QGEaYYPl6f2T","outputId":"433ee89b-969b-48e5-f2b5-c7c3bf26e363","execution":{"iopub.status.busy":"2023-06-30T22:48:57.448278Z","iopub.execute_input":"2023-06-30T22:48:57.448648Z","iopub.status.idle":"2023-06-30T22:48:57.747965Z","shell.execute_reply.started":"2023-06-30T22:48:57.448613Z","shell.execute_reply":"2023-06-30T22:48:57.746997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluation Metrics**","metadata":{"id":"79hTg2Mw9kcP"}},{"cell_type":"markdown","source":"Moving forward, we will deploy the Model Dense for further analysis.","metadata":{"id":"4l4Y72GSKkQL"}},{"cell_type":"code","source":"y_true = y_valid.tolist()  # Convert labels to a list\npreds = model_dense.predict(X_valid)\ny_probs = preds.squeeze().tolist()  # Store the prediction probabilities as a list\ny_preds = tf.round(y_probs).numpy().tolist()  # Convert probabilities to class predictions and convert to a list","metadata":{"id":"86Uc7_wRsGmT","outputId":"eaa893d6-c0bc-4686-da40-868ea84a8901","execution":{"iopub.status.busy":"2023-06-30T22:53:21.677473Z","iopub.execute_input":"2023-06-30T22:53:21.677956Z","iopub.status.idle":"2023-06-30T22:53:21.943934Z","shell.execute_reply.started":"2023-06-30T22:53:21.677923Z","shell.execute_reply":"2023-06-30T22:53:21.942925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score\n\nreport = classification_report(y_true, y_preds)\nprint(report)","metadata":{"id":"L6fuA88i7W5b","outputId":"73411991-730f-45e8-d5b5-df34b5a0e727","execution":{"iopub.status.busy":"2023-06-30T22:53:23.74863Z","iopub.execute_input":"2023-06-30T22:53:23.749006Z","iopub.status.idle":"2023-06-30T22:53:23.772677Z","shell.execute_reply.started":"2023-06-30T22:53:23.748972Z","shell.execute_reply":"2023-06-30T22:53:23.771713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Make Prediction on Text from Wild**","metadata":{"id":"V7RlQ8-q8Xzc"}},{"cell_type":"code","source":"# Turn Text into string\ntextx = \"text meet someone sexy today u can find date even flirt, call customer service 78990gh3. xxx9893jkdljk\"","metadata":{"id":"7HtJjhn58eNU","execution":{"iopub.status.busy":"2023-06-30T22:58:00.222467Z","iopub.execute_input":"2023-06-30T22:58:00.223173Z","iopub.status.idle":"2023-06-30T22:58:00.229029Z","shell.execute_reply.started":"2023-06-30T22:58:00.223126Z","shell.execute_reply":"2023-06-30T22:58:00.227781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn Text into string\ntextx2 = \"thanks ringtone order ref number r836 mobile will charged 450 tone not arrive please call customer service 09065069154\"","metadata":{"execution":{"iopub.status.busy":"2023-06-30T22:55:02.20475Z","iopub.execute_input":"2023-06-30T22:55:02.20516Z","iopub.status.idle":"2023-06-30T22:55:02.210269Z","shell.execute_reply.started":"2023-06-30T22:55:02.205127Z","shell.execute_reply":"2023-06-30T22:55:02.209153Z"},"id":"RbfS1gzSmd_h","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn Text into string\ntextx3 = \"The weather today is beautiful, perfect for a walk in the park.\"","metadata":{"id":"CamOdO3XAEvm","execution":{"iopub.status.busy":"2023-06-30T22:54:15.586789Z","iopub.execute_input":"2023-06-30T22:54:15.587192Z","iopub.status.idle":"2023-06-30T22:54:15.591527Z","shell.execute_reply.started":"2023-06-30T22:54:15.587161Z","shell.execute_reply":"2023-06-30T22:54:15.590572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The 'predict_on_sentence' function is used to make predictions on unseen sentences, displaying the predicted class and its corresponding probability.","metadata":{"id":"Tjis9xPcKqos"}},{"cell_type":"code","source":"def predict_on_sentence(model, sentence, category_reverse_mapping, tokenizer, max_length):\n    \"\"\"\n    Uses model to make a prediction on sentence.\n\n    Returns the sentence, the predicted labels and the prediction probabilities.\n    \"\"\"\n\n    # Convert the sentence into sequences\n    sequence = tokenizer.texts_to_sequences([sentence])\n\n    # Pad the sequences to ensure consistent length\n    padded_sequence = pad_sequences(sequence, maxlen=max_length)\n\n    # Make the prediction\n    pred_prob = model.predict(padded_sequence)\n    pred_label = np.round(pred_prob).astype(int)[0]  # Converting to int to match the format of your labels\n\n    # Get the label names of the predicted class\n    pred_label_str = category_reverse_mapping[pred_label[0]]  # Use the first element of pred_label\n    pred_prob_str = pred_prob[0][0]\n\n    print(f\"Prediction: {pred_label_str}\")  # Print the predicted label\n    print(f\"Prediction probability: {pred_prob_str}\")  # Print the prediction probabilities\n    print(f\"Text:\\n{sentence}\")\n","metadata":{"id":"p-pEM4jhFItt","execution":{"iopub.status.busy":"2023-06-30T22:54:23.35186Z","iopub.execute_input":"2023-06-30T22:54:23.352946Z","iopub.status.idle":"2023-06-30T22:54:23.361855Z","shell.execute_reply.started":"2023-06-30T22:54:23.352906Z","shell.execute_reply":"2023-06-30T22:54:23.360827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prediction on text from the wild\npredict_on_sentence(model=model_dense,\n                    sentence=textx,\n                    category_reverse_mapping=class_names,\n                    tokenizer=tokenizer,\n                    max_length=max_length\n                   )","metadata":{"id":"tO6oRkB68lEo","outputId":"441692fb-6509-47ff-d65f-4e152d23c158","execution":{"iopub.status.busy":"2023-06-30T22:58:03.646129Z","iopub.execute_input":"2023-06-30T22:58:03.646495Z","iopub.status.idle":"2023-06-30T22:58:03.723933Z","shell.execute_reply.started":"2023-06-30T22:58:03.646466Z","shell.execute_reply":"2023-06-30T22:58:03.722334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prediction on text from the wild\npredict_on_sentence(model=model_dense,\n                    sentence=textx2,\n                    category_reverse_mapping=class_names,\n                    tokenizer=tokenizer,\n                    max_length=max_length)","metadata":{"id":"PwAywowwAKzG","outputId":"c5499b0e-9cd5-4dc0-eb85-fa5c69204541","execution":{"iopub.status.busy":"2023-06-30T22:55:12.727647Z","iopub.execute_input":"2023-06-30T22:55:12.731573Z","iopub.status.idle":"2023-06-30T22:55:12.995408Z","shell.execute_reply.started":"2023-06-30T22:55:12.731533Z","shell.execute_reply":"2023-06-30T22:55:12.984448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prediction on text from the wild\npredict_on_sentence(model=model_dense,\n                    sentence=textx3,\n                    category_reverse_mapping=class_names,\n                    tokenizer=tokenizer,\n                    max_length=max_length)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T22:58:49.645276Z","iopub.execute_input":"2023-06-30T22:58:49.645826Z","iopub.status.idle":"2023-06-30T22:58:49.772054Z","shell.execute_reply.started":"2023-06-30T22:58:49.64578Z","shell.execute_reply":"2023-06-30T22:58:49.771175Z"},"id":"fsARU0ngmd_i","outputId":"5d429a18-c78f-487f-ec5f-890ccb1827b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Most Wrong Predictions**","metadata":{"id":"aURn8j9h7gvX"}},{"cell_type":"markdown","source":"The 'Most Wrong Predictions' code segment below allows for a deeper understanding of model errors by identifying and analyzing predictions that deviate most from actual values, assisting in pinpointing model weaknesses and potential areas of improvement. Here, a DataFrame is created with the validation sentences and predictions of the best-performing model, which helps to identify the most incorrect predictions, both false positives and negatives.","metadata":{"id":"Ih4kVohJKvNM"}},{"cell_type":"code","source":"val_df = pd.DataFrame({\n    \"text\": X_valid_tx.tolist(),\n    \"target\": [class_names[label] for label in y_valid],\n    \"target_label\": y_valid.tolist(),\n    \"pred\": [class_names[int(round(prob))] for prob in y_preds],\n    \"pred_label\": [int(round(prob)) for prob in y_preds],\n    \"pred_prob\": y_preds\n})\nval_df","metadata":{"id":"tblLqRNp-Y4_","outputId":"ef1c63b4-0e46-4a17-835d-566ba4717e50","execution":{"iopub.status.busy":"2023-06-30T22:58:49.777813Z","iopub.execute_input":"2023-06-30T22:58:49.780286Z","iopub.status.idle":"2023-06-30T22:58:49.815907Z","shell.execute_reply.started":"2023-06-30T22:58:49.780252Z","shell.execute_reply":"2023-06-30T22:58:49.815087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the wrong predictions and sort by prediction probabilities\nmost_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\nmost_wrong[:10]","metadata":{"id":"MfIwio9S-anP","outputId":"e2189d7d-6d07-4058-a0b0-b202ff6d68c0","execution":{"iopub.status.busy":"2023-06-30T22:58:49.820218Z","iopub.execute_input":"2023-06-30T22:58:49.82227Z","iopub.status.idle":"2023-06-30T22:58:49.849861Z","shell.execute_reply.started":"2023-06-30T22:58:49.822235Z","shell.execute_reply":"2023-06-30T22:58:49.84228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Given that the Simple Dense model achieved a 100% accuracy rate on the validation data, this means that there were no incorrect predictions made by the model. Thus, when attempting to identify and analyze the most wrong predictions, as intended in the given code snippet, we find that there is no such instance to consider. The model's perfect accuracy highlights its robust performance and ability to precisely classify the validation data. Nonetheless, it's important to evaluate the model's performance on unseen data to ensure its generalizability, as a 100% accuracy rate might also be indicative of overfitting to the training data.","metadata":{"id":"9ad1cJoPmd_j"}},{"cell_type":"markdown","source":"**The speed/score tradeoff**","metadata":{"id":"NqUad2JI-H-e"}},{"cell_type":"markdown","source":"The speed-performance trade-off code below helps quantify and visualize the balance between a model's prediction accuracy (performance) and the computational resources required (time taken for predictions), which is critical in optimizing real-world applications.","metadata":{"id":"3A5lSxG1KzUI"}},{"cell_type":"code","source":"# Calculate the time of predictions\nimport time\ndef pred_timer(model, samples):\n  \"\"\"\n  Times how long a model takes to make predictions on samples.\n\n  Args:\n  ----\n  model = a trained model\n  sample = a list of samples\n\n  Returns:\n  ----\n  total_time = total elapsed time for model to make predictions on samples\n  time_per_pred = time in seconds per single sample\n  \"\"\"\n  start_time = time.perf_counter() # get start time\n  model.predict(samples) # make predictions\n  end_time = time.perf_counter() # get finish time\n  total_time = end_time-start_time # calculate how long predictions took to make\n  time_per_pred = total_time/len(X_valid) # find prediction time per sample\n  return total_time, time_per_pred","metadata":{"id":"DV1Q7fvo-JWy","execution":{"iopub.status.busy":"2023-06-30T22:58:49.881105Z","iopub.execute_input":"2023-06-30T22:58:49.881606Z","iopub.status.idle":"2023-06-30T22:58:49.890962Z","shell.execute_reply.started":"2023-06-30T22:58:49.881578Z","shell.execute_reply":"2023-06-30T22:58:49.890142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate model prediction times\nmodel_total_pred_time, model_time_per_pred = pred_timer(model_dense, X_valid)\nmodel_total_pred_time, model_time_per_pred","metadata":{"id":"i5Q6vUQA-LUG","outputId":"0248b71f-8c3c-4d9c-f669-ad31aa06feb7","execution":{"iopub.status.busy":"2023-06-30T22:59:22.916094Z","iopub.execute_input":"2023-06-30T22:59:22.91649Z","iopub.status.idle":"2023-06-30T22:59:23.352175Z","shell.execute_reply.started":"2023-06-30T22:59:22.916459Z","shell.execute_reply":"2023-06-30T22:59:23.351091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate Naive Bayes prediction times\nbaseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, X_valid_tx)\nbaseline_total_pred_time, baseline_time_per_pred","metadata":{"id":"A9o4jB-H-Ms2","outputId":"da7fc733-40e3-40c5-9eda-149519259a7c","execution":{"iopub.status.busy":"2023-06-30T22:59:25.430077Z","iopub.execute_input":"2023-06-30T22:59:25.430446Z","iopub.status.idle":"2023-06-30T22:59:25.51042Z","shell.execute_reply.started":"2023-06-30T22:59:25.430418Z","shell.execute_reply":"2023-06-30T22:59:25.504107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The time per prediction and F1-score for each model are plotted on a scatter plot to visualize this trade-off.","metadata":{"id":"m1aZvcVbK23L"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 7))\nplt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\nplt.scatter(model_time_per_pred, model_dense_results[\"f1\"], label=\"model dense\")\nplt.legend()\nplt.title(\"F1-score versus time per prediction\")\nplt.xlabel(\"Time per prediction\")\nplt.ylabel(\"F1-Score\");","metadata":{"id":"uU-ZuJhA-N82","outputId":"e2995927-a8ce-407d-e014-139e44a8fba2","execution":{"iopub.status.busy":"2023-06-30T22:59:57.183629Z","iopub.execute_input":"2023-06-30T22:59:57.18411Z","iopub.status.idle":"2023-06-30T22:59:57.596866Z","shell.execute_reply.started":"2023-06-30T22:59:57.184065Z","shell.execute_reply":"2023-06-30T22:59:57.595952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-ideal-performance-speed-of-pred-tradeoff-highlighted.png)\n*Ideal position for speed and performance tradeoff model (fast predictions with great results).*\n\nAs can be seen, the best-performing model, while significantly improving the F1-score, takes considerably more time per prediction, highlighting a crucial consideration for machine learning applications: balancing model performance and prediction speed.","metadata":{"id":"EWwW5TJX-QC5"}},{"cell_type":"markdown","source":"**Improving model performance: Ensemble Models**","metadata":{"id":"gQoeW3Ip-qgR"}},{"cell_type":"markdown","source":"Ensemble methods are a cornerstone of machine learning where multiple models are trained and their predictions are combined, typically leading to a more robust and accurate result compared to a single model. They reduce both bias and variance, provide a way to handle large datasets, and improve generalizability and robustness over a single estimator.\n\nIn this project, an ensemble of three models (Bi-LSTM, Dense, and Bi-GRU) is created. The prediction probabilities of these models are added together and the average is calculated (by dividing by 3). The class (label) with the highest mean probability is then selected as the final ensemble prediction. This effectively votes on the most likely class based on the individual model's predictions, hence capitalizing on their collective learning.","metadata":{"id":"LlLk1Lzv-qgS"}},{"cell_type":"code","source":"# Get mean pred probs for 3 models\ncombined_pred_probs = tf.squeeze(model_dense_pred_probs, axis=1) + tf.squeeze(model_bi_GRU_pred_probs, axis=1) + tf.squeeze(model_lstm_pred_probs)\ncombined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\ncombined_preds[:20]","metadata":{"id":"YZUC49Ev-qgS","outputId":"0fb7798b-2dc0-4ba8-e9e2-b9f51fcadeda","execution":{"iopub.status.busy":"2023-06-30T23:02:35.399001Z","iopub.execute_input":"2023-06-30T23:02:35.399452Z","iopub.status.idle":"2023-06-30T23:02:35.419394Z","shell.execute_reply.started":"2023-06-30T23:02:35.399418Z","shell.execute_reply":"2023-06-30T23:02:35.418114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.losses import BinaryCrossentropy\n\nloss_fn = BinaryCrossentropy()\nloss = loss_fn(y_valid, combined_pred_probs/3) # Note, this is before rounding\nloss_np=loss.numpy()\nprint('Ensemble model loss: ', loss_np)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T23:05:58.804853Z","iopub.execute_input":"2023-06-30T23:05:58.805257Z","iopub.status.idle":"2023-06-30T23:05:58.819446Z","shell.execute_reply.started":"2023-06-30T23:05:58.805225Z","shell.execute_reply":"2023-06-30T23:05:58.818306Z"},"id":"zouuapNOmd_n","outputId":"4853171c-a12f-40ea-fe35-92371bcb3908","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following code evaluates the ensemble model's performance, adds these results to a DataFrame for comparison with other models, and plots the F1 scores of all models. The code evaluates the ensemble model's performance, adds these results to a DataFrame for comparison with other models, and plots the F1 scores of all models.","metadata":{"id":"BJJcQrsSLDSJ"}},{"cell_type":"code","source":"# Calculate results from averaging the prediction probabilities\nensemble_results = calculate_results(y_valid, combined_preds, loss=loss_np)\nensemble_results","metadata":{"id":"ziI-azeFYqfG","outputId":"ba485183-8c2f-49be-c888-f1271a29c609","execution":{"iopub.status.busy":"2023-06-30T23:06:07.445778Z","iopub.execute_input":"2023-06-30T23:06:07.446188Z","iopub.status.idle":"2023-06-30T23:06:07.460711Z","shell.execute_reply.started":"2023-06-30T23:06:07.446157Z","shell.execute_reply":"2023-06-30T23:06:07.459795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add our combined model's results to the results DataFrame\nall_model_results.loc[\"ensemble_results\"] = ensemble_results\nall_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100","metadata":{"id":"HYsJ0E8k-qgT","execution":{"iopub.status.busy":"2023-06-30T23:06:59.064968Z","iopub.execute_input":"2023-06-30T23:06:59.065594Z","iopub.status.idle":"2023-06-30T23:06:59.071497Z","shell.execute_reply.started":"2023-06-30T23:06:59.065562Z","shell.execute_reply":"2023-06-30T23:06:59.070533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_model_results","metadata":{"id":"9H-lXZIJFIt0","outputId":"24cdc79e-6e6d-42c5-a849-3f661d764a68","execution":{"iopub.status.busy":"2023-06-30T23:07:01.26466Z","iopub.execute_input":"2023-06-30T23:07:01.265368Z","iopub.status.idle":"2023-06-30T23:07:01.280299Z","shell.execute_reply.started":"2023-06-30T23:07:01.265335Z","shell.execute_reply":"2023-06-30T23:07:01.279313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the accuracy to the same scale as the rest of the results\nsorted_df = all_model_results.sort_values(by='loss', ascending=True)\nsorted_df","metadata":{"id":"xplpVFDe-qgT","outputId":"2674365d-0b4b-43d0-d91f-b62e8feff379","execution":{"iopub.status.busy":"2023-06-30T23:07:51.152951Z","iopub.execute_input":"2023-06-30T23:07:51.153708Z","iopub.status.idle":"2023-06-30T23:07:51.171989Z","shell.execute_reply.started":"2023-06-30T23:07:51.153673Z","shell.execute_reply":"2023-06-30T23:07:51.170868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The ensemble model's performance evaluation revealed intriguing results, surpassing most individual models, including Bidirectional GRU, Bidirectional LSTM, NNLM, GRU, USE, Conv1D, and the baseline model. It achieved remarkable accuracy, precision, recall, and F1 score (approximately 0.997) with a low loss of 0.006873, ranking third in performance, only behind the Simple Dense and LSTM models.\n\nThis underscores the efficacy of ensemble methods, harnessing the strengths of multiple models to enhance overall performance. Ensembles exhibit superior generalization and stability, minimizing errors from individual models. Despite its excellence, the ensemble model couldn't outperform the Simple Dense and LSTM models, suggesting potential for fine-tuning or exploring alternative ensemble techniques to further elevate performance.","metadata":{"id":"DkVlavk9LG_m"}},{"cell_type":"markdown","source":"**Save Model**","metadata":{"id":"O5o6aq0-7ahz"}},{"cell_type":"code","source":"# Save dense model to HDF5 format\nmodel_dense.save(\"model.h5\")","metadata":{"id":"1SY16ZNa7WRZ","execution":{"iopub.status.busy":"2023-06-30T23:09:35.903628Z","iopub.execute_input":"2023-06-30T23:09:35.904206Z","iopub.status.idle":"2023-06-30T23:09:36.003375Z","shell.execute_reply.started":"2023-06-30T23:09:35.904165Z","shell.execute_reply":"2023-06-30T23:09:36.002357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Load saved model**","metadata":{"id":"TOdiLFU17bdQ"}},{"cell_type":"code","source":"# Load saved model\nloaded_model_SavedModel = tf.keras.models.load_model(\"model.h5\")","metadata":{"id":"qlnC7--AFIt2","execution":{"iopub.status.busy":"2023-06-30T23:09:51.138938Z","iopub.execute_input":"2023-06-30T23:09:51.139701Z","iopub.status.idle":"2023-06-30T23:09:51.222753Z","shell.execute_reply.started":"2023-06-30T23:09:51.139663Z","shell.execute_reply":"2023-06-30T23:09:51.221786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate loaded model\nloaded_model_SavedModel.evaluate(X_valid, y_valid)","metadata":{"id":"Ia-T5JhLY4Np","outputId":"0930520f-223a-4ef4-f790-d64b9c7b1627","execution":{"iopub.status.busy":"2023-06-30T23:10:57.257988Z","iopub.execute_input":"2023-06-30T23:10:57.25896Z","iopub.status.idle":"2023-06-30T23:10:57.629819Z","shell.execute_reply.started":"2023-06-30T23:10:57.258925Z","shell.execute_reply":"2023-06-30T23:10:57.628922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model_SavedModel.summary()","metadata":{"id":"x-ADvLBEFIt3","outputId":"b05c2150-f32e-4fea-d2ca-c513dce6c6de","execution":{"iopub.status.busy":"2023-06-30T23:11:01.686065Z","iopub.execute_input":"2023-06-30T23:11:01.686501Z","iopub.status.idle":"2023-06-30T23:11:01.710733Z","shell.execute_reply.started":"2023-06-30T23:11:01.686469Z","shell.execute_reply":"2023-06-30T23:11:01.709956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate loaded SavedModel format\nloaded_model_SavedModel.evaluate(X_valid, y_valid)","metadata":{"id":"VfzkJcr1FIt3","outputId":"3a07e3de-fd2a-4607-935c-ece4554027f5","execution":{"iopub.status.busy":"2023-06-30T23:11:12.368399Z","iopub.execute_input":"2023-06-30T23:11:12.368774Z","iopub.status.idle":"2023-06-30T23:11:12.572955Z","shell.execute_reply.started":"2023-06-30T23:11:12.368745Z","shell.execute_reply":"2023-06-30T23:11:12.572043Z"},"trusted":true},"execution_count":null,"outputs":[]}]}